{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPleJaIP0fyvhXVL+kPPvAj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csukuangfj/colab/blob/master/sherpa_onnx_streaming_paraformer_gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "This colab notebook shows how to use [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx) to run streaming [Paraformer](https://www.modelscope.cn/models/damo/speech_paraformer_asr_nat-zh-cn-16k-common-vocab8404-online/summary) models on **GPU**.\n",
        "\n",
        "Please refer to\n",
        "https://github.com/k2-fsa/colab/blob/master/sherpa-onnx/sherpa_onnx_streaming_paraformer_cpu.ipynb\n",
        "for how to run on CPU."
      ],
      "metadata": {
        "id": "EWAwGW_ZLVSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install sherpa-onnx\n",
        "\n",
        "Please refer to\n",
        "https://k2-fsa.github.io/sherpa/onnx/install/linux.html\n",
        "for how to build sherpa-onnx with GPU support."
      ],
      "metadata": {
        "id": "TNRMn2_7LgZ6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lg5rPoIjLP1U",
        "outputId": "7609939a-dcdd-4729-9e67-a28b6e879439"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sherpa-onnx'...\n",
            "remote: Enumerating objects: 2855, done.\u001b[K\n",
            "remote: Counting objects: 100% (1332/1332), done.\u001b[K\n",
            "remote: Compressing objects: 100% (532/532), done.\u001b[K\n",
            "remote: Total 2855 (delta 915), reused 1006 (delta 780), pack-reused 1523\u001b[K\n",
            "Receiving objects: 100% (2855/2855), 2.02 MiB | 3.02 MiB/s, done.\n",
            "Resolving deltas: 100% (1647/1647), done.\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "\u001b[33mCMake Warning at CMakeLists.txt:62 (message):\n",
            "  Compiling for NVIDIA GPU is enabled.  Please make sure cudatoolkit\n",
            "\n",
            "  is installed on your system.  Otherwise, you will get errors at runtime.\n",
            "\n",
            "  Hint: You don't need sudo permission to install CUDA toolkit.  Please refer\n",
            "  to\n",
            "\n",
            "    https://k2-fsa.github.io/k2/installation/cuda-cudnn.html\n",
            "\n",
            "  to install CUDA toolkit if you have not installed it.\n",
            "\n",
            "\u001b[0m\n",
            "-- CMAKE_BUILD_TYPE: Release\n",
            "-- CMAKE_INSTALL_PREFIX: /usr/local\n",
            "-- BUILD_SHARED_LIBS ON\n",
            "-- SHERPA_ONNX_ENABLE_PYTHON ON\n",
            "-- SHERPA_ONNX_ENABLE_TESTS OFF\n",
            "-- SHERPA_ONNX_ENABLE_CHECK OFF\n",
            "-- SHERPA_ONNX_ENABLE_PORTAUDIO ON\n",
            "-- SHERPA_ONNX_ENABLE_JNI OFF\n",
            "-- SHERPA_ONNX_ENABLE_C_API ON\n",
            "-- SHERPA_ONNX_ENABLE_WEBSOCKET ON\n",
            "-- SHERPA_ONNX_ENABLE_GPU ON\n",
            "-- Looking for C++ include alsa/asoundlib.h\n",
            "-- Looking for C++ include alsa/asoundlib.h - found\n",
            "-- Looking for C++ include cxxabi.h\n",
            "-- Looking for C++ include cxxabi.h - found\n",
            "-- Looking for C++ include execinfo.h\n",
            "-- Looking for C++ include execinfo.h - found\n",
            "-- Downloading kaldi-native-fbank from https://github.com/csukuangfj/kaldi-native-fbank/archive/refs/tags/v1.18.1.tar.gz\n",
            "-- kaldi-native-fbank is downloaded to /content/sherpa-onnx/build/_deps/kaldi_native_fbank-src\n",
            "-- kaldi-native-fbank's binary dir is /content/sherpa-onnx/build/_deps/kaldi_native_fbank-build\n",
            "\u001b[0mCMake Deprecation Warning at build/_deps/kaldi_native_fbank-src/CMakeLists.txt:24 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- CMAKE_BUILD_TYPE: Release\n",
            "-- CMAKE_EXPORT_COMPILE_COMMANDS: \n",
            "-- BUILD_SHARED_LIBS: ON\n",
            "-- KALDI_NATIVE_FBANK_BUILD_TESTS: OFF\n",
            "-- KALDI_NATIVE_FBANK_BUILD_PYTHON: OFF\n",
            "-- KALDI_NATIVE_FBANK_ENABLE_CHECK: OFF\n",
            "-- KALDI_NATIVE_FBANK_ENABLE_CHECK: OFF\n",
            "-- CMAKE_CXX_FLAGS: \n",
            "-- CMAKE_INSTALL_PREFIX: /usr/local\n",
            "-- Looking for C++ include cxxabi.h\n",
            "-- Looking for C++ include cxxabi.h - found\n",
            "-- Looking for C++ include execinfo.h\n",
            "-- Looking for C++ include execinfo.h - found\n",
            "-- Disable building Python\n",
            "-- CMAKE_SYSTEM_NAME: Linux\n",
            "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "-- location_onnxruntime_header_dir: location_onnxruntime_header_dir-NOTFOUND\n",
            "-- location_onnxruntime_lib: location_onnxruntime_lib-NOTFOUND\n",
            "-- location_onnxruntime_cuda_lib: location_onnxruntime_cuda_lib-NOTFOUND\n",
            "-- Could not find a pre-installed onnxruntime. Downloading pre-compiled onnxruntime\n",
            "-- CMAKE_SYSTEM_NAME: Linux\n",
            "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "-- CMAKE_SYSTEM_NAME: Linux\n",
            "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "-- Downloading onnxruntime from https://github.com/microsoft/onnxruntime/releases/download/v1.15.1/onnxruntime-linux-x64-gpu-1.15.1.tgz\n",
            "-- onnxruntime is downloaded to /content/sherpa-onnx/build/_deps/onnxruntime-src\n",
            "-- location_onnxruntime: /content/sherpa-onnx/build/_deps/onnxruntime-src/lib/libonnxruntime.so\n",
            "-- location_onnxruntime_cuda_lib: /content/sherpa-onnx/build/_deps/onnxruntime-src/lib/libonnxruntime_providers_cuda.so\n",
            "-- location_onnxruntime_providers_shared_lib: /content/sherpa-onnx/build/_deps/onnxruntime-src/lib/libonnxruntime_providers_shared.so\n",
            "-- onnxruntime lib files: /content/sherpa-onnx/build/_deps/onnxruntime-src/lib/libonnxruntime.so;/content/sherpa-onnx/build/_deps/onnxruntime-src/lib/libonnxruntime.so.1.15.1;/content/sherpa-onnx/build/_deps/onnxruntime-src/lib/libonnxruntime_providers_cuda.so;/content/sherpa-onnx/build/_deps/onnxruntime-src/lib/libonnxruntime_providers_shared.so;/content/sherpa-onnx/build/_deps/onnxruntime-src/lib/libonnxruntime_providers_tensorrt.so\n",
            "-- Downloading portaudio from http://files.portaudio.com/archives/pa_stable_v190700_20210406.tgz\n",
            "-- portaudio is downloaded to /content/sherpa-onnx/build/_deps/portaudio-src\n",
            "-- portaudio's binary dir is /content/sherpa-onnx/build/_deps/portaudio-build\n",
            "\u001b[0mCMake Deprecation Warning at build/_deps/portaudio-src/CMakeLists.txt:7 (CMAKE_MINIMUM_REQUIRED):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- Found ALSA: /usr/lib/x86_64-linux-gnu/libasound.so (found version \"1.2.6.1\") \n",
            "-- Downloading pybind11 from https://github.com/pybind/pybind11/archive/refs/tags/v2.10.2.tar.gz\n",
            "-- pybind11 is downloaded to /content/sherpa-onnx/build/_deps/pybind11-src\n",
            "\u001b[0mCMake Deprecation Warning at build/_deps/pybind11-src/CMakeLists.txt:8 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- pybind11 v2.10.2 \n",
            "\u001b[33mCMake Warning (dev) at build/_deps/pybind11-src/tools/FindPythonLibsNew.cmake:98 (find_package):\n",
            "  Policy CMP0148 is not set: The FindPythonInterp and FindPythonLibs modules\n",
            "  are removed.  Run \"cmake --help-policy CMP0148\" for policy details.  Use\n",
            "  the cmake_policy command to set the policy and suppress this warning.\n",
            "\n",
            "Call Stack (most recent call first):\n",
            "  build/_deps/pybind11-src/tools/pybind11Tools.cmake:50 (find_package)\n",
            "  build/_deps/pybind11-src/tools/pybind11Common.cmake:180 (include)\n",
            "  build/_deps/pybind11-src/CMakeLists.txt:208 (include)\n",
            "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\u001b[0m\n",
            "-- Found PythonInterp: /usr/bin/python3 (found suitable version \"3.10.12\", minimum required is \"3.6\") \n",
            "-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.10.so\n",
            "-- Performing Test HAS_FLTO\n",
            "-- Performing Test HAS_FLTO - Success\n",
            "-- Downloading websocketpp from https://github.com/zaphoyd/websocketpp/archive/b9aeec6eaf3d5610503439b4fae3581d9aff08e8.zip\n",
            "-- websocketpp is downloaded to /content/sherpa-onnx/build/_deps/websocketpp-src\n",
            "-- Downloading asio https://github.com/chriskohlhoff/asio/archive/refs/tags/asio-1-24-0.tar.gz\n",
            "-- asio is downloaded to /content/sherpa-onnx/build/_deps/asio-src\n",
            "-- Downloading json from https://github.com/nlohmann/json/archive/refs/tags/v3.11.2.tar.gz\n",
            "-- json is downloaded to /content/sherpa-onnx/build/_deps/json-src\n",
            "-- PYTHON_EXECUTABLE: /usr/bin/python3\n",
            "-- PYTHON_VERSION: 3.10\n",
            "-- Downloading cargs https://github.com/likle/cargs/archive/refs/tags/v1.0.3.tar.gz\n",
            "-- cargs is downloaded to /content/sherpa-onnx/build/_deps/cargs-src\n",
            "-- CMAKE_CXX_FLAGS: \n",
            "-- Configuring done (10.6s)\n",
            "-- Generating done (0.1s)\n",
            "-- Build files have been written to: /content/sherpa-onnx/build\n",
            "[  1%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio.dir/src/common/pa_allocation.c.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio.dir/src/common/pa_cpuload.c.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/feature-fbank.cc.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio.dir/src/common/pa_converters.c.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio.dir/src/common/pa_debugprint.c.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding C object _deps/cargs-build/CMakeFiles/cargs.dir/src/cargs.c.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio.dir/src/common/pa_front.c.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio.dir/src/common/pa_dither.c.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio.dir/src/common/pa_process.c.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio.dir/src/common/pa_ringbuffer.c.o\u001b[0m\n",
            "[  9%] \u001b[32m\u001b[1mLinking C shared library ../../lib/libcargs.so\u001b[0m\n",
            "[  9%] Built target cargs\n",
            "[ 10%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio.dir/src/common/pa_stream.c.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio.dir/src/common/pa_trace.c.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio.dir/src/hostapi/skeleton/pa_hostapi_skeleton.c.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio.dir/src/os/unix/pa_unix_hostapis.c.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio.dir/src/os/unix/pa_unix_util.c.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio.dir/src/hostapi/jack/pa_jack.c.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio.dir/src/hostapi/alsa/pa_linux_alsa.c.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/feature-functions.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/feature-window.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding C object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/fftsg.c.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/mel-computations.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/online-feature.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/rfft.cc.o\u001b[0m\n",
            "\u001b[01m\u001b[K/content/sherpa-onnx/build/_deps/portaudio-src/src/hostapi/alsa/pa_linux_alsa.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KBuildDeviceList.constprop\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/sherpa-onnx/build/_deps/portaudio-src/src/hostapi/alsa/pa_linux_alsa.c:1304:45:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K%s\u001b[m\u001b[K’ directive output may be truncated writing up to 49 bytes into a region of size between 46 and 50 [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wformat-truncation=\u0007-Wformat-truncation=\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            " 1304 |             snprintf( buf, sizeof (buf), \"%s\u001b[01;35m\u001b[K%s\u001b[m\u001b[K,%d\", hwPrefix, \u001b[32m\u001b[KalsaCardName\u001b[m\u001b[K, devIdx );\n",
            "      |                                             \u001b[01;35m\u001b[K^~\u001b[m\u001b[K                \u001b[32m\u001b[K~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/sherpa-onnx/build/_deps/portaudio-src/src/hostapi/alsa/pa_linux_alsa.c:1304:42:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdirective argument in the range [0, 2147483647]\n",
            " 1304 |             snprintf( buf, sizeof (buf), \u001b[01;36m\u001b[K\"%s%s,%d\"\u001b[m\u001b[K, hwPrefix, alsaCardName, devIdx );\n",
            "      |                                          \u001b[01;36m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/include/stdio.h:894\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/include/alsa/asoundlib.h:32\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sherpa-onnx/build/_deps/portaudio-src/src/hostapi/alsa/pa_linux_alsa.c:52\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/include/x86_64-linux-gnu/bits/stdio2.h:71:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K‘\u001b[01m\u001b[K__builtin___snprintf_chk\u001b[m\u001b[K’ output between 3 and 65 bytes into a destination of size 50\n",
            "   71 |   return \u001b[01;36m\u001b[K__builtin___snprintf_chk (__s, __n, __USE_FORTIFY_LEVEL - 1,\u001b[m\u001b[K\n",
            "      |          \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "   72 | \u001b[01;36m\u001b[K                                   __glibc_objsize (__s), __fmt,\u001b[m\u001b[K\n",
            "      |                                    \u001b[01;36m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "   73 | \u001b[01;36m\u001b[K                                   __va_arg_pack ())\u001b[m\u001b[K;\n",
            "      |                                    \u001b[01;36m\u001b[K~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "[ 19%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/whisper-feature.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32m\u001b[1mLinking C shared library ../../lib/libsherpa-onnx-portaudio.so\u001b[0m\n",
            "[ 20%] Built target portaudio\n",
            "[ 21%] \u001b[32m\u001b[1mLinking CXX shared library ../../../../lib/libkaldi-native-fbank-core.so\u001b[0m\n",
            "[ 21%] Built target kaldi-native-fbank-core\n",
            "[ 22%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/base64-decode.cc.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/cat.cc.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/context-graph.cc.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/endpoint.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/features.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/file-utils.cc.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/hypothesis.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-ctc-greedy-search-decoder.cc.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-ctc-model.cc.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-lm-config.cc.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-lm.cc.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-model-config.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-nemo-enc-dec-ctc-model-config.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-nemo-enc-dec-ctc-model.cc.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-paraformer-greedy-search-decoder.cc.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-paraformer-model-config.cc.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-paraformer-model.cc.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-recognizer-impl.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-recognizer.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-stream.cc.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-rnn-lm.cc.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-tdnn-ctc-model.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-tdnn-model-config.cc.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-transducer-greedy-search-decoder.cc.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-transducer-model-config.cc.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-transducer-model.cc.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-transducer-modified-beam-search-decoder.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-whisper-greedy-search-decoder.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-whisper-model-config.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-whisper-model.cc.o\u001b[0m\n",
            "[ 44%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-conformer-transducer-model.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-lm-config.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-lm.cc.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-lstm-transducer-model.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-model-config.cc.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-paraformer-model-config.cc.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-paraformer-model.cc.o\u001b[0m\n",
            "[ 49%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-recognizer-impl.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-recognizer.cc.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-rnn-lm.cc.o\u001b[0m\n",
            "[ 51%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-stream.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-transducer-decoder.cc.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-transducer-greedy-search-decoder.cc.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-transducer-model-config.cc.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-transducer-model.cc.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-transducer-modified-beam-search-decoder.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-zipformer-transducer-model.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-zipformer2-transducer-model.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/onnx-utils.cc.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/packed-sequence.cc.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/pad-sequence.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/parse-options.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/provider.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/resample.cc.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/session.cc.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/slice.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/stack.cc.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/symbol-table.cc.o\u001b[0m\n",
            "In file included from \u001b[01m\u001b[K/usr/include/c++/11/backward/strstream:50\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sherpa-onnx/sherpa-onnx/csrc/symbol-table.cc:10\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/include/c++/11/backward/backward_warning.h:32:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning This file includes at least one deprecated or antiquated header which may be removed without further notice at a future date. Please use a non-deprecated interface with equivalent functionality instead. For a listing of replacement headers and interfaces, consult the file backward_warning.h. To disable this warning use -Wno-deprecated. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wcpp\u0007-Wcpp\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   32 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \\\n",
            "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "[ 65%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/text-utils.cc.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/transpose.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/unbind.cc.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/wave-reader.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32m\u001b[1mLinking CXX shared library ../../lib/libsherpa-onnx-core.so\u001b[0m\n",
            "[ 68%] Built target sherpa-onnx-core\n",
            "[ 69%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx.dir/sherpa-onnx.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-offline.dir/sherpa-onnx-offline.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-microphone.dir/sherpa-onnx-microphone.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-alsa.dir/sherpa-onnx-alsa.cc.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-online-websocket-server.dir/online-websocket-server-impl.cc.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-microphone-offline.dir/sherpa-onnx-microphone-offline.cc.o\u001b[0m\n",
            "[ 74%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/sherpa-onnx-offline\u001b[0m\n",
            "[ 74%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-microphone-offline.dir/microphone.cc.o\u001b[0m\n",
            "[ 74%] Built target sherpa-onnx-offline\n",
            "[ 75%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-online-websocket-client.dir/online-websocket-client.cc.o\u001b[0m\n",
            "[ 76%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/sherpa-onnx-microphone-offline\u001b[0m\n",
            "[ 76%] Built target sherpa-onnx-microphone-offline\n",
            "[ 76%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-offline-websocket-server.dir/offline-websocket-server-impl.cc.o\u001b[0m\n",
            "[ 77%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-alsa.dir/alsa.cc.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-microphone.dir/microphone.cc.o\u001b[0m\n",
            "[ 79%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/sherpa-onnx-microphone\u001b[0m\n",
            "[ 79%] Built target sherpa-onnx-microphone\n",
            "[ 79%] \u001b[32mBuilding CXX object sherpa-onnx/python/csrc/CMakeFiles/_sherpa_onnx.dir/display.cc.o\u001b[0m\n",
            "[ 79%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/sherpa-onnx\u001b[0m\n",
            "[ 79%] Built target sherpa-onnx\n",
            "[ 79%] \u001b[32mBuilding CXX object sherpa-onnx/c-api/CMakeFiles/sherpa-onnx-c-api.dir/c-api.cc.o\u001b[0m\n",
            "[ 80%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/sherpa-onnx-alsa\u001b[0m\n",
            "[ 80%] Built target sherpa-onnx-alsa\n",
            "[ 81%] \u001b[32mBuilding CXX object sherpa-onnx/python/csrc/CMakeFiles/_sherpa_onnx.dir/endpoint.cc.o\u001b[0m\n",
            "[ 82%] \u001b[32m\u001b[1mLinking CXX shared library ../../lib/libsherpa-onnx-c-api.so\u001b[0m\n",
            "[ 82%] Built target sherpa-onnx-c-api\n",
            "[ 83%] \u001b[32mBuilding CXX object sherpa-onnx/python/csrc/CMakeFiles/_sherpa_onnx.dir/features.cc.o\u001b[0m\n",
            "[ 84%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-offline-websocket-server.dir/offline-websocket-server.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-online-websocket-server.dir/online-websocket-server.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object sherpa-onnx/python/csrc/CMakeFiles/_sherpa_onnx.dir/offline-lm-config.cc.o\u001b[0m\n",
            "[ 86%] \u001b[32mBuilding CXX object sherpa-onnx/python/csrc/CMakeFiles/_sherpa_onnx.dir/offline-model-config.cc.o\u001b[0m\n",
            "[ 87%] \u001b[32mBuilding CXX object sherpa-onnx/python/csrc/CMakeFiles/_sherpa_onnx.dir/offline-nemo-enc-dec-ctc-model-config.cc.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object sherpa-onnx/python/csrc/CMakeFiles/_sherpa_onnx.dir/offline-paraformer-model-config.cc.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding C object c-api-examples/CMakeFiles/decode-file-c-api.dir/decode-file-c-api.c.o\u001b[0m\n",
            "[ 89%] \u001b[32m\u001b[1mLinking C executable ../bin/decode-file-c-api\u001b[0m\n",
            "[ 89%] Built target decode-file-c-api\n",
            "[ 89%] \u001b[32mBuilding CXX object sherpa-onnx/python/csrc/CMakeFiles/_sherpa_onnx.dir/offline-recognizer.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object sherpa-onnx/python/csrc/CMakeFiles/_sherpa_onnx.dir/offline-stream.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object sherpa-onnx/python/csrc/CMakeFiles/_sherpa_onnx.dir/offline-tdnn-model-config.cc.o\u001b[0m\n",
            "[ 92%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/sherpa-onnx-online-websocket-server\u001b[0m\n",
            "[ 92%] Built target sherpa-onnx-online-websocket-server\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/sherpa-onnx-offline-websocket-server\u001b[0m\n",
            "[ 94%] \u001b[32mBuilding CXX object sherpa-onnx/python/csrc/CMakeFiles/_sherpa_onnx.dir/offline-transducer-model-config.cc.o\u001b[0m\n",
            "[ 94%] Built target sherpa-onnx-offline-websocket-server\n",
            "[ 94%] \u001b[32mBuilding CXX object sherpa-onnx/python/csrc/CMakeFiles/_sherpa_onnx.dir/offline-whisper-model-config.cc.o\u001b[0m\n",
            "[ 94%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/sherpa-onnx-online-websocket-client\u001b[0m\n",
            "[ 94%] Built target sherpa-onnx-online-websocket-client\n",
            "[ 95%] \u001b[32mBuilding CXX object sherpa-onnx/python/csrc/CMakeFiles/_sherpa_onnx.dir/online-lm-config.cc.o\u001b[0m\n",
            "[ 96%] \u001b[32mBuilding CXX object sherpa-onnx/python/csrc/CMakeFiles/_sherpa_onnx.dir/online-model-config.cc.o\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object sherpa-onnx/python/csrc/CMakeFiles/_sherpa_onnx.dir/online-paraformer-model-config.cc.o\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object sherpa-onnx/python/csrc/CMakeFiles/_sherpa_onnx.dir/online-recognizer.cc.o\u001b[0m\n",
            "[ 98%] \u001b[32mBuilding CXX object sherpa-onnx/python/csrc/CMakeFiles/_sherpa_onnx.dir/online-stream.cc.o\u001b[0m\n",
            "[ 99%] \u001b[32mBuilding CXX object sherpa-onnx/python/csrc/CMakeFiles/_sherpa_onnx.dir/online-transducer-model-config.cc.o\u001b[0m\n",
            "[100%] \u001b[32mBuilding CXX object sherpa-onnx/python/csrc/CMakeFiles/_sherpa_onnx.dir/sherpa-onnx.cc.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX shared module ../../../lib/_sherpa_onnx.cpython-310-x86_64-linux-gnu.so\u001b[0m\n",
            "lto-wrapper: warning: using serial compilation of 7 LTRANS jobs\n",
            "[100%] Built target _sherpa_onnx\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "%%shell\n",
        "\n",
        "\n",
        "git clone https://github.com/k2-fsa/sherpa-onnx\n",
        "cd sherpa-onnx\n",
        "mkdir build\n",
        "cd build\n",
        "cmake \\\n",
        "  -DCMAKE_BUILD_TYPE=Release \\\n",
        "  -DBUILD_SHARED_LIBS=ON \\\n",
        "  -DSHERPA_ONNX_ENABLE_GPU=ON \\\n",
        "  -DSHERPA_ONNX_ENABLE_PYTHON=ON ..\n",
        "make -j6\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check that `sherpa-onnx` is built successfully:"
      ],
      "metadata": {
        "id": "ajVAcvghMKjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "export PATH=$PWD/sherpa-onnx/build/bin:$PATH\n",
        "export PYTHONPATH=$PWD/sherpa-onnx/build/lib:$PYTHONPATH\n",
        "export PYTHONPATH=$PWD/sherpa-onnx/sherpa-onnx/python:$PYTHONPATH\n",
        "\n",
        "python3 -c \"import sherpa_onnx; print(sherpa_onnx.__file__)\"\n",
        "\n",
        "sherpa-onnx --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f1LRhuKL2v-",
        "outputId": "d361b1ea-6426-4d45-aa65-3f14010bab5f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/python/sherpa_onnx/__init__.py\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:PrintUsage:402 \n",
            "\n",
            "Usage:\n",
            "\n",
            "  ./bin/sherpa-onnx \\\n",
            "    --tokens=/path/to/tokens.txt \\\n",
            "    --encoder=/path/to/encoder.onnx \\\n",
            "    --decoder=/path/to/decoder.onnx \\\n",
            "    --joiner=/path/to/joiner.onnx \\\n",
            "    --provider=cpu \\\n",
            "    --num-threads=2 \\\n",
            "    --decoding-method=greedy_search \\\n",
            "    /path/to/foo.wav [bar.wav foobar.wav ...]\n",
            "\n",
            "Note: It supports decoding multiple files in batches\n",
            "\n",
            "Default value for num_threads is 2.\n",
            "Valid values for decoding_method: greedy_search (default), modified_beam_search.\n",
            "Valid values for provider: cpu (default), cuda, coreml.\n",
            "foo.wav should be of single channel, 16-bit PCM encoded wave file; its\n",
            "sampling rate can be arbitrary and does not need to be 16kHz.\n",
            "\n",
            "Please refer to\n",
            "https://k2-fsa.github.io/sherpa/onnx/pretrained_models/index.html\n",
            "for a list of pre-trained models to download.\n",
            "\n",
            "Options:\n",
            "  --max-active-paths          : beam size used in modified beam search. (int, default = 4)\n",
            "  --debug                     : true to print model information while loading it. (bool, default = false)\n",
            "  --decoding-method           : decoding method,now support greedy_search and modified_beam_search. (string, default = \"greedy_search\")\n",
            "  --tokens                    : Path to tokens.txt (string, default = \"\")\n",
            "  --rule2-must-contain-nonsilence : If True, for this endpointing rule2 to apply there must be nonsilence in the best-path traceback. For decoding, a non-blank token is considered as non-silence (bool, default = true)\n",
            "  --num-threads               : Number of threads to run the neural network (int, default = 1)\n",
            "  --encoder                   : Path to encoder.onnx (string, default = \"\")\n",
            "  --sample-rate               : Sampling rate of the input waveform. Note: You can have a different sample rate for the input waveform. We will do resampling inside the feature extractor (int, default = 16000)\n",
            "  --paraformer-decoder        : Path to decoder.onnx of paraformer. (string, default = \"\")\n",
            "  --rule3-min-trailing-silence : This endpointing rule3 requires duration of trailing silence in seconds) to be >= this value. (float, default = 0)\n",
            "  --lm-num-threads            : Number of threads to run the neural network of LM model (int, default = 1)\n",
            "  --decoder                   : Path to decoder.onnx (string, default = \"\")\n",
            "  --rule3-must-contain-nonsilence : If True, for this endpointing rule3 to apply there must be nonsilence in the best-path traceback. For decoding, a non-blank token is considered as non-silence (bool, default = false)\n",
            "  --joiner                    : Path to joiner.onnx (string, default = \"\")\n",
            "  --provider                  : Specify a provider to use: cpu, cuda, coreml (string, default = \"cpu\")\n",
            "  --model-type                : Specify it to reduce model initialization time. Valid values are: conformer, lstm, zipformer, zipformer2.All other values lead to loading the model twice. (string, default = \"\")\n",
            "  --feat-dim                  : Feature dimension. Must match the one expected by the model. (int, default = 80)\n",
            "  --rule1-must-contain-nonsilence : If True, for this endpointing rule1 to apply there must be nonsilence in the best-path traceback. For decoding, a non-blank token is considered as non-silence (bool, default = false)\n",
            "  --lm                        : Path to LM model. (string, default = \"\")\n",
            "  --paraformer-encoder        : Path to encoder.onnx of paraformer. (string, default = \"\")\n",
            "  --rule1-min-utterance-length : This endpointing rule1 requires utterance-length (in seconds) to be >= this value. (float, default = 0)\n",
            "  --rule2-min-trailing-silence : This endpointing rule2 requires duration of trailing silence in seconds) to be >= this value. (float, default = 1.2)\n",
            "  --context-score             : The bonus score for each token in context word/phrase. Used only when decoding_method is modified_beam_search (float, default = 1.5)\n",
            "  --rule2-min-utterance-length : This endpointing rule2 requires utterance-length (in seconds) to be >= this value. (float, default = 0)\n",
            "  --lm-scale                  : LM scale. (float, default = 0.5)\n",
            "  --rule3-min-utterance-length : This endpointing rule3 requires utterance-length (in seconds) to be >= this value. (float, default = 20)\n",
            "  --lm-provider               : Specify a provider to LM model use: cpu, cuda, coreml (string, default = \"cpu\")\n",
            "  --rule1-min-trailing-silence : This endpointing rule1 requires duration of trailing silence in seconds) to be >= this value. (float, default = 2.4)\n",
            "  --enable-endpoint           : True to enable endpoint detection. False to disable it. (bool, default = true)\n",
            "\n",
            "Standard options:\n",
            "  --print-args                : Print the command line arguments (to stderr) (bool, default = true)\n",
            "  --help                      : Print out usage message (bool, default = false)\n",
            "  --config                    : Configuration file to read (this option may be repeated) (string, default = \"\")\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download pre-trained streaming paraformer model"
      ],
      "metadata": {
        "id": "-VLXEFCaOQi1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please see\n",
        "https://k2-fsa.github.io/sherpa/onnx/pretrained_models/online-paraformer/index.html\n",
        "for details"
      ],
      "metadata": {
        "id": "9JQgrnfcOUpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "sudo apt-get install git-lfs\n",
        "git clone https://huggingface.co/csukuangfj/sherpa-onnx-streaming-paraformer-bilingual-zh-en\n",
        "ls -lh sherpa-onnx-streaming-paraformer-bilingual-zh-en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCnBcCg2OYSc",
        "outputId": "687be70a-eb98-4b72-f0f4-b92b08bc1d00"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 16 not upgraded.\n",
            "Cloning into 'sherpa-onnx-streaming-paraformer-bilingual-zh-en'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 18 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (18/18), 949.80 KiB | 10.10 MiB/s, done.\n",
            "Filtering content: 100% (4/4), 1.02 GiB | 71.57 MiB/s, done.\n",
            "total 1.1G\n",
            "-rw-r--r-- 1 root root  69M Aug 14 13:26 decoder.int8.onnx\n",
            "-rw-r--r-- 1 root root 218M Aug 14 13:26 decoder.onnx\n",
            "-rw-r--r-- 1 root root 158M Aug 14 13:26 encoder.int8.onnx\n",
            "-rw-r--r-- 1 root root 607M Aug 14 13:26 encoder.onnx\n",
            "-rw-r--r-- 1 root root  415 Aug 14 13:26 README.md\n",
            "drwxr-xr-x 2 root root 4.0K Aug 14 13:26 test_wavs\n",
            "-rw-r--r-- 1 root root  74K Aug 14 13:26 tokens.txt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real-time factor (RTF) test"
      ],
      "metadata": {
        "id": "GuvVmCgzMwxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## float32 (CPU)"
      ],
      "metadata": {
        "id": "4HG6lZ6rMx1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "export PATH=$PWD/sherpa-onnx/build/bin:$PATH\n",
        "\n",
        "sherpa-onnx \\\n",
        "  --tokens=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/tokens.txt \\\n",
        "  --paraformer-encoder=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/encoder.onnx \\\n",
        "  --paraformer-decoder=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/decoder.onnx \\\n",
        "  --num-threads=1 \\\n",
        "  --provider=cpu \\\n",
        "  ./sherpa-onnx-streaming-paraformer-bilingual-zh-en/test_wavs/0.wav\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GokwvFtRMonH",
        "outputId": "ddc658c1-bd15-4306-a35f-c9d21f939a10"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 sherpa-onnx --tokens=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/tokens.txt --paraformer-encoder=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/encoder.onnx --paraformer-decoder=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/decoder.onnx --num-threads=1 --provider=cpu ./sherpa-onnx-streaming-paraformer-bilingual-zh-en/test_wavs/0.wav \n",
            "\n",
            "OnlineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OnlineModelConfig(transducer=OnlineTransducerModelConfig(encoder=\"\", decoder=\"\", joiner=\"\"), paraformer=OnlineParaformerModelConfig(encoder=\"./sherpa-onnx-streaming-paraformer-bilingual-zh-en/encoder.onnx\", decoder=\"./sherpa-onnx-streaming-paraformer-bilingual-zh-en/decoder.onnx\"), tokens=\"./sherpa-onnx-streaming-paraformer-bilingual-zh-en/tokens.txt\", num_threads=1, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OnlineLMConfig(model=\"\", scale=0.5), endpoint_config=EndpointConfig(rule1=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=2.4, min_utterance_length=0), rule2=EndpointRule(must_contain_nonsilence=True, min_trailing_silence=1.2, min_utterance_length=0), rule3=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20)), enable_endpoint=True, max_active_paths=4, context_score=1.5, decoding_method=\"greedy_search\")\n",
            "./sherpa-onnx-streaming-paraformer-bilingual-zh-en/test_wavs/0.wav\n",
            "Elapsed seconds: 3.7, Real time factor (RTF): 0.37\n",
            "昨天是 monday today day is 零八二 the day after tomorrow 是星期三\n",
            "{\"is_final\":false,\"segment\":0,\"start_time\":0.0,\"text\":\"昨天是 monday today day is 零八二 the day after tomorrow 是星期三\",\"timestamps\":\"[]\",\"tokens\":[\"昨\",\"天\",\"是\",\"mon@@\",\"day\",\"today\",\"day\",\"is\",\"零\",\"八\",\"二\",\"the\",\"day\",\"after\",\"tom@@\",\"or@@\",\"row\",\"是\",\"星\",\"期\",\"三\"]}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## float32 (GPU)"
      ],
      "metadata": {
        "id": "P2Mx6pRDOjuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "export PATH=$PWD/sherpa-onnx/build/bin:$PATH\n",
        "\n",
        "sherpa-onnx \\\n",
        "  --tokens=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/tokens.txt \\\n",
        "  --paraformer-encoder=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/encoder.onnx \\\n",
        "  --paraformer-decoder=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/decoder.onnx \\\n",
        "  --num-threads=1 \\\n",
        "  --provider=cuda \\\n",
        "  ./sherpa-onnx-streaming-paraformer-bilingual-zh-en/test_wavs/0.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTlwbBBSOM2-",
        "outputId": "461ed0cb-2b38-4c74-9caf-47146e1e47d4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 sherpa-onnx --tokens=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/tokens.txt --paraformer-encoder=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/encoder.onnx --paraformer-decoder=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/decoder.onnx --num-threads=1 --provider=cuda ./sherpa-onnx-streaming-paraformer-bilingual-zh-en/test_wavs/0.wav \n",
            "\n",
            "OnlineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OnlineModelConfig(transducer=OnlineTransducerModelConfig(encoder=\"\", decoder=\"\", joiner=\"\"), paraformer=OnlineParaformerModelConfig(encoder=\"./sherpa-onnx-streaming-paraformer-bilingual-zh-en/encoder.onnx\", decoder=\"./sherpa-onnx-streaming-paraformer-bilingual-zh-en/decoder.onnx\"), tokens=\"./sherpa-onnx-streaming-paraformer-bilingual-zh-en/tokens.txt\", num_threads=1, debug=False, provider=\"cuda\", model_type=\"\"), lm_config=OnlineLMConfig(model=\"\", scale=0.5), endpoint_config=EndpointConfig(rule1=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=2.4, min_utterance_length=0), rule2=EndpointRule(must_contain_nonsilence=True, min_trailing_silence=1.2, min_utterance_length=0), rule3=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20)), enable_endpoint=True, max_active_paths=4, context_score=1.5, decoding_method=\"greedy_search\")\n",
            "./sherpa-onnx-streaming-paraformer-bilingual-zh-en/test_wavs/0.wav\n",
            "Elapsed seconds: 4.8, Real time factor (RTF): 0.47\n",
            "昨天是 monday today day is 零八二 the day after tomorrow 是星期三\n",
            "{\"is_final\":false,\"segment\":0,\"start_time\":0.0,\"text\":\"昨天是 monday today day is 零八二 the day after tomorrow 是星期三\",\"timestamps\":\"[]\",\"tokens\":[\"昨\",\"天\",\"是\",\"mon@@\",\"day\",\"today\",\"day\",\"is\",\"零\",\"八\",\"二\",\"the\",\"day\",\"after\",\"tom@@\",\"or@@\",\"row\",\"是\",\"星\",\"期\",\"三\"]}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## int8 (CPU)"
      ],
      "metadata": {
        "id": "HSt0rbTsPU_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "export PATH=$PWD/sherpa-onnx/build/bin:$PATH\n",
        "\n",
        "sherpa-onnx \\\n",
        "  --tokens=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/tokens.txt \\\n",
        "  --paraformer-encoder=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/encoder.int8.onnx \\\n",
        "  --paraformer-decoder=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/decoder.int8.onnx \\\n",
        "  --num-threads=1 \\\n",
        "  --provider=cpu \\\n",
        "  ./sherpa-onnx-streaming-paraformer-bilingual-zh-en/test_wavs/0.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44t0NxrwOm5s",
        "outputId": "39eab6cf-d43c-4be3-d8d7-dbf793054a62"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 sherpa-onnx --tokens=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/tokens.txt --paraformer-encoder=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/encoder.int8.onnx --paraformer-decoder=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/decoder.int8.onnx --num-threads=1 --provider=cpu ./sherpa-onnx-streaming-paraformer-bilingual-zh-en/test_wavs/0.wav \n",
            "\n",
            "OnlineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OnlineModelConfig(transducer=OnlineTransducerModelConfig(encoder=\"\", decoder=\"\", joiner=\"\"), paraformer=OnlineParaformerModelConfig(encoder=\"./sherpa-onnx-streaming-paraformer-bilingual-zh-en/encoder.int8.onnx\", decoder=\"./sherpa-onnx-streaming-paraformer-bilingual-zh-en/decoder.int8.onnx\"), tokens=\"./sherpa-onnx-streaming-paraformer-bilingual-zh-en/tokens.txt\", num_threads=1, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OnlineLMConfig(model=\"\", scale=0.5), endpoint_config=EndpointConfig(rule1=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=2.4, min_utterance_length=0), rule2=EndpointRule(must_contain_nonsilence=True, min_trailing_silence=1.2, min_utterance_length=0), rule3=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20)), enable_endpoint=True, max_active_paths=4, context_score=1.5, decoding_method=\"greedy_search\")\n",
            "./sherpa-onnx-streaming-paraformer-bilingual-zh-en/test_wavs/0.wav\n",
            "Elapsed seconds: 2.8, Real time factor (RTF): 0.28\n",
            "昨天是 monday today day is 零八二 the day after tomorrow 是星期三\n",
            "{\"is_final\":false,\"segment\":0,\"start_time\":0.0,\"text\":\"昨天是 monday today day is 零八二 the day after tomorrow 是星期三\",\"timestamps\":\"[]\",\"tokens\":[\"昨\",\"天\",\"是\",\"mon@@\",\"day\",\"today\",\"day\",\"is\",\"零\",\"八\",\"二\",\"the\",\"day\",\"after\",\"tom@@\",\"or@@\",\"row\",\"是\",\"星\",\"期\",\"三\"]}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## int8 (GPU)"
      ],
      "metadata": {
        "id": "B8_rmfT7PjTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "export PATH=$PWD/sherpa-onnx/build/bin:$PATH\n",
        "\n",
        "sherpa-onnx \\\n",
        "  --tokens=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/tokens.txt \\\n",
        "  --paraformer-encoder=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/encoder.int8.onnx \\\n",
        "  --paraformer-decoder=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/decoder.int8.onnx \\\n",
        "  --num-threads=1 \\\n",
        "  --provider=cuda \\\n",
        "  ./sherpa-onnx-streaming-paraformer-bilingual-zh-en/test_wavs/0.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHwshqB9PbTE",
        "outputId": "d2878516-2ca2-4b07-b651-95909c942352"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 sherpa-onnx --tokens=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/tokens.txt --paraformer-encoder=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/encoder.int8.onnx --paraformer-decoder=./sherpa-onnx-streaming-paraformer-bilingual-zh-en/decoder.int8.onnx --num-threads=1 --provider=cuda ./sherpa-onnx-streaming-paraformer-bilingual-zh-en/test_wavs/0.wav \n",
            "\n",
            "OnlineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OnlineModelConfig(transducer=OnlineTransducerModelConfig(encoder=\"\", decoder=\"\", joiner=\"\"), paraformer=OnlineParaformerModelConfig(encoder=\"./sherpa-onnx-streaming-paraformer-bilingual-zh-en/encoder.int8.onnx\", decoder=\"./sherpa-onnx-streaming-paraformer-bilingual-zh-en/decoder.int8.onnx\"), tokens=\"./sherpa-onnx-streaming-paraformer-bilingual-zh-en/tokens.txt\", num_threads=1, debug=False, provider=\"cuda\", model_type=\"\"), lm_config=OnlineLMConfig(model=\"\", scale=0.5), endpoint_config=EndpointConfig(rule1=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=2.4, min_utterance_length=0), rule2=EndpointRule(must_contain_nonsilence=True, min_trailing_silence=1.2, min_utterance_length=0), rule3=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20)), enable_endpoint=True, max_active_paths=4, context_score=1.5, decoding_method=\"greedy_search\")\n",
            "./sherpa-onnx-streaming-paraformer-bilingual-zh-en/test_wavs/0.wav\n",
            "Elapsed seconds: 5.1, Real time factor (RTF): 0.51\n",
            "昨天是 monday today day is 零八二 the day after tomorrow 是星期三\n",
            "{\"is_final\":false,\"segment\":0,\"start_time\":0.0,\"text\":\"昨天是 monday today day is 零八二 the day after tomorrow 是星期三\",\"timestamps\":\"[]\",\"tokens\":[\"昨\",\"天\",\"是\",\"mon@@\",\"day\",\"today\",\"day\",\"is\",\"零\",\"八\",\"二\",\"the\",\"day\",\"after\",\"tom@@\",\"or@@\",\"row\",\"是\",\"星\",\"期\",\"三\"]}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please refer to\n",
        "https://github.com/k2-fsa/colab/blob/master/sherpa-onnx/sherpa_onnx_streaming_paraformer_cpu.ipynb\n",
        "for other use cases."
      ],
      "metadata": {
        "id": "X4_qCyMiPrtH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kz061zXGPnZa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}