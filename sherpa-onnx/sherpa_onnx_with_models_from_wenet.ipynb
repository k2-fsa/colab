{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN+IhuE4Nkfqgv7C+cDUmKn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k2-fsa/colab/blob/master/sherpa-onnx/sherpa_onnx_with_models_from_wenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "This colab notebooks shows how to use [sherpa-onnx](https://github.com/k2-fsa/sherpa-onnx) with models with\n",
        "[WeNet](https://github.com/wenet-e2e/wenet)."
      ],
      "metadata": {
        "id": "6oZpJxRWIMnw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please see\n",
        "\n",
        "https://k2-fsa.github.io/sherpa/onnx/pretrained_models/wenet/index.html\n",
        "\n",
        "for details"
      ],
      "metadata": {
        "id": "Q6UhkFk_OaQk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRuYZqO0IJBd",
        "outputId": "8ad665ac-8913-4f93-c741-e1ee52b70ee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sherpa-onnx'...\n",
            "remote: Enumerating objects: 4692, done.\u001b[K\n",
            "remote: Counting objects: 100% (1907/1907), done.\u001b[K\n",
            "remote: Compressing objects: 100% (553/553), done.\u001b[K\n",
            "remote: Total 4692 (delta 1508), reused 1462 (delta 1345), pack-reused 2785\u001b[K\n",
            "Receiving objects: 100% (4692/4692), 2.47 MiB | 8.86 MiB/s, done.\n",
            "Resolving deltas: 100% (2920/2920), done.\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- No CMAKE_BUILD_TYPE given, default to Release\n",
            "-- CMAKE_BUILD_TYPE: Release\n",
            "-- CMAKE_INSTALL_PREFIX: /usr/local\n",
            "-- BUILD_SHARED_LIBS OFF\n",
            "-- SHERPA_ONNX_ENABLE_PYTHON OFF\n",
            "-- SHERPA_ONNX_ENABLE_TESTS OFF\n",
            "-- SHERPA_ONNX_ENABLE_CHECK OFF\n",
            "-- SHERPA_ONNX_ENABLE_PORTAUDIO ON\n",
            "-- SHERPA_ONNX_ENABLE_JNI OFF\n",
            "-- SHERPA_ONNX_ENABLE_C_API ON\n",
            "-- SHERPA_ONNX_ENABLE_WEBSOCKET ON\n",
            "-- SHERPA_ONNX_ENABLE_GPU OFF\n",
            "-- C++ Standard version: 14\n",
            "-- Looking for C++ include alsa/asoundlib.h\n",
            "-- Looking for C++ include alsa/asoundlib.h - found\n",
            "-- Looking for C++ include cxxabi.h\n",
            "-- Looking for C++ include cxxabi.h - found\n",
            "-- Looking for C++ include execinfo.h\n",
            "-- Looking for C++ include execinfo.h - found\n",
            "-- Link libstdc++ statically\n",
            "-- Downloading kaldi-native-fbank from https://github.com/csukuangfj/kaldi-native-fbank/archive/refs/tags/v1.18.5.tar.gz\n",
            "-- kaldi-native-fbank is downloaded to /content/sherpa-onnx/build/_deps/kaldi_native_fbank-src\n",
            "-- kaldi-native-fbank's binary dir is /content/sherpa-onnx/build/_deps/kaldi_native_fbank-build\n",
            "\u001b[0mCMake Deprecation Warning at build/_deps/kaldi_native_fbank-src/CMakeLists.txt:24 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- CMAKE_BUILD_TYPE: Release\n",
            "-- CMAKE_EXPORT_COMPILE_COMMANDS: \n",
            "-- BUILD_SHARED_LIBS: OFF\n",
            "-- KALDI_NATIVE_FBANK_BUILD_TESTS: OFF\n",
            "-- KALDI_NATIVE_FBANK_BUILD_PYTHON: OFF\n",
            "-- KALDI_NATIVE_FBANK_ENABLE_CHECK: OFF\n",
            "-- KALDI_NATIVE_FBANK_ENABLE_CHECK: OFF\n",
            "-- CMAKE_CXX_FLAGS:   -static-libstdc++ -static-libgcc \n",
            "-- CMAKE_INSTALL_PREFIX: /usr/local\n",
            "-- Looking for C++ include cxxabi.h\n",
            "-- Looking for C++ include cxxabi.h - found\n",
            "-- Looking for C++ include execinfo.h\n",
            "-- Looking for C++ include execinfo.h - found\n",
            "-- Disable building Python\n",
            "-- Downloading kaldi-decoder from https://github.com/k2-fsa/kaldi-decoder/archive/refs/tags/v0.2.3.tar.gz\n",
            "-- kaldi-decoder is downloaded to /content/sherpa-onnx/build/_deps/kaldi_decoder-src\n",
            "-- kaldi-decoder's binary dir is /content/sherpa-onnx/build/_deps/kaldi_decoder-build\n",
            "-- CMAKE_BUILD_TYPE: Release\n",
            "-- Downloading kaldifst from https://github.com/k2-fsa/kaldifst/archive/refs/tags/v1.7.9.tar.gz\n",
            "-- kaldifst is downloaded to /content/sherpa-onnx/build/_deps/kaldifst-src\n",
            "-- kaldifst's binary dir is /content/sherpa-onnx/build/_deps/kaldifst-build\n",
            "-- CMAKE_BUILD_TYPE: Release\n",
            "-- CMAKE_BUILD_TYPE: Release\n",
            "-- CMAKE_INSTALL_PREFIX: /usr/local\n",
            "-- BUILD_SHARED_LIBS OFF\n",
            "-- C++ Standard version: 14\n",
            "-- CMAKE_CXX_FLAGS:   -static-libstdc++ -static-libgcc \n",
            "\u001b[33mCMake Warning (dev) at /usr/local/lib/python3.10/dist-packages/cmake/data/share/cmake-3.27/Modules/FetchContent.cmake:1316 (message):\n",
            "  The DOWNLOAD_EXTRACT_TIMESTAMP option was not given and policy CMP0135 is\n",
            "  not set.  The policy's OLD behavior will be used.  When using a URL\n",
            "  download, the timestamps of extracted files should preferably be that of\n",
            "  the time of extraction, otherwise code that depends on the extracted\n",
            "  contents might not be rebuilt if the URL changes.  The OLD behavior\n",
            "  preserves the timestamps from the archive instead, but this is usually not\n",
            "  what you want.  Update your project to the NEW behavior or specify the\n",
            "  DOWNLOAD_EXTRACT_TIMESTAMP option with a value of true to avoid this\n",
            "  robustness issue.\n",
            "Call Stack (most recent call first):\n",
            "  build/_deps/kaldifst-src/cmake/openfst.cmake:45 (FetchContent_Declare)\n",
            "  build/_deps/kaldifst-src/cmake/openfst.cmake:89 (download_openfst)\n",
            "  build/_deps/kaldifst-src/CMakeLists.txt:87 (include)\n",
            "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\u001b[0m\n",
            "-- Downloading openfst from https://github.com/kkm000/openfst/archive/refs/tags/win/1.6.5.1.tar.gz\n",
            "-- openfst is downloaded to /content/sherpa-onnx/build/_deps/openfst-src\n",
            "-- Found the following ICU libraries:\n",
            "--   data (required): /usr/lib/x86_64-linux-gnu/libicudata.so\n",
            "--   i18n (required): /usr/lib/x86_64-linux-gnu/libicui18n.so\n",
            "--   io (required): /usr/lib/x86_64-linux-gnu/libicuio.so\n",
            "--   test (required): /usr/lib/x86_64-linux-gnu/libicutest.so\n",
            "--   tu (required): /usr/lib/x86_64-linux-gnu/libicutu.so\n",
            "--   uc (required): /usr/lib/x86_64-linux-gnu/libicuuc.so\n",
            "-- Found ICU: /usr/include (found version \"70.1\") \n",
            "-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\")  \n",
            "\u001b[0mCMake Deprecation Warning at build/_deps/openfst-src/CMakeLists.txt:15 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- Downloading eigen from https://gitlab.com/libeigen/eigen/-/archive/3.4.0/eigen-3.4.0.tar.gz\n",
            "-- eigen is downloaded to /content/sherpa-onnx/build/_deps/eigen-src\n",
            "-- eigen's binary dir is /content/sherpa-onnx/build/_deps/eigen-build\n",
            "-- Performing Test EIGEN_COMPILER_SUPPORT_CPP11\n",
            "-- Performing Test EIGEN_COMPILER_SUPPORT_CPP11 - Success\n",
            "-- Performing Test COMPILER_SUPPORT_std=cpp03\n",
            "-- Performing Test COMPILER_SUPPORT_std=cpp03 - Success\n",
            "-- Performing Test standard_math_library_linked_to_automatically\n",
            "-- Performing Test standard_math_library_linked_to_automatically - Success\n",
            "-- Standard libraries to link to explicitly: none\n",
            "-- Performing Test COMPILER_SUPPORT_WERROR\n",
            "-- Performing Test COMPILER_SUPPORT_WERROR - Success\n",
            "-- Performing Test COMPILER_SUPPORT_pedantic\n",
            "-- Performing Test COMPILER_SUPPORT_pedantic - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wall\n",
            "-- Performing Test COMPILER_SUPPORT_Wall - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wextra\n",
            "-- Performing Test COMPILER_SUPPORT_Wextra - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wundef\n",
            "-- Performing Test COMPILER_SUPPORT_Wundef - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wcastalign\n",
            "-- Performing Test COMPILER_SUPPORT_Wcastalign - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wcharsubscripts\n",
            "-- Performing Test COMPILER_SUPPORT_Wcharsubscripts - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wnonvirtualdtor\n",
            "-- Performing Test COMPILER_SUPPORT_Wnonvirtualdtor - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wunusedlocaltypedefs\n",
            "-- Performing Test COMPILER_SUPPORT_Wunusedlocaltypedefs - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wpointerarith\n",
            "-- Performing Test COMPILER_SUPPORT_Wpointerarith - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wwritestrings\n",
            "-- Performing Test COMPILER_SUPPORT_Wwritestrings - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wformatsecurity\n",
            "-- Performing Test COMPILER_SUPPORT_Wformatsecurity - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wshorten64to32\n",
            "-- Performing Test COMPILER_SUPPORT_Wshorten64to32 - Failed\n",
            "-- Performing Test COMPILER_SUPPORT_Wlogicalop\n",
            "-- Performing Test COMPILER_SUPPORT_Wlogicalop - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wenumconversion\n",
            "-- Performing Test COMPILER_SUPPORT_Wenumconversion - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wcpp11extensions\n",
            "-- Performing Test COMPILER_SUPPORT_Wcpp11extensions - Failed\n",
            "-- Performing Test COMPILER_SUPPORT_Wdoublepromotion\n",
            "-- Performing Test COMPILER_SUPPORT_Wdoublepromotion - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wshadow\n",
            "-- Performing Test COMPILER_SUPPORT_Wshadow - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wnopsabi\n",
            "-- Performing Test COMPILER_SUPPORT_Wnopsabi - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wnovariadicmacros\n",
            "-- Performing Test COMPILER_SUPPORT_Wnovariadicmacros - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wnolonglong\n",
            "-- Performing Test COMPILER_SUPPORT_Wnolonglong - Success\n",
            "-- Performing Test COMPILER_SUPPORT_fnochecknew\n",
            "-- Performing Test COMPILER_SUPPORT_fnochecknew - Success\n",
            "-- Performing Test COMPILER_SUPPORT_fnocommon\n",
            "-- Performing Test COMPILER_SUPPORT_fnocommon - Success\n",
            "-- Performing Test COMPILER_SUPPORT_fstrictaliasing\n",
            "-- Performing Test COMPILER_SUPPORT_fstrictaliasing - Success\n",
            "-- Performing Test COMPILER_SUPPORT_wd981\n",
            "-- Performing Test COMPILER_SUPPORT_wd981 - Failed\n",
            "-- Performing Test COMPILER_SUPPORT_wd2304\n",
            "-- Performing Test COMPILER_SUPPORT_wd2304 - Failed\n",
            "-- Performing Test COMPILER_SUPPORT_STRICTANSI\n",
            "-- Performing Test COMPILER_SUPPORT_STRICTANSI - Failed\n",
            "-- Performing Test COMPILER_SUPPORT_Qunusedarguments\n",
            "-- Performing Test COMPILER_SUPPORT_Qunusedarguments - Failed\n",
            "-- Performing Test COMPILER_SUPPORT_ansi\n",
            "-- Performing Test COMPILER_SUPPORT_ansi - Success\n",
            "-- Performing Test COMPILER_SUPPORT_OPENMP\n",
            "-- Performing Test COMPILER_SUPPORT_OPENMP - Success\n",
            "-- Looking for a Fortran compiler\n",
            "-- Looking for a Fortran compiler - /usr/bin/f95\n",
            "-- The Fortran compiler identification is GNU 11.4.0\n",
            "-- Detecting Fortran compiler ABI info\n",
            "-- Detecting Fortran compiler ABI info - done\n",
            "-- Check for working Fortran compiler: /usr/bin/f95 - skipped\n",
            "-- Found unsuitable Qt version \"\" from NOTFOUND\n",
            "-- Qt4 not found, so disabling the mandelbrot and opengl demos\n",
            "-- Could NOT find CHOLMOD (missing: CHOLMOD_INCLUDES CHOLMOD_LIBRARIES) \n",
            "-- Could NOT find UMFPACK (missing: UMFPACK_INCLUDES UMFPACK_LIBRARIES) \n",
            "-- Could NOT find KLU (missing: KLU_INCLUDES KLU_LIBRARIES) \n",
            "-- Performing Test SUPERLU_HAS_GLOBAL_MEM_USAGE_T\n",
            "-- Performing Test SUPERLU_HAS_GLOBAL_MEM_USAGE_T - Success\n",
            "-- Performing Test SUPERLU_HAS_CLEAN_ENUMS\n",
            "-- Performing Test SUPERLU_HAS_CLEAN_ENUMS - Success\n",
            "-- Performing Test SUPERLU_HAS_GLOBALLU_T\n",
            "-- Performing Test SUPERLU_HAS_GLOBALLU_T - Success\n",
            "-- Found SuperLU: /usr/include/superlu (found suitable version \"5.0\", minimum required is \"4.0\") \n",
            "-- Checking for one of the modules 'hwloc'\n",
            "-- Performing Test HAVE_HWLOC_PARENT_MEMBER\n",
            "-- Performing Test HAVE_HWLOC_PARENT_MEMBER - Success\n",
            "-- Performing Test HAVE_HWLOC_CACHE_ATTR\n",
            "-- Performing Test HAVE_HWLOC_CACHE_ATTR - Success\n",
            "-- Performing Test HAVE_HWLOC_OBJ_PU\n",
            "-- Performing Test HAVE_HWLOC_OBJ_PU - Success\n",
            "-- Looking for hwloc_bitmap_free in hwloc\n",
            "-- Looking for hwloc_bitmap_free in hwloc - found\n",
            "-- A version of Pastix has been found but pastix_nompi.h does not exist in the include directory. Because Eigen tests require a version without MPI, we disable the Pastix backend.\n",
            "-- \n",
            "-- Configured Eigen 3.4.0\n",
            "-- \n",
            "-- Available targets (use: make TARGET):\n",
            "-- ---------+--------------------------------------------------------------\n",
            "-- Target   |   Description\n",
            "-- ---------+--------------------------------------------------------------\n",
            "-- install  | Install Eigen. Headers will be installed to:\n",
            "--          |     <CMAKE_INSTALL_PREFIX>/<INCLUDE_INSTALL_DIR>\n",
            "--          |   Using the following values:\n",
            "--          |     CMAKE_INSTALL_PREFIX: /usr/local\n",
            "--          |     INCLUDE_INSTALL_DIR:  include/eigen3\n",
            "--          |   Change the install location of Eigen headers using:\n",
            "--          |     cmake . -DCMAKE_INSTALL_PREFIX=yourprefix\n",
            "--          |   Or:\n",
            "--          |     cmake . -DINCLUDE_INSTALL_DIR=yourdir\n",
            "-- doc      | Generate the API documentation, requires Doxygen & LaTeX\n",
            "-- blas     | Build BLAS library (not the same thing as Eigen)\n",
            "-- uninstall| Remove files installed by the install target\n",
            "-- ---------+--------------------------------------------------------------\n",
            "-- \n",
            "-- CMAKE_SYSTEM_NAME: Linux\n",
            "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "-- location_onnxruntime_header_dir: location_onnxruntime_header_dir-NOTFOUND\n",
            "-- location_onnxruntime_lib: location_onnxruntime_lib-NOTFOUND\n",
            "-- Could not find a pre-installed onnxruntime. Downloading pre-compiled onnxruntime\n",
            "-- CMAKE_SYSTEM_NAME: Linux\n",
            "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "-- CMAKE_SYSTEM_NAME: Linux\n",
            "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "-- Downloading onnxruntime from https://github.com/csukuangfj/onnxruntime-libs/releases/download/v1.16.2/onnxruntime-linux-x64-static_lib-1.16.2.zip\n",
            "-- onnxruntime is downloaded to /content/sherpa-onnx/build/_deps/onnxruntime-src\n",
            "-- onnxruntime lib files: /content/sherpa-onnx/build/_deps/onnxruntime-src/lib/libonnxruntime.a\n",
            "-- Downloading portaudio from http://files.portaudio.com/archives/pa_stable_v190700_20210406.tgz\n",
            "-- portaudio is downloaded to /content/sherpa-onnx/build/_deps/portaudio-src\n",
            "-- portaudio's binary dir is /content/sherpa-onnx/build/_deps/portaudio-build\n",
            "\u001b[0mCMake Deprecation Warning at build/_deps/portaudio-src/CMakeLists.txt:7 (CMAKE_MINIMUM_REQUIRED):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- Found ALSA: /usr/lib/x86_64-linux-gnu/libasound.so (found version \"1.2.6.1\") \n",
            "-- Downloading websocketpp from https://github.com/zaphoyd/websocketpp/archive/b9aeec6eaf3d5610503439b4fae3581d9aff08e8.zip\n",
            "-- websocketpp is downloaded to /content/sherpa-onnx/build/_deps/websocketpp-src\n",
            "-- Downloading asio https://github.com/chriskohlhoff/asio/archive/refs/tags/asio-1-24-0.tar.gz\n",
            "-- asio is downloaded to /content/sherpa-onnx/build/_deps/asio-src\n",
            "-- Downloading cargs https://github.com/likle/cargs/archive/refs/tags/v1.0.3.tar.gz\n",
            "-- cargs is downloaded to /content/sherpa-onnx/build/_deps/cargs-src\n",
            "-- CMAKE_CXX_FLAGS:   -static-libstdc++ -static-libgcc \n",
            "-- CMAKE_CXX_FLAGS:   -static-libstdc++ -static-libgcc \n",
            "-- Configuring done (14.1s)\n",
            "-- Generating done (0.2s)\n",
            "-- Build files have been written to: /content/sherpa-onnx/build\n",
            "[  0%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/feature-fbank.cc.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object _deps/openfst-build/src/lib/CMakeFiles/fst.dir/compat.cc.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object _deps/openfst-build/src/lib/CMakeFiles/fst.dir/flags.cc.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding C object _deps/cargs-build/CMakeFiles/cargs.dir/src/cargs.c.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object _deps/openfst-build/src/lib/CMakeFiles/fst.dir/fst.cc.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/feature-window.cc.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/feature-functions.cc.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/fftsg.cc.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object _deps/openfst-build/src/lib/CMakeFiles/fst.dir/properties.cc.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio_static.dir/src/common/pa_allocation.c.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio_static.dir/src/common/pa_converters.c.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object _deps/openfst-build/src/lib/CMakeFiles/fst.dir/symbol-table.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/mel-computations.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio_static.dir/src/common/pa_cpuload.c.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio_static.dir/src/common/pa_debugprint.c.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/online-feature.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio_static.dir/src/common/pa_dither.c.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/rfft.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object _deps/openfst-build/src/lib/CMakeFiles/fst.dir/util.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object _deps/openfst-build/src/lib/CMakeFiles/fst.dir/symbol-table-ops.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/whisper-feature.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object _deps/openfst-build/src/lib/CMakeFiles/fst.dir/mapped-file.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object _deps/openfst-build/src/lib/CMakeFiles/fst.dir/weight.cc.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio_static.dir/src/common/pa_front.c.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio_static.dir/src/common/pa_process.c.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio_static.dir/src/common/pa_ringbuffer.c.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio_static.dir/src/common/pa_stream.c.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio_static.dir/src/common/pa_trace.c.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio_static.dir/src/hostapi/skeleton/pa_hostapi_skeleton.c.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio_static.dir/src/os/unix/pa_unix_hostapis.c.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio_static.dir/src/os/unix/pa_unix_util.c.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio_static.dir/src/hostapi/jack/pa_jack.c.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding C object _deps/portaudio-build/CMakeFiles/portaudio_static.dir/src/hostapi/alsa/pa_linux_alsa.c.o\u001b[0m\n",
            "[ 18%] \u001b[32m\u001b[1mLinking C static library ../../lib/libcargs.a\u001b[0m\n",
            "[ 18%] Built target cargs\n",
            "\u001b[01m\u001b[K/content/sherpa-onnx/build/_deps/portaudio-src/src/hostapi/alsa/pa_linux_alsa.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KBuildDeviceList.constprop\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/sherpa-onnx/build/_deps/portaudio-src/src/hostapi/alsa/pa_linux_alsa.c:1304:45:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K%s\u001b[m\u001b[K’ directive output may be truncated writing up to 49 bytes into a region of size between 46 and 50 [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wformat-truncation=\u0007-Wformat-truncation=\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            " 1304 |             snprintf( buf, sizeof (buf), \"%s\u001b[01;35m\u001b[K%s\u001b[m\u001b[K,%d\", hwPrefix, \u001b[32m\u001b[KalsaCardName\u001b[m\u001b[K, devIdx );\n",
            "      |                                             \u001b[01;35m\u001b[K^~\u001b[m\u001b[K                \u001b[32m\u001b[K~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/sherpa-onnx/build/_deps/portaudio-src/src/hostapi/alsa/pa_linux_alsa.c:1304:42:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdirective argument in the range [0, 2147483647]\n",
            " 1304 |             snprintf( buf, sizeof (buf), \u001b[01;36m\u001b[K\"%s%s,%d\"\u001b[m\u001b[K, hwPrefix, alsaCardName, devIdx );\n",
            "      |                                          \u001b[01;36m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/include/stdio.h:894\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/include/alsa/asoundlib.h:32\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sherpa-onnx/build/_deps/portaudio-src/src/hostapi/alsa/pa_linux_alsa.c:52\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/include/x86_64-linux-gnu/bits/stdio2.h:71:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K‘\u001b[01m\u001b[K__builtin___snprintf_chk\u001b[m\u001b[K’ output between 3 and 65 bytes into a destination of size 50\n",
            "   71 |   return \u001b[01;36m\u001b[K__builtin___snprintf_chk (__s, __n, __USE_FORTIFY_LEVEL - 1,\u001b[m\u001b[K\n",
            "      |          \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "   72 | \u001b[01;36m\u001b[K                                   __glibc_objsize (__s), __fmt,\u001b[m\u001b[K\n",
            "      |                                    \u001b[01;36m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "   73 | \u001b[01;36m\u001b[K                                   __va_arg_pack ())\u001b[m\u001b[K;\n",
            "      |                                    \u001b[01;36m\u001b[K~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "[ 18%] \u001b[32m\u001b[1mLinking C static library ../../lib/libsherpa-onnx-portaudio_static.a\u001b[0m\n",
            "[ 18%] Built target portaudio_static\n",
            "[ 20%] \u001b[32m\u001b[1mLinking CXX static library ../../../../lib/libkaldi-native-fbank-core.a\u001b[0m\n",
            "[ 20%] Built target kaldi-native-fbank-core\n",
            "[ 20%] \u001b[32m\u001b[1mLinking CXX static library ../../../../lib/libsherpa-onnx-fst.a\u001b[0m\n",
            "[ 20%] Built target fst\n",
            "[ 20%] \u001b[32mBuilding CXX object _deps/kaldifst-build/kaldifst/csrc/CMakeFiles/kaldifst_core.dir/kaldi-holder.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object _deps/kaldifst-build/kaldifst/csrc/CMakeFiles/kaldifst_core.dir/context-fst.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object _deps/kaldifst-build/kaldifst/csrc/CMakeFiles/kaldifst_core.dir/kaldi-fst-io.cc.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object _deps/kaldifst-build/kaldifst/csrc/CMakeFiles/kaldifst_core.dir/kaldi-io.cc.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object _deps/kaldifst-build/kaldifst/csrc/CMakeFiles/kaldifst_core.dir/kaldi-math.cc.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object _deps/kaldifst-build/kaldifst/csrc/CMakeFiles/kaldifst_core.dir/kaldi-semaphore.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object _deps/kaldifst-build/kaldifst/csrc/CMakeFiles/kaldifst_core.dir/kaldi-table.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object _deps/kaldifst-build/kaldifst/csrc/CMakeFiles/kaldifst_core.dir/parse-options.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object _deps/kaldifst-build/kaldifst/csrc/CMakeFiles/kaldifst_core.dir/text-normalizer.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object _deps/kaldifst-build/kaldifst/csrc/CMakeFiles/kaldifst_core.dir/text-utils.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32m\u001b[1mLinking CXX static library ../../../../lib/libsherpa-onnx-kaldifst-core.a\u001b[0m\n",
            "[ 27%] Built target kaldifst_core\n",
            "[ 27%] \u001b[32mBuilding CXX object _deps/kaldi_decoder-build/kaldi-decoder/csrc/CMakeFiles/kaldi-decoder-core.dir/decodable-ctc.cc.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object _deps/kaldi_decoder-build/kaldi-decoder/csrc/CMakeFiles/kaldi-decoder-core.dir/eigen.cc.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object _deps/kaldi_decoder-build/kaldi-decoder/csrc/CMakeFiles/kaldi-decoder-core.dir/faster-decoder.cc.o\u001b[0m\n",
            "[ 29%] \u001b[32m\u001b[1mLinking CXX static library ../../../../lib/libkaldi-decoder-core.a\u001b[0m\n",
            "[ 29%] Built target kaldi-decoder-core\n",
            "[ 31%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/base64-decode.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/circular-buffer.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/cat.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/context-graph.cc.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/endpoint.cc.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/features.cc.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/file-utils.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/hypothesis.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-ctc-fst-decoder-config.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-ctc-fst-decoder.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-ctc-greedy-search-decoder.cc.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-ctc-model.cc.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-lm.cc.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-lm-config.cc.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-model-config.cc.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-nemo-enc-dec-ctc-model-config.cc.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-nemo-enc-dec-ctc-model.cc.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-paraformer-greedy-search-decoder.cc.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-paraformer-model-config.cc.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-paraformer-model.cc.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-recognizer-impl.cc.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-recognizer.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-rnn-lm.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-stream.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-tdnn-model-config.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-tdnn-ctc-model.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-transducer-model-config.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-transducer-greedy-search-decoder.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-transducer-model.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-transducer-modified-beam-search-decoder.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-wenet-ctc-model-config.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-wenet-ctc-model.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-whisper-greedy-search-decoder.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-whisper-model-config.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-whisper-model.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-zipformer-ctc-model-config.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-zipformer-ctc-model.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-conformer-transducer-model.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-ctc-greedy-search-decoder.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-ctc-model.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-lm-config.cc.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-lm.cc.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-lstm-transducer-model.cc.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-model-config.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-paraformer-model-config.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-paraformer-model.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-recognizer-impl.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-recognizer.cc.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-rnn-lm.cc.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-stream.cc.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-transducer-decoder.cc.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-transducer-greedy-search-decoder.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-transducer-model-config.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-transducer-model.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-transducer-modified-beam-search-decoder.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-wenet-ctc-model-config.cc.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-wenet-ctc-model.cc.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-zipformer-transducer-model.cc.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-zipformer2-transducer-model.cc.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/onnx-utils.cc.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/packed-sequence.cc.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/pad-sequence.cc.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/parse-options.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/provider.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/resample.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/silero-vad-model-config.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/session.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/silero-vad-model.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/slice.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/stack.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/symbol-table.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/text-utils.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/transpose.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/unbind.cc.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/utils.cc.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/vad-model-config.cc.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/vad-model.cc.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/wave-reader.cc.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/voice-activity-detector.cc.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/lexicon.cc.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-tts-impl.cc.o\u001b[0m\n",
            "[ 77%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-tts-model-config.cc.o\u001b[0m\n",
            "[ 77%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-tts-vits-model-config.cc.o\u001b[0m\n",
            "[ 77%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-tts-vits-model.cc.o\u001b[0m\n",
            "[ 77%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-tts.cc.o\u001b[0m\n",
            "[ 79%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/wave-writer.cc.o\u001b[0m\n",
            "[ 79%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libsherpa-onnx-core.a\u001b[0m\n",
            "[ 79%] Built target sherpa-onnx-core\n",
            "[ 81%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx.dir/sherpa-onnx.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-offline.dir/sherpa-onnx-offline.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-offline-parallel.dir/sherpa-onnx-offline-parallel.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-alsa.dir/sherpa-onnx-alsa.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-offline-tts.dir/sherpa-onnx-offline-tts.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-microphone.dir/sherpa-onnx-microphone.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-alsa.dir/alsa.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-microphone.dir/microphone.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-microphone-offline.dir/sherpa-onnx-microphone-offline.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-microphone-offline.dir/microphone.cc.o\u001b[0m\n",
            "[ 87%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-vad-microphone.dir/sherpa-onnx-vad-microphone.cc.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-online-websocket-server.dir/online-websocket-server-impl.cc.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-online-websocket-server.dir/online-websocket-server.cc.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-vad-microphone.dir/microphone.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-vad-microphone-offline-asr.dir/microphone.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-vad-microphone-offline-asr.dir/sherpa-onnx-vad-microphone-offline-asr.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-online-websocket-client.dir/online-websocket-client.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-offline-websocket-server.dir/offline-websocket-server-impl.cc.o\u001b[0m\n",
            "[ 93%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-offline-websocket-server.dir/offline-websocket-server.cc.o\u001b[0m\n",
            "[ 93%] \u001b[32mBuilding CXX object sherpa-onnx/c-api/CMakeFiles/sherpa-onnx-c-api.dir/c-api.cc.o\u001b[0m\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/sherpa-onnx-offline-tts\u001b[0m\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/sherpa-onnx-vad-microphone\u001b[0m\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/sherpa-onnx-offline\u001b[0m\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/sherpa-onnx-vad-microphone-offline-asr\u001b[0m\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/sherpa-onnx-microphone-offline\u001b[0m\n",
            "[ 95%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/sherpa-onnx-microphone\u001b[0m\n",
            "[ 95%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/sherpa-onnx-alsa\u001b[0m\n",
            "[ 95%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/sherpa-onnx\u001b[0m\n",
            "[ 97%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/sherpa-onnx-offline-parallel\u001b[0m\n",
            "[ 97%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libsherpa-onnx-c-api.a\u001b[0m\n",
            "[ 97%] Built target sherpa-onnx-c-api\n",
            "[ 97%] \u001b[32mBuilding C object c-api-examples/CMakeFiles/decode-file-c-api.dir/decode-file-c-api.c.o\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding C object c-api-examples/CMakeFiles/offline-tts-c-api.dir/offline-tts-c-api.c.o\u001b[0m\n",
            "[ 97%] \u001b[32m\u001b[1mLinking CXX executable ../bin/offline-tts-c-api\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../bin/decode-file-c-api\u001b[0m\n",
            "[100%] Built target sherpa-onnx-vad-microphone\n",
            "[100%] Built target sherpa-onnx-offline-tts\n",
            "[100%] Built target sherpa-onnx-offline\n",
            "[100%] Built target sherpa-onnx-vad-microphone-offline-asr\n",
            "[100%] Built target sherpa-onnx-microphone-offline\n",
            "[100%] Built target sherpa-onnx-microphone\n",
            "[100%] Built target sherpa-onnx-alsa\n",
            "[100%] Built target sherpa-onnx\n",
            "[100%] Built target sherpa-onnx-offline-parallel\n",
            "[100%] Built target decode-file-c-api\n",
            "[100%] Built target offline-tts-c-api\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/sherpa-onnx-offline-websocket-server\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/sherpa-onnx-online-websocket-server\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/sherpa-onnx-online-websocket-client\u001b[0m\n",
            "[100%] Built target sherpa-onnx-online-websocket-client\n",
            "[100%] Built target sherpa-onnx-offline-websocket-server\n",
            "[100%] Built target sherpa-onnx-online-websocket-server\n",
            "total 317M\n",
            "-rwxr-xr-x 1 root root  26M Nov 16 03:49 decode-file-c-api\n",
            "-rwxr-xr-x 1 root root  26M Nov 16 03:49 offline-tts-c-api\n",
            "-rwxr-xr-x 1 root root  23M Nov 16 03:49 sherpa-onnx\n",
            "-rwxr-xr-x 1 root root  23M Nov 16 03:49 sherpa-onnx-alsa\n",
            "-rwxr-xr-x 1 root root  24M Nov 16 03:49 sherpa-onnx-microphone\n",
            "-rwxr-xr-x 1 root root  25M Nov 16 03:49 sherpa-onnx-microphone-offline\n",
            "-rwxr-xr-x 1 root root  25M Nov 16 03:49 sherpa-onnx-offline\n",
            "-rwxr-xr-x 1 root root  25M Nov 16 03:49 sherpa-onnx-offline-parallel\n",
            "-rwxr-xr-x 1 root root  25M Nov 16 03:49 sherpa-onnx-offline-tts\n",
            "-rwxr-xr-x 1 root root  25M Nov 16 03:50 sherpa-onnx-offline-websocket-server\n",
            "-rwxr-xr-x 1 root root 3.5M Nov 16 03:50 sherpa-onnx-online-websocket-client\n",
            "-rwxr-xr-x 1 root root  24M Nov 16 03:50 sherpa-onnx-online-websocket-server\n",
            "-rwxr-xr-x 1 root root  23M Nov 16 03:49 sherpa-onnx-vad-microphone\n",
            "-rwxr-xr-x 1 root root  25M Nov 16 03:49 sherpa-onnx-vad-microphone-offline-asr\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "%%shell\n",
        "\n",
        "# Install sherpa-onnx\n",
        "git clone https://github.com/k2-fsa/sherpa-onnx\n",
        "cd sherpa-onnx\n",
        "mkdir build\n",
        "cd build\n",
        "cmake ..\n",
        "make -j\n",
        "ls -lh bin"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sherpa-onnx-zh-wenet-aishell"
      ],
      "metadata": {
        "id": "eH5Tv8tqKQIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "git lfs install\n",
        "git clone https://huggingface.co/csukuangfj/sherpa-onnx-zh-wenet-aishell\n",
        "ls -lh sherpa-onnx-zh-wenet-aishell"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M549GQnTInNp",
        "outputId": "68152b57-1cc6-441d-a563-dd930c0d52af"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'sherpa-onnx-zh-wenet-aishell'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects:   4% (1/21)\u001b[K\rremote: Counting objects:   9% (2/21)\u001b[K\rremote: Counting objects:  14% (3/21)\u001b[K\rremote: Counting objects:  19% (4/21)\u001b[K\rremote: Counting objects:  23% (5/21)\u001b[K\rremote: Counting objects:  28% (6/21)\u001b[K\rremote: Counting objects:  33% (7/21)\u001b[K\rremote: Counting objects:  38% (8/21)\u001b[K\rremote: Counting objects:  42% (9/21)\u001b[K\rremote: Counting objects:  47% (10/21)\u001b[K\rremote: Counting objects:  52% (11/21)\u001b[K\rremote: Counting objects:  57% (12/21)\u001b[K\rremote: Counting objects:  61% (13/21)\u001b[K\rremote: Counting objects:  66% (14/21)\u001b[K\rremote: Counting objects:  71% (15/21)\u001b[K\rremote: Counting objects:  76% (16/21)\u001b[K\rremote: Counting objects:  80% (17/21)\u001b[K\rremote: Counting objects:  85% (18/21)\u001b[K\rremote: Counting objects:  90% (19/21)\u001b[K\rremote: Counting objects:  95% (20/21)\u001b[K\rremote: Counting objects: 100% (21/21)\u001b[K\rremote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 24 (delta 1), reused 0 (delta 0), pack-reused 3\u001b[K\n",
            "Unpacking objects: 100% (24/24), 362.77 KiB | 5.95 MiB/s, done.\n",
            "Filtering content: 100% (4/4), 368.82 MiB | 43.46 MiB/s, done.\n",
            "total 369M\n",
            "-rw-r--r-- 1 root root  48M Nov 16 03:50 model.int8.onnx\n",
            "-rw-r--r-- 1 root root 138M Nov 16 03:50 model.onnx\n",
            "-rw-r--r-- 1 root root  48M Nov 16 03:50 model-streaming.int8.onnx\n",
            "-rw-r--r-- 1 root root 137M Nov 16 03:50 model-streaming.onnx\n",
            "-rw-r--r-- 1 root root  130 Nov 16 03:50 README.md\n",
            "drwxr-xr-x 2 root root 4.0K Nov 16 03:50 test_wavs\n",
            "-rwxr-xr-x 1 root root  37K Nov 16 03:50 tokens.txt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Streaming decoding"
      ],
      "metadata": {
        "id": "ms0zjhn2KgEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# float32 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-zh-wenet-aishell/model-streaming.onnx \\\n",
        "  --tokens=./sherpa-onnx-zh-wenet-aishell/tokens.txt \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sCJn2iaKcx3",
        "outputId": "3697a13a-a5ed-4ebb-d444-bdd4680535e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx --wenet-ctc-model=./sherpa-onnx-zh-wenet-aishell/model-streaming.onnx --tokens=./sherpa-onnx-zh-wenet-aishell/tokens.txt ./sherpa-onnx-zh-wenet-aishell/test_wavs/0.wav ./sherpa-onnx-zh-wenet-aishell/test_wavs/1.wav ./sherpa-onnx-zh-wenet-aishell/test_wavs/8k.wav \n",
            "\n",
            "OnlineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OnlineModelConfig(transducer=OnlineTransducerModelConfig(encoder=\"\", decoder=\"\", joiner=\"\"), paraformer=OnlineParaformerModelConfig(encoder=\"\", decoder=\"\"), wenet_ctc=OnlineWenetCtcModelConfig(model=\"./sherpa-onnx-zh-wenet-aishell/model-streaming.onnx\", chunk_size=16, num_left_chunks=4), tokens=\"./sherpa-onnx-zh-wenet-aishell/tokens.txt\", num_threads=1, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OnlineLMConfig(model=\"\", scale=0.5), endpoint_config=EndpointConfig(rule1=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=2.4, min_utterance_length=0), rule2=EndpointRule(must_contain_nonsilence=True, min_trailing_silence=1.2, min_utterance_length=0), rule3=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20)), enable_endpoint=True, max_active_paths=4, hotwords_score=1.5, hotwords_file=\"\", decoding_method=\"greedy_search\")\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/features.cc:AcceptWaveformImpl:85 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "./sherpa-onnx-zh-wenet-aishell/test_wavs/0.wav\n",
            "Elapsed seconds: 1.1, Real time factor (RTF): 0.2\n",
            "对我做了介绍马偶想说的来量如果练了研究感兴趣\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"对我做了介绍马偶想说的来量如果练了研究感兴趣\", \"timestamps\": [0.52, 0.04, 0.20, 0.32, 0.48, 0.04, 0.20, 0.40, 0.56, 0.08, 0.16, 0.28, 0.40, 0.52, 0.00, 0.12, 0.24, 0.36, 0.48, 0.00, 0.24, 0.44], \"tokens\":[\"对\", \"我\", \"做\", \"了\", \"介\", \"绍\", \"马\", \"偶\", \"想\", \"说\", \"的\", \"来\", \"量\", \"如\", \"果\", \"练\", \"了\", \"研\", \"究\", \"感\", \"兴\", \"趣\"]}\n",
            "\n",
            "./sherpa-onnx-zh-wenet-aishell/test_wavs/1.wav\n",
            "Elapsed seconds: 1.1, Real time factor (RTF): 0.22\n",
            "痛点了小看三个问题首先那就是这一轮全球电动动荡的表现\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"痛点了小看三个问题首先那就是这一轮全球电动动荡的表现\", \"timestamps\": [0.36, 0.52, 0.00, 0.20, 0.36, 0.52, 0.00, 0.16, 0.40, 0.48, 0.00, 0.12, 0.28, 0.48, 0.08, 0.16, 0.36, 0.56, 0.08, 0.20, 0.28, 0.44, 0.52, 0.04, 0.24, 0.44], \"tokens\":[\"痛\", \"点\", \"了\", \"小\", \"看\", \"三\", \"个\", \"问\", \"题\", \"首\", \"先\", \"那\", \"就\", \"是\", \"这\", \"一\", \"轮\", \"全\", \"球\", \"电\", \"动\", \"动\", \"荡\", \"的\", \"表\", \"现\"]}\n",
            "\n",
            "./sherpa-onnx-zh-wenet-aishell/test_wavs/8k.wav\n",
            "Elapsed seconds: 1.1, Real time factor (RTF): 0.23\n",
            "深穆的可须被喝全球金融动荡背后的根远\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"深穆的可须被喝全球金融动荡背后的根远\", \"timestamps\": [0.00, 0.12, 0.28, 0.44, 0.16, 0.60, 0.36, 0.24, 0.44, 0.56, 0.04, 0.20, 0.36, 0.48, 0.60, 0.08, 0.24, 0.48], \"tokens\":[\"深\", \"穆\", \"的\", \"可\", \"须\", \"被\", \"喝\", \"全\", \"球\", \"金\", \"融\", \"动\", \"荡\", \"背\", \"后\", \"的\", \"根\", \"远\"]}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# int8 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-zh-wenet-aishell/model-streaming.int8.onnx \\\n",
        "  --tokens=./sherpa-onnx-zh-wenet-aishell/tokens.txt \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOMfRV0PKyr_",
        "outputId": "b3ed4987-10d4-434b-9512-a0136635d077"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx --wenet-ctc-model=./sherpa-onnx-zh-wenet-aishell/model-streaming.int8.onnx --tokens=./sherpa-onnx-zh-wenet-aishell/tokens.txt ./sherpa-onnx-zh-wenet-aishell/test_wavs/0.wav ./sherpa-onnx-zh-wenet-aishell/test_wavs/1.wav ./sherpa-onnx-zh-wenet-aishell/test_wavs/8k.wav \n",
            "\n",
            "OnlineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OnlineModelConfig(transducer=OnlineTransducerModelConfig(encoder=\"\", decoder=\"\", joiner=\"\"), paraformer=OnlineParaformerModelConfig(encoder=\"\", decoder=\"\"), wenet_ctc=OnlineWenetCtcModelConfig(model=\"./sherpa-onnx-zh-wenet-aishell/model-streaming.int8.onnx\", chunk_size=16, num_left_chunks=4), tokens=\"./sherpa-onnx-zh-wenet-aishell/tokens.txt\", num_threads=1, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OnlineLMConfig(model=\"\", scale=0.5), endpoint_config=EndpointConfig(rule1=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=2.4, min_utterance_length=0), rule2=EndpointRule(must_contain_nonsilence=True, min_trailing_silence=1.2, min_utterance_length=0), rule3=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20)), enable_endpoint=True, max_active_paths=4, hotwords_score=1.5, hotwords_file=\"\", decoding_method=\"greedy_search\")\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/features.cc:AcceptWaveformImpl:85 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "./sherpa-onnx-zh-wenet-aishell/test_wavs/0.wav\n",
            "Elapsed seconds: 1, Real time factor (RTF): 0.18\n",
            "对我做了介绍马偶想说的呢来量如果队了研究感兴趣\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"对我做了介绍马偶想说的呢来量如果队了研究感兴趣\", \"timestamps\": [0.52, 0.04, 0.20, 0.32, 0.48, 0.04, 0.20, 0.40, 0.56, 0.08, 0.16, 0.44, 0.28, 0.40, 0.52, 0.00, 0.12, 0.24, 0.36, 0.48, 0.00, 0.24, 0.44], \"tokens\":[\"对\", \"我\", \"做\", \"了\", \"介\", \"绍\", \"马\", \"偶\", \"想\", \"说\", \"的\", \"呢\", \"来\", \"量\", \"如\", \"果\", \"队\", \"了\", \"研\", \"究\", \"感\", \"兴\", \"趣\"]}\n",
            "\n",
            "./sherpa-onnx-zh-wenet-aishell/test_wavs/1.wav\n",
            "Elapsed seconds: 1, Real time factor (RTF): 0.19\n",
            "动点了小看三个问题首先那这是这一轮全球电动动荡的表现\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"动点了小看三个问题首先那这是这一轮全球电动动荡的表现\", \"timestamps\": [0.36, 0.52, 0.00, 0.20, 0.36, 0.52, 0.00, 0.16, 0.40, 0.48, 0.00, 0.12, 0.28, 0.48, 0.08, 0.16, 0.36, 0.56, 0.08, 0.20, 0.28, 0.44, 0.52, 0.04, 0.24, 0.44], \"tokens\":[\"动\", \"点\", \"了\", \"小\", \"看\", \"三\", \"个\", \"问\", \"题\", \"首\", \"先\", \"那\", \"这\", \"是\", \"这\", \"一\", \"轮\", \"全\", \"球\", \"电\", \"动\", \"动\", \"荡\", \"的\", \"表\", \"现\"]}\n",
            "\n",
            "./sherpa-onnx-zh-wenet-aishell/test_wavs/8k.wav\n",
            "Elapsed seconds: 0.94, Real time factor (RTF): 0.21\n",
            "深穆的喷须被喝全球金融动荡背后的根远\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"深穆的喷须被喝全球金融动荡背后的根远\", \"timestamps\": [0.00, 0.12, 0.28, 0.44, 0.16, 0.60, 0.36, 0.24, 0.44, 0.56, 0.04, 0.20, 0.36, 0.48, 0.60, 0.08, 0.24, 0.48], \"tokens\":[\"深\", \"穆\", \"的\", \"喷\", \"须\", \"被\", \"喝\", \"全\", \"球\", \"金\", \"融\", \"动\", \"荡\", \"背\", \"后\", \"的\", \"根\", \"远\"]}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-stremaing decoding"
      ],
      "metadata": {
        "id": "Z_l3D_-MLGCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# float32 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx-offline \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-zh-wenet-aishell/model.onnx \\\n",
        "  --tokens=./sherpa-onnx-zh-wenet-aishell/tokens.txt \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV_uS00MK-us",
        "outputId": "aef44331-dd2f-4424-9211-b69bad4d61fa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx-offline --wenet-ctc-model=./sherpa-onnx-zh-wenet-aishell/model.onnx --tokens=./sherpa-onnx-zh-wenet-aishell/tokens.txt ./sherpa-onnx-zh-wenet-aishell/test_wavs/0.wav ./sherpa-onnx-zh-wenet-aishell/test_wavs/1.wav ./sherpa-onnx-zh-wenet-aishell/test_wavs/8k.wav \n",
            "\n",
            "OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=\"\", decoder_filename=\"\", joiner_filename=\"\"), paraformer=OfflineParaformerModelConfig(model=\"\"), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=\"\"), whisper=OfflineWhisperModelConfig(encoder=\"\", decoder=\"\", language=\"\", task=\"transcribe\"), tdnn=OfflineTdnnModelConfig(model=\"\"), zipformer_ctc=OfflineZipformerCtcModelConfig(model=\"\"), wenet_ctc=OfflineWenetCtcModelConfig(model=\"./sherpa-onnx-zh-wenet-aishell/model.onnx\"), tokens=\"./sherpa-onnx-zh-wenet-aishell/tokens.txt\", num_threads=2, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OfflineLMConfig(model=\"\", scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=\"\", max_active=3000), decoding_method=\"greedy_search\", max_active_paths=4, hotwords_file=\"\", hotwords_score=1.5)\n",
            "Creating recognizer ...\n",
            "Started\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/offline-stream.cc:AcceptWaveformImpl:113 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "Done!\n",
            "\n",
            "./sherpa-onnx-zh-wenet-aishell/test_wavs/0.wav\n",
            "{\"text\": \"对我做了介绍猫偶想说的事那让如果做了研究感兴趣\", \"timestamps\": [0.52, 0.68, 0.84, 0.96, 1.12, 1.32, 2.12, 2.32, 2.48, 2.60, 2.72, 2.84, 3.44, 3.60, 3.72, 3.84, 3.96, 4.08, 4.20, 4.32, 4.48, 4.72, 4.92], \"tokens\":[\"对\", \"我\", \"做\", \"了\", \"介\", \"绍\", \"猫\", \"偶\", \"想\", \"说\", \"的\", \"事\", \"那\", \"让\", \"如\", \"果\", \"做\", \"了\", \"研\", \"究\", \"感\", \"兴\", \"趣\"]}\n",
            "----\n",
            "./sherpa-onnx-zh-wenet-aishell/test_wavs/1.wav\n",
            "{\"text\": \"动点了小看三个问题首先那就是这一轮全球金动荡的表现\", \"timestamps\": [0.36, 0.52, 0.64, 0.84, 1.00, 1.16, 1.28, 1.44, 1.64, 2.40, 2.52, 2.68, 2.84, 3.04, 3.28, 3.36, 3.52, 3.76, 3.92, 4.04, 4.12, 4.36, 4.52, 4.72, 4.88], \"tokens\":[\"动\", \"点\", \"了\", \"小\", \"看\", \"三\", \"个\", \"问\", \"题\", \"首\", \"先\", \"那\", \"就\", \"是\", \"这\", \"一\", \"轮\", \"全\", \"球\", \"金\", \"动\", \"荡\", \"的\", \"表\", \"现\"]}\n",
            "----\n",
            "./sherpa-onnx-zh-wenet-aishell/test_wavs/8k.wav\n",
            "{\"text\": \"深度的分烯对于和全球金融动荡背忘地根远\", \"timestamps\": [0.60, 0.76, 0.92, 1.08, 1.44, 1.84, 2.00, 2.28, 2.80, 3.00, 3.12, 3.24, 3.40, 3.56, 3.68, 3.80, 3.92, 4.08, 4.28], \"tokens\":[\"深\", \"度\", \"的\", \"分\", \"烯\", \"对\", \"于\", \"和\", \"全\", \"球\", \"金\", \"融\", \"动\", \"荡\", \"背\", \"忘\", \"地\", \"根\", \"远\"]}\n",
            "----\n",
            "num threads: 2\n",
            "decoding method: greedy_search\n",
            "Elapsed seconds: 0.731 s\n",
            "Real time factor (RTF): 0.731 / 15.289 = 0.048\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# int8 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx-offline \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-zh-wenet-aishell/model.int8.onnx \\\n",
        "  --tokens=./sherpa-onnx-zh-wenet-aishell/tokens.txt \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7LH2u33LK1_",
        "outputId": "250f9fc0-29b1-43cd-e76b-23b25c834555"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx-offline --wenet-ctc-model=./sherpa-onnx-zh-wenet-aishell/model.int8.onnx --tokens=./sherpa-onnx-zh-wenet-aishell/tokens.txt ./sherpa-onnx-zh-wenet-aishell/test_wavs/0.wav ./sherpa-onnx-zh-wenet-aishell/test_wavs/1.wav ./sherpa-onnx-zh-wenet-aishell/test_wavs/8k.wav \n",
            "\n",
            "OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=\"\", decoder_filename=\"\", joiner_filename=\"\"), paraformer=OfflineParaformerModelConfig(model=\"\"), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=\"\"), whisper=OfflineWhisperModelConfig(encoder=\"\", decoder=\"\", language=\"\", task=\"transcribe\"), tdnn=OfflineTdnnModelConfig(model=\"\"), zipformer_ctc=OfflineZipformerCtcModelConfig(model=\"\"), wenet_ctc=OfflineWenetCtcModelConfig(model=\"./sherpa-onnx-zh-wenet-aishell/model.int8.onnx\"), tokens=\"./sherpa-onnx-zh-wenet-aishell/tokens.txt\", num_threads=2, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OfflineLMConfig(model=\"\", scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=\"\", max_active=3000), decoding_method=\"greedy_search\", max_active_paths=4, hotwords_file=\"\", hotwords_score=1.5)\n",
            "Creating recognizer ...\n",
            "Started\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/offline-stream.cc:AcceptWaveformImpl:113 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "Done!\n",
            "\n",
            "./sherpa-onnx-zh-wenet-aishell/test_wavs/0.wav\n",
            "{\"text\": \"对我做了介绍马偶想说的事来让如果做了研究感兴趣\", \"timestamps\": [0.52, 0.68, 0.84, 0.96, 1.12, 1.32, 2.12, 2.32, 2.48, 2.60, 2.72, 2.84, 3.44, 3.60, 3.72, 3.84, 3.96, 4.08, 4.20, 4.32, 4.48, 4.72, 4.92], \"tokens\":[\"对\", \"我\", \"做\", \"了\", \"介\", \"绍\", \"马\", \"偶\", \"想\", \"说\", \"的\", \"事\", \"来\", \"让\", \"如\", \"果\", \"做\", \"了\", \"研\", \"究\", \"感\", \"兴\", \"趣\"]}\n",
            "----\n",
            "./sherpa-onnx-zh-wenet-aishell/test_wavs/1.wav\n",
            "{\"text\": \"动点了小看三个问题首先那就是这一轮全球经动荡的表现\", \"timestamps\": [0.36, 0.52, 0.64, 0.84, 1.00, 1.16, 1.28, 1.44, 1.64, 2.40, 2.52, 2.68, 2.84, 3.04, 3.28, 3.36, 3.52, 3.76, 3.92, 4.04, 4.12, 4.36, 4.52, 4.72, 4.88], \"tokens\":[\"动\", \"点\", \"了\", \"小\", \"看\", \"三\", \"个\", \"问\", \"题\", \"首\", \"先\", \"那\", \"就\", \"是\", \"这\", \"一\", \"轮\", \"全\", \"球\", \"经\", \"动\", \"荡\", \"的\", \"表\", \"现\"]}\n",
            "----\n",
            "./sherpa-onnx-zh-wenet-aishell/test_wavs/8k.wav\n",
            "{\"text\": \"深度的分需对于和全球金融动荡背忘地根远\", \"timestamps\": [0.60, 0.76, 0.92, 1.08, 1.44, 1.84, 2.00, 2.28, 2.80, 3.00, 3.12, 3.24, 3.40, 3.56, 3.68, 3.80, 3.92, 4.08, 4.28], \"tokens\":[\"深\", \"度\", \"的\", \"分\", \"需\", \"对\", \"于\", \"和\", \"全\", \"球\", \"金\", \"融\", \"动\", \"荡\", \"背\", \"忘\", \"地\", \"根\", \"远\"]}\n",
            "----\n",
            "num threads: 2\n",
            "decoding method: greedy_search\n",
            "Elapsed seconds: 0.629 s\n",
            "Real time factor (RTF): 0.629 / 15.289 = 0.041\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sherpa-onnx-zh-wenet-aishell2"
      ],
      "metadata": {
        "id": "PF2o5sriLo8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "git lfs install\n",
        "git clone https://huggingface.co/csukuangfj/sherpa-onnx-zh-wenet-aishell2\n",
        "ls -lh sherpa-onnx-zh-wenet-aishell2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G_vUyWULy8T",
        "outputId": "0d38b047-7fbc-44d6-c9e8-20f0b2c9ab22"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'sherpa-onnx-zh-wenet-aishell2'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 24 (delta 1), reused 0 (delta 0), pack-reused 3\u001b[K\n",
            "Unpacking objects: 100% (24/24), 366.07 KiB | 5.30 MiB/s, done.\n",
            "Filtering content: 100% (4/4), 371.28 MiB | 58.86 MiB/s, done.\n",
            "total 372M\n",
            "-rw-r--r-- 1 root root  48M Nov 16 03:50 model.int8.onnx\n",
            "-rw-r--r-- 1 root root 139M Nov 16 03:51 model.onnx\n",
            "-rw-r--r-- 1 root root  48M Nov 16 03:50 model-streaming.int8.onnx\n",
            "-rw-r--r-- 1 root root 138M Nov 16 03:51 model-streaming.onnx\n",
            "-rw-r--r-- 1 root root  131 Nov 16 03:50 README.md\n",
            "drwxr-xr-x 2 root root 4.0K Nov 16 03:50 test_wavs\n",
            "-rwxr-xr-x 1 root root  45K Nov 16 03:50 tokens.txt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Streaming decoding"
      ],
      "metadata": {
        "id": "KJgMaMMLLuAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# float32 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-zh-wenet-aishell2/model-streaming.onnx \\\n",
        "  --tokens=./sherpa-onnx-zh-wenet-aishell2/tokens.txt \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell2/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell2/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell2/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTDL8ah1L6Hv",
        "outputId": "faee69e2-96ab-42e0-dc89-6f5a2f4d821a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx --wenet-ctc-model=./sherpa-onnx-zh-wenet-aishell2/model-streaming.onnx --tokens=./sherpa-onnx-zh-wenet-aishell2/tokens.txt ./sherpa-onnx-zh-wenet-aishell2/test_wavs/0.wav ./sherpa-onnx-zh-wenet-aishell2/test_wavs/1.wav ./sherpa-onnx-zh-wenet-aishell2/test_wavs/8k.wav \n",
            "\n",
            "OnlineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OnlineModelConfig(transducer=OnlineTransducerModelConfig(encoder=\"\", decoder=\"\", joiner=\"\"), paraformer=OnlineParaformerModelConfig(encoder=\"\", decoder=\"\"), wenet_ctc=OnlineWenetCtcModelConfig(model=\"./sherpa-onnx-zh-wenet-aishell2/model-streaming.onnx\", chunk_size=16, num_left_chunks=4), tokens=\"./sherpa-onnx-zh-wenet-aishell2/tokens.txt\", num_threads=1, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OnlineLMConfig(model=\"\", scale=0.5), endpoint_config=EndpointConfig(rule1=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=2.4, min_utterance_length=0), rule2=EndpointRule(must_contain_nonsilence=True, min_trailing_silence=1.2, min_utterance_length=0), rule3=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20)), enable_endpoint=True, max_active_paths=4, hotwords_score=1.5, hotwords_file=\"\", decoding_method=\"greedy_search\")\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/features.cc:AcceptWaveformImpl:85 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "./sherpa-onnx-zh-wenet-aishell2/test_wavs/0.wav\n",
            "Elapsed seconds: 1.1, Real time factor (RTF): 0.2\n",
            "对我做了介绍妈我想做的事玩家如果对我研究感兴趣\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"对我做了介绍妈我想做的事玩家如果对我研究感兴趣\", \"timestamps\": [0.00, 0.08, 0.24, 0.36, 0.52, 0.04, 0.24, 0.48, 0.60, 0.08, 0.20, 0.32, 0.32, 0.44, 0.60, 0.08, 0.16, 0.24, 0.40, 0.56, 0.04, 0.24, 0.44], \"tokens\":[\"对\", \"我\", \"做\", \"了\", \"介\", \"绍\", \"妈\", \"我\", \"想\", \"做\", \"的\", \"事\", \"玩\", \"家\", \"如\", \"果\", \"对\", \"我\", \"研\", \"究\", \"感\", \"兴\", \"趣\"]}\n",
            "\n",
            "./sherpa-onnx-zh-wenet-aishell2/test_wavs/1.wav\n",
            "Elapsed seconds: 1.1, Real time factor (RTF): 0.22\n",
            "重点的想看三个问题首先那就是在一轮全球金融动荡的表现\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"重点的想看三个问题首先那就是在一轮全球金融动荡的表现\", \"timestamps\": [0.40, 0.56, 0.08, 0.20, 0.40, 0.56, 0.04, 0.20, 0.36, 0.52, 0.04, 0.16, 0.32, 0.48, 0.12, 0.24, 0.40, 0.00, 0.08, 0.24, 0.36, 0.48, 0.60, 0.08, 0.24, 0.48], \"tokens\":[\"重\", \"点\", \"的\", \"想\", \"看\", \"三\", \"个\", \"问\", \"题\", \"首\", \"先\", \"那\", \"就\", \"是\", \"在\", \"一\", \"轮\", \"全\", \"球\", \"金\", \"融\", \"动\", \"荡\", \"的\", \"表\", \"现\"]}\n",
            "\n",
            "./sherpa-onnx-zh-wenet-aishell2/test_wavs/8k.wav\n",
            "Elapsed seconds: 1.1, Real time factor (RTF): 0.23\n",
            "深度的分析析再一次全球金融动荡背后的根源\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"深度的分析析再一次全球金融动荡背后的根源\", \"timestamps\": [0.04, 0.20, 0.32, 0.44, 0.60, 0.16, 0.00, 0.16, 0.36, 0.28, 0.44, 0.00, 0.12, 0.24, 0.40, 0.52, 0.04, 0.12, 0.28, 0.44], \"tokens\":[\"深\", \"度\", \"的\", \"分\", \"析\", \"析\", \"再\", \"一\", \"次\", \"全\", \"球\", \"金\", \"融\", \"动\", \"荡\", \"背\", \"后\", \"的\", \"根\", \"源\"]}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# int8 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-zh-wenet-aishell2/model-streaming.int8.onnx \\\n",
        "  --tokens=./sherpa-onnx-zh-wenet-aishell2/tokens.txt \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell2/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell2/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell2/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p98WSninL_xn",
        "outputId": "8b467c06-f8e2-47c3-881f-9be7ffa5badc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx --wenet-ctc-model=./sherpa-onnx-zh-wenet-aishell2/model-streaming.int8.onnx --tokens=./sherpa-onnx-zh-wenet-aishell2/tokens.txt ./sherpa-onnx-zh-wenet-aishell2/test_wavs/0.wav ./sherpa-onnx-zh-wenet-aishell2/test_wavs/1.wav ./sherpa-onnx-zh-wenet-aishell2/test_wavs/8k.wav \n",
            "\n",
            "OnlineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OnlineModelConfig(transducer=OnlineTransducerModelConfig(encoder=\"\", decoder=\"\", joiner=\"\"), paraformer=OnlineParaformerModelConfig(encoder=\"\", decoder=\"\"), wenet_ctc=OnlineWenetCtcModelConfig(model=\"./sherpa-onnx-zh-wenet-aishell2/model-streaming.int8.onnx\", chunk_size=16, num_left_chunks=4), tokens=\"./sherpa-onnx-zh-wenet-aishell2/tokens.txt\", num_threads=1, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OnlineLMConfig(model=\"\", scale=0.5), endpoint_config=EndpointConfig(rule1=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=2.4, min_utterance_length=0), rule2=EndpointRule(must_contain_nonsilence=True, min_trailing_silence=1.2, min_utterance_length=0), rule3=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20)), enable_endpoint=True, max_active_paths=4, hotwords_score=1.5, hotwords_file=\"\", decoding_method=\"greedy_search\")\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/features.cc:AcceptWaveformImpl:85 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "./sherpa-onnx-zh-wenet-aishell2/test_wavs/0.wav\n",
            "Elapsed seconds: 0.9, Real time factor (RTF): 0.16\n",
            "对我做了介绍妈我想做的事玩家如果对我研究感兴趣\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"对我做了介绍妈我想做的事玩家如果对我研究感兴趣\", \"timestamps\": [0.00, 0.08, 0.24, 0.36, 0.52, 0.04, 0.24, 0.48, 0.60, 0.08, 0.20, 0.32, 0.32, 0.44, 0.60, 0.08, 0.16, 0.24, 0.40, 0.56, 0.04, 0.24, 0.44], \"tokens\":[\"对\", \"我\", \"做\", \"了\", \"介\", \"绍\", \"妈\", \"我\", \"想\", \"做\", \"的\", \"事\", \"玩\", \"家\", \"如\", \"果\", \"对\", \"我\", \"研\", \"究\", \"感\", \"兴\", \"趣\"]}\n",
            "\n",
            "./sherpa-onnx-zh-wenet-aishell2/test_wavs/1.wav\n",
            "Elapsed seconds: 0.9, Real time factor (RTF): 0.18\n",
            "重点的想看三个问题首先那就是在一轮全球金动动荡的表现\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"重点的想看三个问题首先那就是在一轮全球金动动荡的表现\", \"timestamps\": [0.40, 0.56, 0.08, 0.20, 0.40, 0.56, 0.04, 0.20, 0.36, 0.52, 0.04, 0.16, 0.32, 0.48, 0.12, 0.24, 0.40, 0.00, 0.08, 0.24, 0.36, 0.48, 0.60, 0.08, 0.24, 0.48], \"tokens\":[\"重\", \"点\", \"的\", \"想\", \"看\", \"三\", \"个\", \"问\", \"题\", \"首\", \"先\", \"那\", \"就\", \"是\", \"在\", \"一\", \"轮\", \"全\", \"球\", \"金\", \"动\", \"动\", \"荡\", \"的\", \"表\", \"现\"]}\n",
            "\n",
            "./sherpa-onnx-zh-wenet-aishell2/test_wavs/8k.wav\n",
            "Elapsed seconds: 0.84, Real time factor (RTF): 0.18\n",
            "深度的分析析再一次全球金融动荡背后的根源\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"深度的分析析再一次全球金融动荡背后的根源\", \"timestamps\": [0.04, 0.20, 0.32, 0.44, 0.60, 0.16, 0.00, 0.16, 0.36, 0.28, 0.44, 0.00, 0.12, 0.24, 0.40, 0.52, 0.04, 0.12, 0.28, 0.44], \"tokens\":[\"深\", \"度\", \"的\", \"分\", \"析\", \"析\", \"再\", \"一\", \"次\", \"全\", \"球\", \"金\", \"融\", \"动\", \"荡\", \"背\", \"后\", \"的\", \"根\", \"源\"]}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-streaming decoding"
      ],
      "metadata": {
        "id": "_M6BVQ5jLwLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# float32 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx-offline \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-zh-wenet-aishell2/model.onnx \\\n",
        "  --tokens=./sherpa-onnx-zh-wenet-aishell2/tokens.txt \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell2/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell2/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell2/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlghU-YSL9eh",
        "outputId": "f9fac33c-1049-465f-aad4-b2b88d4b1a5e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx-offline --wenet-ctc-model=./sherpa-onnx-zh-wenet-aishell2/model.onnx --tokens=./sherpa-onnx-zh-wenet-aishell2/tokens.txt ./sherpa-onnx-zh-wenet-aishell2/test_wavs/0.wav ./sherpa-onnx-zh-wenet-aishell2/test_wavs/1.wav ./sherpa-onnx-zh-wenet-aishell2/test_wavs/8k.wav \n",
            "\n",
            "OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=\"\", decoder_filename=\"\", joiner_filename=\"\"), paraformer=OfflineParaformerModelConfig(model=\"\"), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=\"\"), whisper=OfflineWhisperModelConfig(encoder=\"\", decoder=\"\", language=\"\", task=\"transcribe\"), tdnn=OfflineTdnnModelConfig(model=\"\"), zipformer_ctc=OfflineZipformerCtcModelConfig(model=\"\"), wenet_ctc=OfflineWenetCtcModelConfig(model=\"./sherpa-onnx-zh-wenet-aishell2/model.onnx\"), tokens=\"./sherpa-onnx-zh-wenet-aishell2/tokens.txt\", num_threads=2, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OfflineLMConfig(model=\"\", scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=\"\", max_active=3000), decoding_method=\"greedy_search\", max_active_paths=4, hotwords_file=\"\", hotwords_score=1.5)\n",
            "Creating recognizer ...\n",
            "Started\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/offline-stream.cc:AcceptWaveformImpl:113 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "Done!\n",
            "\n",
            "./sherpa-onnx-zh-wenet-aishell2/test_wavs/0.wav\n",
            "{\"text\": \"对我做了介绍往我想做算是玩家如果对我的研究感兴趣呢\", \"timestamps\": [0.56, 0.72, 0.88, 1.00, 1.16, 1.36, 2.16, 2.40, 2.52, 2.64, 2.76, 2.88, 3.52, 3.64, 3.80, 3.92, 4.00, 4.08, 4.16, 4.24, 4.40, 4.52, 4.72, 4.92, 5.08], \"tokens\":[\"对\", \"我\", \"做\", \"了\", \"介\", \"绍\", \"往\", \"我\", \"想\", \"做\", \"算\", \"是\", \"玩\", \"家\", \"如\", \"果\", \"对\", \"我\", \"的\", \"研\", \"究\", \"感\", \"兴\", \"趣\", \"呢\"]}\n",
            "----\n",
            "./sherpa-onnx-zh-wenet-aishell2/test_wavs/1.wav\n",
            "{\"text\": \"重点来想看三个问题首先那就是在一轮全球金动荡的表现\", \"timestamps\": [0.40, 0.56, 0.72, 0.84, 1.04, 1.20, 1.32, 1.48, 1.64, 2.44, 2.60, 2.72, 2.88, 3.04, 3.32, 3.44, 3.56, 3.80, 3.92, 4.08, 4.20, 4.44, 4.56, 4.72, 4.92], \"tokens\":[\"重\", \"点\", \"来\", \"想\", \"看\", \"三\", \"个\", \"问\", \"题\", \"首\", \"先\", \"那\", \"就\", \"是\", \"在\", \"一\", \"轮\", \"全\", \"球\", \"金\", \"动\", \"荡\", \"的\", \"表\", \"现\"]}\n",
            "----\n",
            "./sherpa-onnx-zh-wenet-aishell2/test_wavs/8k.wav\n",
            "{\"text\": \"深度的分析师对一次全球金融动荡背后的根源\", \"timestamps\": [0.64, 0.80, 0.96, 1.08, 1.24, 1.44, 1.88, 2.04, 2.28, 2.84, 3.00, 3.16, 3.32, 3.44, 3.60, 3.72, 3.88, 3.96, 4.12, 4.28], \"tokens\":[\"深\", \"度\", \"的\", \"分\", \"析\", \"师\", \"对\", \"一\", \"次\", \"全\", \"球\", \"金\", \"融\", \"动\", \"荡\", \"背\", \"后\", \"的\", \"根\", \"源\"]}\n",
            "----\n",
            "num threads: 2\n",
            "decoding method: greedy_search\n",
            "Elapsed seconds: 1.685 s\n",
            "Real time factor (RTF): 1.685 / 15.289 = 0.110\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# int8 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx-offline \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-zh-wenet-aishell2/model.int8.onnx \\\n",
        "  --tokens=./sherpa-onnx-zh-wenet-aishell2/tokens.txt \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell2/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell2/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-aishell2/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrlJD3DXMFXN",
        "outputId": "e05f1f3f-3edb-4e3d-9f69-cee4b1865664"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx-offline --wenet-ctc-model=./sherpa-onnx-zh-wenet-aishell2/model.int8.onnx --tokens=./sherpa-onnx-zh-wenet-aishell2/tokens.txt ./sherpa-onnx-zh-wenet-aishell2/test_wavs/0.wav ./sherpa-onnx-zh-wenet-aishell2/test_wavs/1.wav ./sherpa-onnx-zh-wenet-aishell2/test_wavs/8k.wav \n",
            "\n",
            "OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=\"\", decoder_filename=\"\", joiner_filename=\"\"), paraformer=OfflineParaformerModelConfig(model=\"\"), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=\"\"), whisper=OfflineWhisperModelConfig(encoder=\"\", decoder=\"\", language=\"\", task=\"transcribe\"), tdnn=OfflineTdnnModelConfig(model=\"\"), zipformer_ctc=OfflineZipformerCtcModelConfig(model=\"\"), wenet_ctc=OfflineWenetCtcModelConfig(model=\"./sherpa-onnx-zh-wenet-aishell2/model.int8.onnx\"), tokens=\"./sherpa-onnx-zh-wenet-aishell2/tokens.txt\", num_threads=2, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OfflineLMConfig(model=\"\", scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=\"\", max_active=3000), decoding_method=\"greedy_search\", max_active_paths=4, hotwords_file=\"\", hotwords_score=1.5)\n",
            "Creating recognizer ...\n",
            "Started\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/offline-stream.cc:AcceptWaveformImpl:113 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "Done!\n",
            "\n",
            "./sherpa-onnx-zh-wenet-aishell2/test_wavs/0.wav\n",
            "{\"text\": \"对我做了介绍往我想说算是玩家如果对我的研究感兴趣呢\", \"timestamps\": [0.56, 0.72, 0.88, 1.00, 1.16, 1.36, 2.16, 2.40, 2.52, 2.64, 2.76, 2.88, 3.52, 3.64, 3.80, 3.92, 4.00, 4.12, 4.16, 4.28, 4.40, 4.52, 4.72, 4.92, 5.08], \"tokens\":[\"对\", \"我\", \"做\", \"了\", \"介\", \"绍\", \"往\", \"我\", \"想\", \"说\", \"算\", \"是\", \"玩\", \"家\", \"如\", \"果\", \"对\", \"我\", \"的\", \"研\", \"究\", \"感\", \"兴\", \"趣\", \"呢\"]}\n",
            "----\n",
            "./sherpa-onnx-zh-wenet-aishell2/test_wavs/1.wav\n",
            "{\"text\": \"重点来想看三个问题首先那就是在一轮全球金动荡的表现\", \"timestamps\": [0.40, 0.56, 0.72, 0.84, 1.04, 1.20, 1.32, 1.48, 1.64, 2.44, 2.60, 2.72, 2.88, 3.04, 3.32, 3.44, 3.56, 3.80, 3.92, 4.08, 4.20, 4.44, 4.56, 4.72, 4.92], \"tokens\":[\"重\", \"点\", \"来\", \"想\", \"看\", \"三\", \"个\", \"问\", \"题\", \"首\", \"先\", \"那\", \"就\", \"是\", \"在\", \"一\", \"轮\", \"全\", \"球\", \"金\", \"动\", \"荡\", \"的\", \"表\", \"现\"]}\n",
            "----\n",
            "./sherpa-onnx-zh-wenet-aishell2/test_wavs/8k.wav\n",
            "{\"text\": \"深度的分析师对一次全球金融动荡背后的根源\", \"timestamps\": [0.64, 0.80, 0.96, 1.08, 1.24, 1.44, 1.88, 2.04, 2.28, 2.84, 3.00, 3.16, 3.32, 3.44, 3.60, 3.72, 3.88, 3.96, 4.12, 4.28], \"tokens\":[\"深\", \"度\", \"的\", \"分\", \"析\", \"师\", \"对\", \"一\", \"次\", \"全\", \"球\", \"金\", \"融\", \"动\", \"荡\", \"背\", \"后\", \"的\", \"根\", \"源\"]}\n",
            "----\n",
            "num threads: 2\n",
            "decoding method: greedy_search\n",
            "Elapsed seconds: 0.618 s\n",
            "Real time factor (RTF): 0.618 / 15.289 = 0.040\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sherpa-onnx-zh-wenet-multi-cn"
      ],
      "metadata": {
        "id": "93kii7CMLqOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "git lfs install\n",
        "git clone https://huggingface.co/csukuangfj/sherpa-onnx-zh-wenet-multi-cn\n",
        "ls -lh sherpa-onnx-zh-wenet-multi-cn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc6WVbIOMai2",
        "outputId": "f23bfe9c-0082-4919-e436-30ccf8d01d7c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'sherpa-onnx-zh-wenet-multi-cn'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 24 (delta 1), reused 0 (delta 0), pack-reused 3\u001b[K\n",
            "Unpacking objects: 100% (24/24), 393.42 KiB | 6.56 MiB/s, done.\n",
            "Filtering content: 100% (4/4), 385.79 MiB | 66.00 MiB/s, done.\n",
            "total 386M\n",
            "-rw-r--r-- 1 root root  50M Nov 16 03:51 model.int8.onnx\n",
            "-rw-r--r-- 1 root root 144M Nov 16 03:51 model.onnx\n",
            "-rw-r--r-- 1 root root  50M Nov 16 03:51 model-streaming.int8.onnx\n",
            "-rw-r--r-- 1 root root 144M Nov 16 03:51 model-streaming.onnx\n",
            "-rw-r--r-- 1 root root  134 Nov 16 03:51 README.md\n",
            "drwxr-xr-x 2 root root 4.0K Nov 16 03:51 test_wavs\n",
            "-rwxr-xr-x 1 root root 119K Nov 16 03:51 tokens.txt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Streaming decoding"
      ],
      "metadata": {
        "id": "ekCjKVATL1Fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# float32 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-zh-wenet-multi-cn/model-streaming.onnx \\\n",
        "  --tokens=./sherpa-onnx-zh-wenet-multi-cn/tokens.txt \\\n",
        "  ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22156CzZMejj",
        "outputId": "51d50482-f17f-4c8b-b8f8-d3aae00726b3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx --wenet-ctc-model=./sherpa-onnx-zh-wenet-multi-cn/model-streaming.onnx --tokens=./sherpa-onnx-zh-wenet-multi-cn/tokens.txt ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/0.wav ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/1.wav ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/8k.wav \n",
            "\n",
            "OnlineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OnlineModelConfig(transducer=OnlineTransducerModelConfig(encoder=\"\", decoder=\"\", joiner=\"\"), paraformer=OnlineParaformerModelConfig(encoder=\"\", decoder=\"\"), wenet_ctc=OnlineWenetCtcModelConfig(model=\"./sherpa-onnx-zh-wenet-multi-cn/model-streaming.onnx\", chunk_size=16, num_left_chunks=4), tokens=\"./sherpa-onnx-zh-wenet-multi-cn/tokens.txt\", num_threads=1, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OnlineLMConfig(model=\"\", scale=0.5), endpoint_config=EndpointConfig(rule1=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=2.4, min_utterance_length=0), rule2=EndpointRule(must_contain_nonsilence=True, min_trailing_silence=1.2, min_utterance_length=0), rule3=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20)), enable_endpoint=True, max_active_paths=4, hotwords_score=1.5, hotwords_file=\"\", decoding_method=\"greedy_search\")\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/features.cc:AcceptWaveformImpl:85 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "./sherpa-onnx-zh-wenet-multi-cn/test_wavs/0.wav\n",
            "Elapsed seconds: 1.2, Real time factor (RTF): 0.21\n",
            "对我做了介绍啊什么我想说的是呢大家如果对我的研究感兴趣呢\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"对我做了介绍啊什么我想说的是呢大家如果对我的研究感兴趣呢\", \"timestamps\": [0.52, 0.00, 0.16, 0.28, 0.40, 0.56, 0.20, 0.04, 0.16, 0.36, 0.48, 0.60, 0.12, 0.20, 0.32, 0.20, 0.36, 0.48, 0.60, 0.04, 0.12, 0.24, 0.28, 0.44, 0.60, 0.12, 0.32, 0.48], \"tokens\":[\"对\", \"我\", \"做\", \"了\", \"介\", \"绍\", \"啊\", \"什\", \"么\", \"我\", \"想\", \"说\", \"的\", \"是\", \"呢\", \"大\", \"家\", \"如\", \"果\", \"对\", \"我\", \"的\", \"研\", \"究\", \"感\", \"兴\", \"趣\", \"呢\"]}\n",
            "\n",
            "./sherpa-onnx-zh-wenet-multi-cn/test_wavs/1.wav\n",
            "Elapsed seconds: 1.2, Real time factor (RTF): 0.23\n",
            "重点的想看三个问题首先呢就是这一轮全球金融动荡的表现\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"重点的想看三个问题首先呢就是这一轮全球金融动荡的表现\", \"timestamps\": [0.32, 0.48, 0.00, 0.12, 0.28, 0.44, 0.56, 0.08, 0.20, 0.44, 0.60, 0.08, 0.20, 0.36, 0.00, 0.12, 0.28, 0.48, 0.00, 0.12, 0.24, 0.36, 0.44, 0.56, 0.12, 0.32], \"tokens\":[\"重\", \"点\", \"的\", \"想\", \"看\", \"三\", \"个\", \"问\", \"题\", \"首\", \"先\", \"呢\", \"就\", \"是\", \"这\", \"一\", \"轮\", \"全\", \"球\", \"金\", \"融\", \"动\", \"荡\", \"的\", \"表\", \"现\"]}\n",
            "\n",
            "./sherpa-onnx-zh-wenet-multi-cn/test_wavs/8k.wav\n",
            "Elapsed seconds: 1.1, Real time factor (RTF): 0.24\n",
            "删东的分析析这一次全球金融动荡背后的根源\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"删东的分析析这一次全球金融动荡背后的根源\", \"timestamps\": [0.00, 0.08, 0.20, 0.36, 0.48, 0.00, 0.52, 0.04, 0.24, 0.20, 0.36, 0.52, 0.00, 0.16, 0.28, 0.44, 0.56, 0.04, 0.16, 0.36], \"tokens\":[\"删\", \"东\", \"的\", \"分\", \"析\", \"析\", \"这\", \"一\", \"次\", \"全\", \"球\", \"金\", \"融\", \"动\", \"荡\", \"背\", \"后\", \"的\", \"根\", \"源\"]}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# int8 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-zh-wenet-multi-cn/model-streaming.int8.onnx \\\n",
        "  --tokens=./sherpa-onnx-zh-wenet-multi-cn/tokens.txt \\\n",
        "  ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwY6UTorMkZp",
        "outputId": "006c79d0-b423-4cac-98d2-eea57e9630fb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx --wenet-ctc-model=./sherpa-onnx-zh-wenet-multi-cn/model-streaming.int8.onnx --tokens=./sherpa-onnx-zh-wenet-multi-cn/tokens.txt ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/0.wav ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/1.wav ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/8k.wav \n",
            "\n",
            "OnlineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OnlineModelConfig(transducer=OnlineTransducerModelConfig(encoder=\"\", decoder=\"\", joiner=\"\"), paraformer=OnlineParaformerModelConfig(encoder=\"\", decoder=\"\"), wenet_ctc=OnlineWenetCtcModelConfig(model=\"./sherpa-onnx-zh-wenet-multi-cn/model-streaming.int8.onnx\", chunk_size=16, num_left_chunks=4), tokens=\"./sherpa-onnx-zh-wenet-multi-cn/tokens.txt\", num_threads=1, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OnlineLMConfig(model=\"\", scale=0.5), endpoint_config=EndpointConfig(rule1=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=2.4, min_utterance_length=0), rule2=EndpointRule(must_contain_nonsilence=True, min_trailing_silence=1.2, min_utterance_length=0), rule3=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20)), enable_endpoint=True, max_active_paths=4, hotwords_score=1.5, hotwords_file=\"\", decoding_method=\"greedy_search\")\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/features.cc:AcceptWaveformImpl:85 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "./sherpa-onnx-zh-wenet-multi-cn/test_wavs/0.wav\n",
            "Elapsed seconds: 0.91, Real time factor (RTF): 0.16\n",
            "对我做了介绍唉什么我想说的是呢大家如果对我的研究感兴趣呢\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"对我做了介绍唉什么我想说的是呢大家如果对我的研究感兴趣呢\", \"timestamps\": [0.52, 0.00, 0.16, 0.28, 0.40, 0.56, 0.20, 0.04, 0.16, 0.36, 0.48, 0.60, 0.12, 0.20, 0.32, 0.20, 0.36, 0.48, 0.60, 0.04, 0.12, 0.24, 0.28, 0.44, 0.60, 0.12, 0.32, 0.48], \"tokens\":[\"对\", \"我\", \"做\", \"了\", \"介\", \"绍\", \"唉\", \"什\", \"么\", \"我\", \"想\", \"说\", \"的\", \"是\", \"呢\", \"大\", \"家\", \"如\", \"果\", \"对\", \"我\", \"的\", \"研\", \"究\", \"感\", \"兴\", \"趣\", \"呢\"]}\n",
            "\n",
            "./sherpa-onnx-zh-wenet-multi-cn/test_wavs/1.wav\n",
            "Elapsed seconds: 0.91, Real time factor (RTF): 0.18\n",
            "重点的想看三个问题首先呢就是这一轮全球金融动荡的表现\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"重点的想看三个问题首先呢就是这一轮全球金融动荡的表现\", \"timestamps\": [0.32, 0.48, 0.00, 0.12, 0.28, 0.44, 0.56, 0.08, 0.20, 0.44, 0.60, 0.08, 0.20, 0.36, 0.00, 0.12, 0.28, 0.48, 0.00, 0.12, 0.24, 0.36, 0.44, 0.56, 0.12, 0.32], \"tokens\":[\"重\", \"点\", \"的\", \"想\", \"看\", \"三\", \"个\", \"问\", \"题\", \"首\", \"先\", \"呢\", \"就\", \"是\", \"这\", \"一\", \"轮\", \"全\", \"球\", \"金\", \"融\", \"动\", \"荡\", \"的\", \"表\", \"现\"]}\n",
            "\n",
            "./sherpa-onnx-zh-wenet-multi-cn/test_wavs/8k.wav\n",
            "Elapsed seconds: 0.84, Real time factor (RTF): 0.19\n",
            "删东的分析析这一次全球金融动荡背后的根源\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"删东的分析析这一次全球金融动荡背后的根源\", \"timestamps\": [0.00, 0.08, 0.20, 0.36, 0.48, 0.00, 0.52, 0.04, 0.24, 0.20, 0.36, 0.52, 0.00, 0.16, 0.28, 0.44, 0.56, 0.04, 0.16, 0.36], \"tokens\":[\"删\", \"东\", \"的\", \"分\", \"析\", \"析\", \"这\", \"一\", \"次\", \"全\", \"球\", \"金\", \"融\", \"动\", \"荡\", \"背\", \"后\", \"的\", \"根\", \"源\"]}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-streaming decoding"
      ],
      "metadata": {
        "id": "NXoAhtCtMnV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# float32 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx-offline \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-zh-wenet-multi-cn/model.onnx \\\n",
        "  --tokens=./sherpa-onnx-zh-wenet-multi-cn/tokens.txt \\\n",
        "  ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGtFm-3YMp6g",
        "outputId": "5c20c8b1-632e-495c-e5b4-de3a0a919000"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx-offline --wenet-ctc-model=./sherpa-onnx-zh-wenet-multi-cn/model.onnx --tokens=./sherpa-onnx-zh-wenet-multi-cn/tokens.txt ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/0.wav ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/1.wav ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/8k.wav \n",
            "\n",
            "OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=\"\", decoder_filename=\"\", joiner_filename=\"\"), paraformer=OfflineParaformerModelConfig(model=\"\"), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=\"\"), whisper=OfflineWhisperModelConfig(encoder=\"\", decoder=\"\", language=\"\", task=\"transcribe\"), tdnn=OfflineTdnnModelConfig(model=\"\"), zipformer_ctc=OfflineZipformerCtcModelConfig(model=\"\"), wenet_ctc=OfflineWenetCtcModelConfig(model=\"./sherpa-onnx-zh-wenet-multi-cn/model.onnx\"), tokens=\"./sherpa-onnx-zh-wenet-multi-cn/tokens.txt\", num_threads=2, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OfflineLMConfig(model=\"\", scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=\"\", max_active=3000), decoding_method=\"greedy_search\", max_active_paths=4, hotwords_file=\"\", hotwords_score=1.5)\n",
            "Creating recognizer ...\n",
            "Started\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/offline-stream.cc:AcceptWaveformImpl:113 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "Done!\n",
            "\n",
            "./sherpa-onnx-zh-wenet-multi-cn/test_wavs/0.wav\n",
            "{\"text\": \"对我做了介绍哈什么我想说的是呢大家如果对我的研究感兴趣呢\", \"timestamps\": [0.48, 0.64, 0.80, 0.92, 1.04, 1.20, 1.48, 1.96, 2.08, 2.28, 2.40, 2.52, 2.68, 2.76, 2.92, 3.40, 3.56, 3.68, 3.80, 3.92, 4.00, 4.08, 4.16, 4.28, 4.40, 4.60, 4.80, 4.96], \"tokens\":[\"对\", \"我\", \"做\", \"了\", \"介\", \"绍\", \"哈\", \"什\", \"么\", \"我\", \"想\", \"说\", \"的\", \"是\", \"呢\", \"大\", \"家\", \"如\", \"果\", \"对\", \"我\", \"的\", \"研\", \"究\", \"感\", \"兴\", \"趣\", \"呢\"]}\n",
            "----\n",
            "./sherpa-onnx-zh-wenet-multi-cn/test_wavs/1.wav\n",
            "{\"text\": \"重点的想看三个问题首先呢就是这一轮全球进融动荡的表现\", \"timestamps\": [0.32, 0.48, 0.60, 0.76, 0.92, 1.08, 1.20, 1.36, 1.52, 2.32, 2.48, 2.64, 2.76, 2.92, 3.20, 3.32, 3.44, 3.68, 3.84, 3.96, 4.08, 4.20, 4.32, 4.44, 4.60, 4.80], \"tokens\":[\"重\", \"点\", \"的\", \"想\", \"看\", \"三\", \"个\", \"问\", \"题\", \"首\", \"先\", \"呢\", \"就\", \"是\", \"这\", \"一\", \"轮\", \"全\", \"球\", \"进\", \"融\", \"动\", \"荡\", \"的\", \"表\", \"现\"]}\n",
            "----\n",
            "./sherpa-onnx-zh-wenet-multi-cn/test_wavs/8k.wav\n",
            "{\"text\": \"深猪的分析师这一次全球金融动荡背后的根源\", \"timestamps\": [0.56, 0.72, 0.84, 1.00, 1.12, 1.32, 1.80, 1.96, 2.12, 2.72, 2.92, 3.08, 3.20, 3.36, 3.48, 3.64, 3.76, 3.88, 4.00, 4.20], \"tokens\":[\"深\", \"猪\", \"的\", \"分\", \"析\", \"师\", \"这\", \"一\", \"次\", \"全\", \"球\", \"金\", \"融\", \"动\", \"荡\", \"背\", \"后\", \"的\", \"根\", \"源\"]}\n",
            "----\n",
            "num threads: 2\n",
            "decoding method: greedy_search\n",
            "Elapsed seconds: 1.996 s\n",
            "Real time factor (RTF): 1.996 / 15.289 = 0.131\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# int8 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx-offline \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-zh-wenet-multi-cn/model.int8.onnx \\\n",
        "  --tokens=./sherpa-onnx-zh-wenet-multi-cn/tokens.txt \\\n",
        "  ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pp39zoI_MsVh",
        "outputId": "0fad3cb5-abee-455b-f390-a7da25bb6123"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx-offline --wenet-ctc-model=./sherpa-onnx-zh-wenet-multi-cn/model.int8.onnx --tokens=./sherpa-onnx-zh-wenet-multi-cn/tokens.txt ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/0.wav ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/1.wav ./sherpa-onnx-zh-wenet-multi-cn/test_wavs/8k.wav \n",
            "\n",
            "OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=\"\", decoder_filename=\"\", joiner_filename=\"\"), paraformer=OfflineParaformerModelConfig(model=\"\"), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=\"\"), whisper=OfflineWhisperModelConfig(encoder=\"\", decoder=\"\", language=\"\", task=\"transcribe\"), tdnn=OfflineTdnnModelConfig(model=\"\"), zipformer_ctc=OfflineZipformerCtcModelConfig(model=\"\"), wenet_ctc=OfflineWenetCtcModelConfig(model=\"./sherpa-onnx-zh-wenet-multi-cn/model.int8.onnx\"), tokens=\"./sherpa-onnx-zh-wenet-multi-cn/tokens.txt\", num_threads=2, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OfflineLMConfig(model=\"\", scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=\"\", max_active=3000), decoding_method=\"greedy_search\", max_active_paths=4, hotwords_file=\"\", hotwords_score=1.5)\n",
            "Creating recognizer ...\n",
            "Started\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/offline-stream.cc:AcceptWaveformImpl:113 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "Done!\n",
            "\n",
            "./sherpa-onnx-zh-wenet-multi-cn/test_wavs/0.wav\n",
            "{\"text\": \"对我做了介绍哈什么我想说的是呢大家如果对我的研究感兴趣呢\", \"timestamps\": [0.48, 0.64, 0.80, 0.92, 1.04, 1.24, 1.48, 1.96, 2.08, 2.28, 2.40, 2.52, 2.68, 2.76, 2.92, 3.40, 3.56, 3.68, 3.80, 3.88, 4.00, 4.08, 4.16, 4.28, 4.40, 4.60, 4.80, 4.96], \"tokens\":[\"对\", \"我\", \"做\", \"了\", \"介\", \"绍\", \"哈\", \"什\", \"么\", \"我\", \"想\", \"说\", \"的\", \"是\", \"呢\", \"大\", \"家\", \"如\", \"果\", \"对\", \"我\", \"的\", \"研\", \"究\", \"感\", \"兴\", \"趣\", \"呢\"]}\n",
            "----\n",
            "./sherpa-onnx-zh-wenet-multi-cn/test_wavs/1.wav\n",
            "{\"text\": \"重点的想看三个问题首先呢就是这一轮全球进融动荡的表现\", \"timestamps\": [0.32, 0.48, 0.60, 0.76, 0.92, 1.08, 1.20, 1.36, 1.52, 2.32, 2.48, 2.64, 2.76, 2.92, 3.20, 3.32, 3.44, 3.68, 3.84, 3.96, 4.08, 4.20, 4.32, 4.44, 4.60, 4.80], \"tokens\":[\"重\", \"点\", \"的\", \"想\", \"看\", \"三\", \"个\", \"问\", \"题\", \"首\", \"先\", \"呢\", \"就\", \"是\", \"这\", \"一\", \"轮\", \"全\", \"球\", \"进\", \"融\", \"动\", \"荡\", \"的\", \"表\", \"现\"]}\n",
            "----\n",
            "./sherpa-onnx-zh-wenet-multi-cn/test_wavs/8k.wav\n",
            "{\"text\": \"深猪的分析师这一次全球金融动荡背后的根源\", \"timestamps\": [0.56, 0.72, 0.84, 1.00, 1.12, 1.32, 1.80, 1.96, 2.12, 2.72, 2.92, 3.08, 3.20, 3.36, 3.48, 3.64, 3.76, 3.88, 4.00, 4.20], \"tokens\":[\"深\", \"猪\", \"的\", \"分\", \"析\", \"师\", \"这\", \"一\", \"次\", \"全\", \"球\", \"金\", \"融\", \"动\", \"荡\", \"背\", \"后\", \"的\", \"根\", \"源\"]}\n",
            "----\n",
            "num threads: 2\n",
            "decoding method: greedy_search\n",
            "Elapsed seconds: 0.659 s\n",
            "Real time factor (RTF): 0.659 / 15.289 = 0.043\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sherpa-onnx-zh-wenet-wenetspeech"
      ],
      "metadata": {
        "id": "xQg4P_SmLryX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "git lfs install\n",
        "git clone https://huggingface.co/csukuangfj/sherpa-onnx-zh-wenet-wenetspeech\n",
        "ls -lh sherpa-onnx-zh-wenet-wenetspeech"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z2AyeqdMzw3",
        "outputId": "3eabce85-174e-464c-a07e-8d1db75f99ff"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'sherpa-onnx-zh-wenet-wenetspeech'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 24 (delta 1), reused 0 (delta 0), pack-reused 3\u001b[K\n",
            "Unpacking objects: 100% (24/24), 367.04 KiB | 5.40 MiB/s, done.\n",
            "Filtering content: 100% (4/4), 930.41 MiB | 54.44 MiB/s, done.\n",
            "total 931M\n",
            "-rw-r--r-- 1 root root 128M Nov 16 03:51 model.int8.onnx\n",
            "-rw-r--r-- 1 root root 339M Nov 16 03:52 model.onnx\n",
            "-rw-r--r-- 1 root root 127M Nov 16 03:52 model-streaming.int8.onnx\n",
            "-rw-r--r-- 1 root root 339M Nov 16 03:52 model-streaming.onnx\n",
            "-rw-r--r-- 1 root root  134 Nov 16 03:51 README.md\n",
            "drwxr-xr-x 2 root root 4.0K Nov 16 03:51 test_wavs\n",
            "-rwxr-xr-x 1 root root  48K Nov 16 03:51 tokens.txt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Streaming decoding"
      ],
      "metadata": {
        "id": "ztg_sDfzM61a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# float32 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-zh-wenet-wenetspeech/model-streaming.onnx \\\n",
        "  --tokens=./sherpa-onnx-zh-wenet-wenetspeech/tokens.txt \\\n",
        "  ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj5ccCafM-Je",
        "outputId": "789ab502-080d-46b3-8458-f9325118ce29"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx --wenet-ctc-model=./sherpa-onnx-zh-wenet-wenetspeech/model-streaming.onnx --tokens=./sherpa-onnx-zh-wenet-wenetspeech/tokens.txt ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/0.wav ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/1.wav ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/8k.wav \n",
            "\n",
            "OnlineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OnlineModelConfig(transducer=OnlineTransducerModelConfig(encoder=\"\", decoder=\"\", joiner=\"\"), paraformer=OnlineParaformerModelConfig(encoder=\"\", decoder=\"\"), wenet_ctc=OnlineWenetCtcModelConfig(model=\"./sherpa-onnx-zh-wenet-wenetspeech/model-streaming.onnx\", chunk_size=16, num_left_chunks=4), tokens=\"./sherpa-onnx-zh-wenet-wenetspeech/tokens.txt\", num_threads=1, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OnlineLMConfig(model=\"\", scale=0.5), endpoint_config=EndpointConfig(rule1=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=2.4, min_utterance_length=0), rule2=EndpointRule(must_contain_nonsilence=True, min_trailing_silence=1.2, min_utterance_length=0), rule3=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20)), enable_endpoint=True, max_active_paths=4, hotwords_score=1.5, hotwords_file=\"\", decoding_method=\"greedy_search\")\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/features.cc:AcceptWaveformImpl:85 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/0.wav\n",
            "Elapsed seconds: 3.8, Real time factor (RTF): 0.69\n",
            "对我做了介绍那么我想做的是呢大家如果对我的研究感兴趣呢\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"对我做了介绍那么我想做的是呢大家如果对我的研究感兴趣呢\", \"timestamps\": [0.48, 0.00, 0.16, 0.28, 0.40, 0.56, 0.04, 0.16, 0.36, 0.48, 0.60, 0.08, 0.20, 0.36, 0.20, 0.32, 0.48, 0.56, 0.04, 0.12, 0.20, 0.32, 0.44, 0.56, 0.12, 0.28, 0.48], \"tokens\":[\"对\", \"我\", \"做\", \"了\", \"介\", \"绍\", \"那\", \"么\", \"我\", \"想\", \"做\", \"的\", \"是\", \"呢\", \"大\", \"家\", \"如\", \"果\", \"对\", \"我\", \"的\", \"研\", \"究\", \"感\", \"兴\", \"趣\", \"呢\"]}\n",
            "\n",
            "./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/1.wav\n",
            "Elapsed seconds: 3.8, Real time factor (RTF): 0.75\n",
            "重点来想谈三个问题首先呢就是这一轮全球金融动荡的表现\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"重点来想谈三个问题首先呢就是这一轮全球金融动荡的表现\", \"timestamps\": [0.32, 0.48, 0.00, 0.12, 0.28, 0.44, 0.56, 0.04, 0.16, 0.40, 0.56, 0.08, 0.20, 0.36, 0.00, 0.12, 0.24, 0.48, 0.00, 0.12, 0.24, 0.36, 0.48, 0.56, 0.12, 0.28], \"tokens\":[\"重\", \"点\", \"来\", \"想\", \"谈\", \"三\", \"个\", \"问\", \"题\", \"首\", \"先\", \"呢\", \"就\", \"是\", \"这\", \"一\", \"轮\", \"全\", \"球\", \"金\", \"融\", \"动\", \"荡\", \"的\", \"表\", \"现\"]}\n",
            "\n",
            "./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/8k.wav\n",
            "Elapsed seconds: 3.6, Real time factor (RTF): 0.8\n",
            "山柱的分析这一次全球金融动荡背后的根源\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"山柱的分析这一次全球金融动荡背后的根源\", \"timestamps\": [0.00, 0.08, 0.20, 0.36, 0.60, 0.52, 0.04, 0.20, 0.16, 0.36, 0.52, 0.00, 0.12, 0.28, 0.40, 0.52, 0.00, 0.16, 0.32], \"tokens\":[\"山\", \"柱\", \"的\", \"分\", \"析\", \"这\", \"一\", \"次\", \"全\", \"球\", \"金\", \"融\", \"动\", \"荡\", \"背\", \"后\", \"的\", \"根\", \"源\"]}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# int8 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-zh-wenet-wenetspeech/model-streaming.int8.onnx \\\n",
        "  --tokens=./sherpa-onnx-zh-wenet-wenetspeech/tokens.txt \\\n",
        "  ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltC0GXDqNFiI",
        "outputId": "d00072cf-e2a1-4c18-f52c-3bfec46123da"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx --wenet-ctc-model=./sherpa-onnx-zh-wenet-wenetspeech/model-streaming.int8.onnx --tokens=./sherpa-onnx-zh-wenet-wenetspeech/tokens.txt ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/0.wav ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/1.wav ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/8k.wav \n",
            "\n",
            "OnlineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OnlineModelConfig(transducer=OnlineTransducerModelConfig(encoder=\"\", decoder=\"\", joiner=\"\"), paraformer=OnlineParaformerModelConfig(encoder=\"\", decoder=\"\"), wenet_ctc=OnlineWenetCtcModelConfig(model=\"./sherpa-onnx-zh-wenet-wenetspeech/model-streaming.int8.onnx\", chunk_size=16, num_left_chunks=4), tokens=\"./sherpa-onnx-zh-wenet-wenetspeech/tokens.txt\", num_threads=1, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OnlineLMConfig(model=\"\", scale=0.5), endpoint_config=EndpointConfig(rule1=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=2.4, min_utterance_length=0), rule2=EndpointRule(must_contain_nonsilence=True, min_trailing_silence=1.2, min_utterance_length=0), rule3=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20)), enable_endpoint=True, max_active_paths=4, hotwords_score=1.5, hotwords_file=\"\", decoding_method=\"greedy_search\")\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/features.cc:AcceptWaveformImpl:85 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/0.wav\n",
            "Elapsed seconds: 2.8, Real time factor (RTF): 0.49\n",
            "对我做了介绍那么我想做的是呢大家如果对我的研究感兴趣呢\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"对我做了介绍那么我想做的是呢大家如果对我的研究感兴趣呢\", \"timestamps\": [0.48, 0.00, 0.16, 0.28, 0.40, 0.60, 0.04, 0.16, 0.36, 0.48, 0.00, 0.08, 0.20, 0.36, 0.20, 0.32, 0.48, 0.56, 0.04, 0.12, 0.20, 0.32, 0.44, 0.56, 0.12, 0.28, 0.48], \"tokens\":[\"对\", \"我\", \"做\", \"了\", \"介\", \"绍\", \"那\", \"么\", \"我\", \"想\", \"做\", \"的\", \"是\", \"呢\", \"大\", \"家\", \"如\", \"果\", \"对\", \"我\", \"的\", \"研\", \"究\", \"感\", \"兴\", \"趣\", \"呢\"]}\n",
            "\n",
            "./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/1.wav\n",
            "Elapsed seconds: 2.8, Real time factor (RTF): 0.54\n",
            "重点来想谈三个问题首先呢就是这一轮全球金融动荡的表现\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"重点来想谈三个问题首先呢就是这一轮全球金融动荡的表现\", \"timestamps\": [0.32, 0.48, 0.00, 0.12, 0.28, 0.44, 0.56, 0.04, 0.16, 0.40, 0.56, 0.08, 0.20, 0.36, 0.00, 0.12, 0.24, 0.48, 0.00, 0.12, 0.24, 0.36, 0.48, 0.56, 0.12, 0.28], \"tokens\":[\"重\", \"点\", \"来\", \"想\", \"谈\", \"三\", \"个\", \"问\", \"题\", \"首\", \"先\", \"呢\", \"就\", \"是\", \"这\", \"一\", \"轮\", \"全\", \"球\", \"金\", \"融\", \"动\", \"荡\", \"的\", \"表\", \"现\"]}\n",
            "\n",
            "./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/8k.wav\n",
            "Elapsed seconds: 2.5, Real time factor (RTF): 0.55\n",
            "山柱的分析这一次全球金融动荡背后的根源\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \"山柱的分析这一次全球金融动荡背后的根源\", \"timestamps\": [0.00, 0.08, 0.20, 0.36, 0.60, 0.52, 0.04, 0.20, 0.16, 0.36, 0.52, 0.00, 0.12, 0.28, 0.40, 0.52, 0.00, 0.16, 0.32], \"tokens\":[\"山\", \"柱\", \"的\", \"分\", \"析\", \"这\", \"一\", \"次\", \"全\", \"球\", \"金\", \"融\", \"动\", \"荡\", \"背\", \"后\", \"的\", \"根\", \"源\"]}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-streaming decoding"
      ],
      "metadata": {
        "id": "0rDU5rU5M8EC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# float32 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx-offline \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-zh-wenet-wenetspeech/model.onnx \\\n",
        "  --tokens=./sherpa-onnx-zh-wenet-wenetspeech/tokens.txt \\\n",
        "  ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc7whE6xLMmq",
        "outputId": "1de941bc-02bd-4711-bffa-a6ec97308a30"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx-offline --wenet-ctc-model=./sherpa-onnx-zh-wenet-wenetspeech/model.onnx --tokens=./sherpa-onnx-zh-wenet-wenetspeech/tokens.txt ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/0.wav ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/1.wav ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/8k.wav \n",
            "\n",
            "OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=\"\", decoder_filename=\"\", joiner_filename=\"\"), paraformer=OfflineParaformerModelConfig(model=\"\"), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=\"\"), whisper=OfflineWhisperModelConfig(encoder=\"\", decoder=\"\", language=\"\", task=\"transcribe\"), tdnn=OfflineTdnnModelConfig(model=\"\"), zipformer_ctc=OfflineZipformerCtcModelConfig(model=\"\"), wenet_ctc=OfflineWenetCtcModelConfig(model=\"./sherpa-onnx-zh-wenet-wenetspeech/model.onnx\"), tokens=\"./sherpa-onnx-zh-wenet-wenetspeech/tokens.txt\", num_threads=2, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OfflineLMConfig(model=\"\", scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=\"\", max_active=3000), decoding_method=\"greedy_search\", max_active_paths=4, hotwords_file=\"\", hotwords_score=1.5)\n",
            "Creating recognizer ...\n",
            "Started\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/offline-stream.cc:AcceptWaveformImpl:113 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "Done!\n",
            "\n",
            "./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/0.wav\n",
            "{\"text\": \"对我做了介绍那么我想说的是大家如果对我的研究感兴趣呢\", \"timestamps\": [0.48, 0.64, 0.76, 0.88, 1.04, 1.24, 1.96, 2.08, 2.28, 2.40, 2.52, 2.64, 2.76, 3.40, 3.52, 3.68, 3.76, 3.88, 3.96, 4.04, 4.16, 4.28, 4.40, 4.60, 4.76, 4.96], \"tokens\":[\"对\", \"我\", \"做\", \"了\", \"介\", \"绍\", \"那\", \"么\", \"我\", \"想\", \"说\", \"的\", \"是\", \"大\", \"家\", \"如\", \"果\", \"对\", \"我\", \"的\", \"研\", \"究\", \"感\", \"兴\", \"趣\", \"呢\"]}\n",
            "----\n",
            "./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/1.wav\n",
            "{\"text\": \"重点来想谈三个问题首先呢就是这一轮全球金融动荡的表现\", \"timestamps\": [0.32, 0.48, 0.60, 0.76, 0.92, 1.08, 1.20, 1.36, 1.48, 2.32, 2.48, 2.64, 2.76, 2.92, 3.20, 3.32, 3.44, 3.68, 3.84, 3.96, 4.08, 4.20, 4.32, 4.44, 4.60, 4.76], \"tokens\":[\"重\", \"点\", \"来\", \"想\", \"谈\", \"三\", \"个\", \"问\", \"题\", \"首\", \"先\", \"呢\", \"就\", \"是\", \"这\", \"一\", \"轮\", \"全\", \"球\", \"金\", \"融\", \"动\", \"荡\", \"的\", \"表\", \"现\"]}\n",
            "----\n",
            "./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/8k.wav\n",
            "{\"text\": \"深入地分析这一次全球金融动荡背后的根源\", \"timestamps\": [0.56, 0.72, 0.84, 1.00, 1.24, 1.76, 1.92, 2.12, 2.72, 2.92, 3.08, 3.20, 3.32, 3.48, 3.60, 3.72, 3.84, 4.00, 4.16], \"tokens\":[\"深\", \"入\", \"地\", \"分\", \"析\", \"这\", \"一\", \"次\", \"全\", \"球\", \"金\", \"融\", \"动\", \"荡\", \"背\", \"后\", \"的\", \"根\", \"源\"]}\n",
            "----\n",
            "num threads: 2\n",
            "decoding method: greedy_search\n",
            "Elapsed seconds: 1.830 s\n",
            "Real time factor (RTF): 1.830 / 15.289 = 0.120\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# int8 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx-offline \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-zh-wenet-wenetspeech/model.int8.onnx \\\n",
        "  --tokens=./sherpa-onnx-zh-wenet-wenetspeech/tokens.txt \\\n",
        "  ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKWqlFyHNM-c",
        "outputId": "963961d9-d382-490f-b06c-9afcff5d66a0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx-offline --wenet-ctc-model=./sherpa-onnx-zh-wenet-wenetspeech/model.int8.onnx --tokens=./sherpa-onnx-zh-wenet-wenetspeech/tokens.txt ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/0.wav ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/1.wav ./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/8k.wav \n",
            "\n",
            "OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=\"\", decoder_filename=\"\", joiner_filename=\"\"), paraformer=OfflineParaformerModelConfig(model=\"\"), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=\"\"), whisper=OfflineWhisperModelConfig(encoder=\"\", decoder=\"\", language=\"\", task=\"transcribe\"), tdnn=OfflineTdnnModelConfig(model=\"\"), zipformer_ctc=OfflineZipformerCtcModelConfig(model=\"\"), wenet_ctc=OfflineWenetCtcModelConfig(model=\"./sherpa-onnx-zh-wenet-wenetspeech/model.int8.onnx\"), tokens=\"./sherpa-onnx-zh-wenet-wenetspeech/tokens.txt\", num_threads=2, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OfflineLMConfig(model=\"\", scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=\"\", max_active=3000), decoding_method=\"greedy_search\", max_active_paths=4, hotwords_file=\"\", hotwords_score=1.5)\n",
            "Creating recognizer ...\n",
            "Started\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/offline-stream.cc:AcceptWaveformImpl:113 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "Done!\n",
            "\n",
            "./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/0.wav\n",
            "{\"text\": \"对我做了介绍那么我想说的是大家如果对我的研究感兴趣呢\", \"timestamps\": [0.48, 0.64, 0.76, 0.88, 1.04, 1.24, 1.96, 2.08, 2.28, 2.40, 2.52, 2.64, 2.76, 3.40, 3.52, 3.68, 3.76, 3.88, 3.96, 4.04, 4.16, 4.28, 4.40, 4.60, 4.76, 4.96], \"tokens\":[\"对\", \"我\", \"做\", \"了\", \"介\", \"绍\", \"那\", \"么\", \"我\", \"想\", \"说\", \"的\", \"是\", \"大\", \"家\", \"如\", \"果\", \"对\", \"我\", \"的\", \"研\", \"究\", \"感\", \"兴\", \"趣\", \"呢\"]}\n",
            "----\n",
            "./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/1.wav\n",
            "{\"text\": \"重点来想谈三个问题首先呢就是这一轮全球金融动荡的表现\", \"timestamps\": [0.32, 0.48, 0.60, 0.76, 0.92, 1.08, 1.20, 1.36, 1.48, 2.32, 2.48, 2.64, 2.76, 2.92, 3.20, 3.32, 3.44, 3.68, 3.84, 3.96, 4.08, 4.20, 4.32, 4.44, 4.60, 4.80], \"tokens\":[\"重\", \"点\", \"来\", \"想\", \"谈\", \"三\", \"个\", \"问\", \"题\", \"首\", \"先\", \"呢\", \"就\", \"是\", \"这\", \"一\", \"轮\", \"全\", \"球\", \"金\", \"融\", \"动\", \"荡\", \"的\", \"表\", \"现\"]}\n",
            "----\n",
            "./sherpa-onnx-zh-wenet-wenetspeech/test_wavs/8k.wav\n",
            "{\"text\": \"深入地分析这一次全球金融动荡背后的根源\", \"timestamps\": [0.56, 0.72, 0.84, 1.00, 1.24, 1.76, 1.92, 2.12, 2.72, 2.92, 3.08, 3.20, 3.32, 3.48, 3.60, 3.72, 3.84, 4.00, 4.16], \"tokens\":[\"深\", \"入\", \"地\", \"分\", \"析\", \"这\", \"一\", \"次\", \"全\", \"球\", \"金\", \"融\", \"动\", \"荡\", \"背\", \"后\", \"的\", \"根\", \"源\"]}\n",
            "----\n",
            "num threads: 2\n",
            "decoding method: greedy_search\n",
            "Elapsed seconds: 1.599 s\n",
            "Real time factor (RTF): 1.599 / 15.289 = 0.105\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sherpa-onnx-zh-wenet-librispeech"
      ],
      "metadata": {
        "id": "Xrg6SdRTNV0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "git lfs install\n",
        "git clone https://huggingface.co/csukuangfj/sherpa-onnx-en-wenet-librispeech\n",
        "ls -lh sherpa-onnx-en-wenet-librispeech"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72GxSy-2NjBY",
        "outputId": "59d06810-71d8-436a-efe0-c6ae89065b49"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'sherpa-onnx-en-wenet-librispeech'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 25 (delta 1), reused 0 (delta 0), pack-reused 3\u001b[K\n",
            "Unpacking objects: 100% (25/25), 690.81 KiB | 7.12 MiB/s, done.\n",
            "Filtering content: 100% (4/4), 371.03 MiB | 66.20 MiB/s, done.\n",
            "total 372M\n",
            "-rw-r--r-- 1 root root  48M Nov 16 03:52 model.int8.onnx\n",
            "-rw-r--r-- 1 root root 138M Nov 16 03:52 model.onnx\n",
            "-rw-r--r-- 1 root root  48M Nov 16 03:52 model-streaming.int8.onnx\n",
            "-rw-r--r-- 1 root root 138M Nov 16 03:52 model-streaming.onnx\n",
            "-rw-r--r-- 1 root root  134 Nov 16 03:52 README.md\n",
            "drwxr-xr-x 2 root root 4.0K Nov 16 03:52 test_wavs\n",
            "-rwxr-xr-x 1 root root  69K Nov 16 03:52 tokens.txt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Streaming decoding"
      ],
      "metadata": {
        "id": "JvITcEYrNYnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# float32 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-en-wenet-librispeech/model-streaming.onnx \\\n",
        "  --tokens=./sherpa-onnx-en-wenet-librispeech/tokens.txt \\\n",
        "  ./sherpa-onnx-en-wenet-librispeech/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-en-wenet-librispeech/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-en-wenet-librispeech/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzGfzt7HNp7O",
        "outputId": "c2b0c71e-8d38-498e-d9bf-b72484337357"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx --wenet-ctc-model=./sherpa-onnx-en-wenet-librispeech/model-streaming.onnx --tokens=./sherpa-onnx-en-wenet-librispeech/tokens.txt ./sherpa-onnx-en-wenet-librispeech/test_wavs/0.wav ./sherpa-onnx-en-wenet-librispeech/test_wavs/1.wav ./sherpa-onnx-en-wenet-librispeech/test_wavs/8k.wav \n",
            "\n",
            "OnlineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OnlineModelConfig(transducer=OnlineTransducerModelConfig(encoder=\"\", decoder=\"\", joiner=\"\"), paraformer=OnlineParaformerModelConfig(encoder=\"\", decoder=\"\"), wenet_ctc=OnlineWenetCtcModelConfig(model=\"./sherpa-onnx-en-wenet-librispeech/model-streaming.onnx\", chunk_size=16, num_left_chunks=4), tokens=\"./sherpa-onnx-en-wenet-librispeech/tokens.txt\", num_threads=1, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OnlineLMConfig(model=\"\", scale=0.5), endpoint_config=EndpointConfig(rule1=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=2.4, min_utterance_length=0), rule2=EndpointRule(must_contain_nonsilence=True, min_trailing_silence=1.2, min_utterance_length=0), rule3=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20)), enable_endpoint=True, max_active_paths=4, hotwords_score=1.5, hotwords_file=\"\", decoding_method=\"greedy_search\")\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/features.cc:AcceptWaveformImpl:85 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "./sherpa-onnx-en-wenet-librispeech/test_wavs/0.wav\n",
            "Elapsed seconds: 1.4, Real time factor (RTF): 0.2\n",
            " AFTER EARLYLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROFFELS\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \" AFTER EARLYLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROFFELS\", \"timestamps\": [0.16, 0.48, 0.60, 0.00, 0.24, 0.48, 0.16, 0.32, 0.04, 0.20, 0.36, 0.60, 0.20, 0.44, 0.00, 0.24, 0.00, 0.16, 0.28, 0.40, 0.12, 0.48, 0.00, 0.08, 0.20, 0.28, 0.40, 0.48], \"tokens\":[\" AFTER\", \" EAR\", \"LY\", \"LY\", \" NIGHT\", \"FALL\", \" THE\", \" YELLOW\", \" LAMP\", \"S\", \" WOULD\", \" LIGHT\", \" UP\", \" HERE\", \" AND\", \" THERE\", \" THE\", \" SQU\", \"AL\", \"ID\", \" QUARTER\", \" OF\", \" THE\", \" \", \"BRO\", \"FF\", \"EL\", \"S\"]}\n",
            "\n",
            "./sherpa-onnx-en-wenet-librispeech/test_wavs/1.wav\n",
            "Elapsed seconds: 2, Real time factor (RTF): 0.12\n",
            " GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONORED BOSOM TO CONNECT HER PARENTRO FOR EVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \" GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONORED BOSOM TO CONNECT HER PARENTRO FOR EVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN\", \"timestamps\": [0.08, 0.40, 0.60, 0.16, 0.56, 0.48, 0.04, 0.20, 0.48, 0.08, 0.36, 0.44, 0.04, 0.24, 0.12, 0.32, 0.44, 0.00, 0.24, 0.40, 0.60, 0.20, 0.24, 0.32, 0.60, 0.28, 0.48, 0.08, 0.36, 0.12, 0.24, 0.40, 0.48, 0.08, 0.52, 0.20, 0.48, 0.04, 0.16, 0.12, 0.32, 0.56, 0.08, 0.28, 0.04, 0.40, 0.08, 0.32, 0.60, 0.52, 0.04, 0.20, 0.44, 0.00, 0.24, 0.44, 0.60, 0.36, 0.08, 0.28], \"tokens\":[\" GOD\", \" AS\", \" A\", \" DIRECT\", \" CONSEQUENCE\", \" OF\", \" THE\", \" SIN\", \" WHICH\", \" MAN\", \" THU\", \"S\", \" PUNISH\", \"ED\", \" HAD\", \" GIVE\", \"N\", \" HER\", \" A\", \" LOVE\", \"LY\", \" CHILD\", \" WHO\", \"SE\", \" PLACE\", \" WAS\", \" ON\", \" THAT\", \" SAME\", \" DISH\", \"ON\", \"OR\", \"ED\", \" BOSOM\", \" TO\", \" CONNECT\", \" HER\", \" PARENT\", \"RO\", \" FOR\", \" EVER\", \" WITH\", \" THE\", \" RACE\", \" AND\", \" DESCENT\", \" OF\", \" MORTAL\", \"S\", \" AND\", \" TO\", \" BE\", \" FINAL\", \"LY\", \" A\", \" BLESS\", \"ED\", \" SOUL\", \" IN\", \" HEAVEN\"]}\n",
            "\n",
            "./sherpa-onnx-en-wenet-librispeech/test_wavs/8k.wav\n",
            "Elapsed seconds: 1.1, Real time factor (RTF): 0.23\n",
            " YET THESE THOUGHTS AFFECTED HESTER PRYNNNE LESS WITH HOPE THAN APPREHENSION\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \" YET THESE THOUGHTS AFFECTED HESTER PRYNNNE LESS WITH HOPE THAN APPREHENSION\", \"timestamps\": [0.12, 0.40, 0.04, 0.16, 0.40, 0.12, 0.32, 0.48, 0.56, 0.60, 0.00, 0.04, 0.32, 0.04, 0.24, 0.08, 0.60], \"tokens\":[\" YET\", \" THESE\", \" THOUGHT\", \"S\", \" AFFECTED\", \" HE\", \"STER\", \" P\", \"RY\", \"N\", \"N\", \"NE\", \" LESS\", \" WITH\", \" HOPE\", \" THAN\", \" APPREHENSION\"]}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# int8 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-en-wenet-librispeech/model-streaming.int8.onnx \\\n",
        "  --tokens=./sherpa-onnx-en-wenet-librispeech/tokens.txt \\\n",
        "  ./sherpa-onnx-en-wenet-librispeech/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-en-wenet-librispeech/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-en-wenet-librispeech/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7gyp-FrNxtu",
        "outputId": "3b9329ef-48ad-4443-eab9-18bd444487f6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx --wenet-ctc-model=./sherpa-onnx-en-wenet-librispeech/model-streaming.int8.onnx --tokens=./sherpa-onnx-en-wenet-librispeech/tokens.txt ./sherpa-onnx-en-wenet-librispeech/test_wavs/0.wav ./sherpa-onnx-en-wenet-librispeech/test_wavs/1.wav ./sherpa-onnx-en-wenet-librispeech/test_wavs/8k.wav \n",
            "\n",
            "OnlineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OnlineModelConfig(transducer=OnlineTransducerModelConfig(encoder=\"\", decoder=\"\", joiner=\"\"), paraformer=OnlineParaformerModelConfig(encoder=\"\", decoder=\"\"), wenet_ctc=OnlineWenetCtcModelConfig(model=\"./sherpa-onnx-en-wenet-librispeech/model-streaming.int8.onnx\", chunk_size=16, num_left_chunks=4), tokens=\"./sherpa-onnx-en-wenet-librispeech/tokens.txt\", num_threads=1, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OnlineLMConfig(model=\"\", scale=0.5), endpoint_config=EndpointConfig(rule1=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=2.4, min_utterance_length=0), rule2=EndpointRule(must_contain_nonsilence=True, min_trailing_silence=1.2, min_utterance_length=0), rule3=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20)), enable_endpoint=True, max_active_paths=4, hotwords_score=1.5, hotwords_file=\"\", decoding_method=\"greedy_search\")\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/features.cc:AcceptWaveformImpl:85 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "./sherpa-onnx-en-wenet-librispeech/test_wavs/0.wav\n",
            "Elapsed seconds: 1.1, Real time factor (RTF): 0.16\n",
            " AFTER EARLYLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROFFTHELS\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \" AFTER EARLYLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROFFTHELS\", \"timestamps\": [0.16, 0.48, 0.60, 0.00, 0.24, 0.48, 0.16, 0.32, 0.04, 0.20, 0.36, 0.60, 0.20, 0.44, 0.00, 0.20, 0.00, 0.16, 0.28, 0.40, 0.12, 0.48, 0.00, 0.08, 0.20, 0.28, 0.32, 0.40, 0.48], \"tokens\":[\" AFTER\", \" EAR\", \"LY\", \"LY\", \" NIGHT\", \"FALL\", \" THE\", \" YELLOW\", \" LAMP\", \"S\", \" WOULD\", \" LIGHT\", \" UP\", \" HERE\", \" AND\", \" THERE\", \" THE\", \" SQU\", \"AL\", \"ID\", \" QUARTER\", \" OF\", \" THE\", \" \", \"BRO\", \"FF\", \"TH\", \"EL\", \"S\"]}\n",
            "\n",
            "./sherpa-onnx-en-wenet-librispeech/test_wavs/1.wav\n",
            "Elapsed seconds: 1.6, Real time factor (RTF): 0.096\n",
            " GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONORED BOSOM TO CONNECT HER PARENTRO FOR EVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \" GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONORED BOSOM TO CONNECT HER PARENTRO FOR EVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN\", \"timestamps\": [0.08, 0.40, 0.60, 0.16, 0.60, 0.48, 0.04, 0.20, 0.48, 0.08, 0.36, 0.44, 0.04, 0.24, 0.12, 0.32, 0.44, 0.00, 0.24, 0.40, 0.60, 0.20, 0.24, 0.32, 0.60, 0.28, 0.48, 0.08, 0.36, 0.12, 0.24, 0.40, 0.48, 0.08, 0.52, 0.20, 0.48, 0.04, 0.16, 0.12, 0.32, 0.56, 0.08, 0.28, 0.04, 0.40, 0.08, 0.32, 0.60, 0.52, 0.04, 0.20, 0.44, 0.00, 0.24, 0.44, 0.60, 0.36, 0.08, 0.28], \"tokens\":[\" GOD\", \" AS\", \" A\", \" DIRECT\", \" CONSEQUENCE\", \" OF\", \" THE\", \" SIN\", \" WHICH\", \" MAN\", \" THU\", \"S\", \" PUNISH\", \"ED\", \" HAD\", \" GIVE\", \"N\", \" HER\", \" A\", \" LOVE\", \"LY\", \" CHILD\", \" WHO\", \"SE\", \" PLACE\", \" WAS\", \" ON\", \" THAT\", \" SAME\", \" DISH\", \"ON\", \"OR\", \"ED\", \" BOSOM\", \" TO\", \" CONNECT\", \" HER\", \" PARENT\", \"RO\", \" FOR\", \" EVER\", \" WITH\", \" THE\", \" RACE\", \" AND\", \" DESCENT\", \" OF\", \" MORTAL\", \"S\", \" AND\", \" TO\", \" BE\", \" FINAL\", \"LY\", \" A\", \" BLESS\", \"ED\", \" SOUL\", \" IN\", \" HEAVEN\"]}\n",
            "\n",
            "./sherpa-onnx-en-wenet-librispeech/test_wavs/8k.wav\n",
            "Elapsed seconds: 0.86, Real time factor (RTF): 0.18\n",
            " YET THESE THOUGHTS AFFECTED HESTER PRYNNNE LESS WITH HOPE THAN APPREHENSION\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \" YET THESE THOUGHTS AFFECTED HESTER PRYNNNE LESS WITH HOPE THAN APPREHENSION\", \"timestamps\": [0.08, 0.40, 0.04, 0.16, 0.40, 0.12, 0.32, 0.48, 0.56, 0.60, 0.00, 0.04, 0.32, 0.04, 0.24, 0.08, 0.60], \"tokens\":[\" YET\", \" THESE\", \" THOUGHT\", \"S\", \" AFFECTED\", \" HE\", \"STER\", \" P\", \"RY\", \"N\", \"N\", \"NE\", \" LESS\", \" WITH\", \" HOPE\", \" THAN\", \" APPREHENSION\"]}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-streaming-decoding"
      ],
      "metadata": {
        "id": "D5-bzWqZNaG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# float32 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx-offline \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-en-wenet-librispeech/model.onnx \\\n",
        "  --tokens=./sherpa-onnx-en-wenet-librispeech/tokens.txt \\\n",
        "  ./sherpa-onnx-en-wenet-librispeech/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-en-wenet-librispeech/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-en-wenet-librispeech/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uasvLI2KNwm3",
        "outputId": "a581cbcb-b9c5-4331-d599-36c1dd048d2f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx-offline --wenet-ctc-model=./sherpa-onnx-en-wenet-librispeech/model.onnx --tokens=./sherpa-onnx-en-wenet-librispeech/tokens.txt ./sherpa-onnx-en-wenet-librispeech/test_wavs/0.wav ./sherpa-onnx-en-wenet-librispeech/test_wavs/1.wav ./sherpa-onnx-en-wenet-librispeech/test_wavs/8k.wav \n",
            "\n",
            "OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=\"\", decoder_filename=\"\", joiner_filename=\"\"), paraformer=OfflineParaformerModelConfig(model=\"\"), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=\"\"), whisper=OfflineWhisperModelConfig(encoder=\"\", decoder=\"\", language=\"\", task=\"transcribe\"), tdnn=OfflineTdnnModelConfig(model=\"\"), zipformer_ctc=OfflineZipformerCtcModelConfig(model=\"\"), wenet_ctc=OfflineWenetCtcModelConfig(model=\"./sherpa-onnx-en-wenet-librispeech/model.onnx\"), tokens=\"./sherpa-onnx-en-wenet-librispeech/tokens.txt\", num_threads=2, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OfflineLMConfig(model=\"\", scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=\"\", max_active=3000), decoding_method=\"greedy_search\", max_active_paths=4, hotwords_file=\"\", hotwords_score=1.5)\n",
            "Creating recognizer ...\n",
            "Started\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/offline-stream.cc:AcceptWaveformImpl:113 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "Done!\n",
            "\n",
            "./sherpa-onnx-en-wenet-librispeech/test_wavs/0.wav\n",
            "{\"text\": \" AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS\", \"timestamps\": [0.80, 1.12, 1.24, 1.52, 1.76, 2.08, 2.24, 2.60, 2.76, 2.92, 3.16, 3.40, 3.68, 3.84, 4.08, 4.48, 4.64, 4.76, 4.88, 5.24, 5.60, 5.76, 5.84, 5.92, 6.00, 6.16, 6.24], \"tokens\":[\" AFTER\", \" EAR\", \"LY\", \" NIGHT\", \"FALL\", \" THE\", \" YELLOW\", \" LAMP\", \"S\", \" WOULD\", \" LIGHT\", \" UP\", \" HERE\", \" AND\", \" THERE\", \" THE\", \" SQU\", \"AL\", \"ID\", \" QUARTER\", \" OF\", \" THE\", \" \", \"BRO\", \"TH\", \"EL\", \"S\"]}\n",
            "----\n",
            "./sherpa-onnx-en-wenet-librispeech/test_wavs/1.wav\n",
            "{\"text\": \" GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONOURED BOSOM TO CONNECT HER PARENT FOR EVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN\", \"timestamps\": [0.72, 1.04, 1.20, 1.44, 1.84, 2.40, 2.56, 2.76, 3.04, 3.28, 3.56, 3.64, 3.88, 4.08, 4.60, 4.80, 4.92, 5.12, 5.36, 5.52, 5.72, 6.00, 6.64, 6.72, 7.00, 7.32, 7.52, 7.76, 8.04, 8.40, 8.56, 8.72, 8.80, 9.00, 9.48, 9.80, 10.08, 10.28, 11.00, 11.20, 11.44, 11.60, 11.80, 12.20, 12.56, 12.88, 13.12, 13.36, 13.96, 14.12, 14.28, 14.48, 14.72, 14.96, 15.16, 15.28, 15.72, 16.04, 16.24], \"tokens\":[\" GOD\", \" AS\", \" A\", \" DIRECT\", \" CONSEQUENCE\", \" OF\", \" THE\", \" SIN\", \" WHICH\", \" MAN\", \" THU\", \"S\", \" PUNISH\", \"ED\", \" HAD\", \" GIVE\", \"N\", \" HER\", \" A\", \" LOVE\", \"LY\", \" CHILD\", \" WHO\", \"SE\", \" PLACE\", \" WAS\", \" ON\", \" THAT\", \" SAME\", \" DISH\", \"ON\", \"OUR\", \"ED\", \" BOSOM\", \" TO\", \" CONNECT\", \" HER\", \" PARENT\", \" FOR\", \" EVER\", \" WITH\", \" THE\", \" RACE\", \" AND\", \" DESCENT\", \" OF\", \" MORTAL\", \"S\", \" AND\", \" TO\", \" BE\", \" FINAL\", \"LY\", \" A\", \" BLESS\", \"ED\", \" SOUL\", \" IN\", \" HEAVEN\"]}\n",
            "----\n",
            "./sherpa-onnx-en-wenet-librispeech/test_wavs/8k.wav\n",
            "{\"text\": \" YET THESE THOUGHTS AFFECTED HESTER PRYNNE LESS WITH HOPE THAN APPREHENSION\", \"timestamps\": [0.76, 1.00, 1.32, 1.44, 1.68, 2.04, 2.24, 2.40, 2.48, 2.56, 2.60, 2.88, 3.24, 3.44, 3.92, 4.44], \"tokens\":[\" YET\", \" THESE\", \" THOUGHT\", \"S\", \" AFFECTED\", \" HE\", \"STER\", \" P\", \"RY\", \"N\", \"NE\", \" LESS\", \" WITH\", \" HOPE\", \" THAN\", \" APPREHENSION\"]}\n",
            "----\n",
            "num threads: 2\n",
            "decoding method: greedy_search\n",
            "Elapsed seconds: 3.379 s\n",
            "Real time factor (RTF): 3.379 / 28.165 = 0.120\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# int8 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx-offline \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-en-wenet-librispeech/model.int8.onnx \\\n",
        "  --tokens=./sherpa-onnx-en-wenet-librispeech/tokens.txt \\\n",
        "  ./sherpa-onnx-en-wenet-librispeech/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-en-wenet-librispeech/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-en-wenet-librispeech/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXwGaawhN4i7",
        "outputId": "3efdb1af-7e7f-4b92-dcd2-05a55826e23a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx-offline --wenet-ctc-model=./sherpa-onnx-en-wenet-librispeech/model.int8.onnx --tokens=./sherpa-onnx-en-wenet-librispeech/tokens.txt ./sherpa-onnx-en-wenet-librispeech/test_wavs/0.wav ./sherpa-onnx-en-wenet-librispeech/test_wavs/1.wav ./sherpa-onnx-en-wenet-librispeech/test_wavs/8k.wav \n",
            "\n",
            "OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=\"\", decoder_filename=\"\", joiner_filename=\"\"), paraformer=OfflineParaformerModelConfig(model=\"\"), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=\"\"), whisper=OfflineWhisperModelConfig(encoder=\"\", decoder=\"\", language=\"\", task=\"transcribe\"), tdnn=OfflineTdnnModelConfig(model=\"\"), zipformer_ctc=OfflineZipformerCtcModelConfig(model=\"\"), wenet_ctc=OfflineWenetCtcModelConfig(model=\"./sherpa-onnx-en-wenet-librispeech/model.int8.onnx\"), tokens=\"./sherpa-onnx-en-wenet-librispeech/tokens.txt\", num_threads=2, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OfflineLMConfig(model=\"\", scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=\"\", max_active=3000), decoding_method=\"greedy_search\", max_active_paths=4, hotwords_file=\"\", hotwords_score=1.5)\n",
            "Creating recognizer ...\n",
            "Started\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/offline-stream.cc:AcceptWaveformImpl:113 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "Done!\n",
            "\n",
            "./sherpa-onnx-en-wenet-librispeech/test_wavs/0.wav\n",
            "{\"text\": \" AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS\", \"timestamps\": [0.80, 1.12, 1.24, 1.52, 1.76, 2.08, 2.24, 2.60, 2.76, 2.92, 3.16, 3.40, 3.68, 3.84, 4.08, 4.48, 4.64, 4.76, 4.88, 5.24, 5.60, 5.76, 5.84, 5.92, 6.00, 6.16, 6.24], \"tokens\":[\" AFTER\", \" EAR\", \"LY\", \" NIGHT\", \"FALL\", \" THE\", \" YELLOW\", \" LAMP\", \"S\", \" WOULD\", \" LIGHT\", \" UP\", \" HERE\", \" AND\", \" THERE\", \" THE\", \" SQU\", \"AL\", \"ID\", \" QUARTER\", \" OF\", \" THE\", \" \", \"BRO\", \"TH\", \"EL\", \"S\"]}\n",
            "----\n",
            "./sherpa-onnx-en-wenet-librispeech/test_wavs/1.wav\n",
            "{\"text\": \" GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONOURED BOSOM TO CONNECT HER PARENT FOR EVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN\", \"timestamps\": [0.72, 1.04, 1.20, 1.44, 1.84, 2.40, 2.60, 2.76, 3.04, 3.28, 3.56, 3.64, 3.88, 4.08, 4.60, 4.80, 4.92, 5.12, 5.36, 5.52, 5.72, 6.00, 6.64, 6.72, 7.00, 7.32, 7.52, 7.76, 8.04, 8.40, 8.56, 8.72, 8.80, 9.04, 9.48, 9.80, 10.08, 10.28, 11.00, 11.20, 11.44, 11.60, 11.80, 12.20, 12.56, 12.88, 13.12, 13.36, 13.96, 14.12, 14.28, 14.48, 14.72, 14.96, 15.16, 15.28, 15.72, 16.04, 16.24], \"tokens\":[\" GOD\", \" AS\", \" A\", \" DIRECT\", \" CONSEQUENCE\", \" OF\", \" THE\", \" SIN\", \" WHICH\", \" MAN\", \" THU\", \"S\", \" PUNISH\", \"ED\", \" HAD\", \" GIVE\", \"N\", \" HER\", \" A\", \" LOVE\", \"LY\", \" CHILD\", \" WHO\", \"SE\", \" PLACE\", \" WAS\", \" ON\", \" THAT\", \" SAME\", \" DISH\", \"ON\", \"OUR\", \"ED\", \" BOSOM\", \" TO\", \" CONNECT\", \" HER\", \" PARENT\", \" FOR\", \" EVER\", \" WITH\", \" THE\", \" RACE\", \" AND\", \" DESCENT\", \" OF\", \" MORTAL\", \"S\", \" AND\", \" TO\", \" BE\", \" FINAL\", \"LY\", \" A\", \" BLESS\", \"ED\", \" SOUL\", \" IN\", \" HEAVEN\"]}\n",
            "----\n",
            "./sherpa-onnx-en-wenet-librispeech/test_wavs/8k.wav\n",
            "{\"text\": \" YET THESE THOUGHTS AFFECTED HESTER PRYNNE LESS WITH HOPE THAN APPREHENSION\", \"timestamps\": [0.76, 1.00, 1.32, 1.44, 1.68, 2.04, 2.24, 2.40, 2.48, 2.56, 2.60, 2.88, 3.24, 3.44, 3.92, 4.44], \"tokens\":[\" YET\", \" THESE\", \" THOUGHT\", \"S\", \" AFFECTED\", \" HE\", \"STER\", \" P\", \"RY\", \"N\", \"NE\", \" LESS\", \" WITH\", \" HOPE\", \" THAN\", \" APPREHENSION\"]}\n",
            "----\n",
            "num threads: 2\n",
            "decoding method: greedy_search\n",
            "Elapsed seconds: 1.240 s\n",
            "Real time factor (RTF): 1.240 / 28.165 = 0.044\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sherpa-onnx-zh-wenet-gigaspeech"
      ],
      "metadata": {
        "id": "I1aZ9ClcNXCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "git lfs install\n",
        "git clone https://huggingface.co/csukuangfj/sherpa-onnx-en-wenet-gigaspeech\n",
        "ls -lh sherpa-onnx-en-wenet-gigaspeech"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bP_HXTNbN9AH",
        "outputId": "b792fe5e-3497-45f7-cd73-be501d913f91"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'sherpa-onnx-en-wenet-gigaspeech'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 25 (delta 1), reused 0 (delta 0), pack-reused 3\u001b[K\n",
            "Unpacking objects: 100% (25/25), 690.77 KiB | 7.20 MiB/s, done.\n",
            "Filtering content: 100% (4/4), 975.77 MiB | 43.30 MiB/s, done.\n",
            "total 976M\n",
            "-rw-r--r-- 1 root root 142M Nov 16 03:53 model.int8.onnx\n",
            "-rw-r--r-- 1 root root 347M Nov 16 03:53 model.onnx\n",
            "-rw-r--r-- 1 root root 142M Nov 16 03:53 model-streaming.int8.onnx\n",
            "-rw-r--r-- 1 root root 347M Nov 16 03:53 model-streaming.onnx\n",
            "-rw-r--r-- 1 root root  133 Nov 16 03:53 README.md\n",
            "drwxr-xr-x 2 root root 4.0K Nov 16 03:53 test_wavs\n",
            "-rwxr-xr-x 1 root root  70K Nov 16 03:53 tokens.txt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Streaming decoding"
      ],
      "metadata": {
        "id": "FmfgaNY2Ne4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# float32 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-en-wenet-gigaspeech/model-streaming.onnx \\\n",
        "  --tokens=./sherpa-onnx-en-wenet-gigaspeech/tokens.txt \\\n",
        "  ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTlN5MIFN8vX",
        "outputId": "c10a34fa-aca1-4ae9-bd3a-f41c48a95c2c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx --wenet-ctc-model=./sherpa-onnx-en-wenet-gigaspeech/model-streaming.onnx --tokens=./sherpa-onnx-en-wenet-gigaspeech/tokens.txt ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/0.wav ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/1.wav ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/8k.wav \n",
            "\n",
            "OnlineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OnlineModelConfig(transducer=OnlineTransducerModelConfig(encoder=\"\", decoder=\"\", joiner=\"\"), paraformer=OnlineParaformerModelConfig(encoder=\"\", decoder=\"\"), wenet_ctc=OnlineWenetCtcModelConfig(model=\"./sherpa-onnx-en-wenet-gigaspeech/model-streaming.onnx\", chunk_size=16, num_left_chunks=4), tokens=\"./sherpa-onnx-en-wenet-gigaspeech/tokens.txt\", num_threads=1, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OnlineLMConfig(model=\"\", scale=0.5), endpoint_config=EndpointConfig(rule1=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=2.4, min_utterance_length=0), rule2=EndpointRule(must_contain_nonsilence=True, min_trailing_silence=1.2, min_utterance_length=0), rule3=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20)), enable_endpoint=True, max_active_paths=4, hotwords_score=1.5, hotwords_file=\"\", decoding_method=\"greedy_search\")\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/features.cc:AcceptWaveformImpl:85 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "./sherpa-onnx-en-wenet-gigaspeech/test_wavs/0.wav\n",
            "Elapsed seconds: 3.9, Real time factor (RTF): 0.6\n",
            " AFTER EARLY EARLY NIGHTFALL FALLLL THE YELLOWLO LAMPS WOULD LIGHT LIGHT UP HERE AND HERE AND THERE THERE THE SQUALILID-LOLID QUARTER OF THE OF THE BROTHELSELS\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \" AFTER EARLY EARLY NIGHTFALL FALLLL THE YELLOWLO LAMPS WOULD LIGHT LIGHT UP HERE AND HERE AND THERE THERE THE SQUALILID-LOLID QUARTER OF THE OF THE BROTHELSELS\", \"timestamps\": [0.40, 0.04, 0.24, 0.48, 0.04, 0.12, 0.28, 0.32, 0.44, 0.56, 0.16, 0.36, 0.48, 0.60, 0.08, 0.32, 0.48, 0.00, 0.12, 0.24, 0.36, 0.48, 0.12, 0.32, 0.44, 0.52, 0.60, 0.00, 0.04, 0.08, 0.20, 0.24, 0.32, 0.40, 0.04, 0.12, 0.24, 0.32, 0.44, 0.56, 0.00, 0.08, 0.20, 0.28], \"tokens\":[\" AFTER\", \" EARLY\", \" EARLY\", \" NIGHT\", \"FA\", \"LL\", \" FALL\", \"LL\", \" THE\", \" YELLOW\", \"LO\", \" LAMP\", \"S\", \" WOULD\", \" LIGHT\", \" LIGHT\", \" UP\", \" HERE\", \" AND\", \" HERE\", \" AND\", \" THERE\", \" THERE\", \" THE\", \" S\", \"QUA\", \"LI\", \"LI\", \"D\", \"-\", \"LO\", \"LI\", \"D\", \" QUARTER\", \" OF\", \" THE\", \" OF\", \" THE\", \" BRO\", \"T\", \"HEL\", \"S\", \"EL\", \"S\"]}\n",
            "\n",
            "./sherpa-onnx-en-wenet-gigaspeech/test_wavs/1.wav\n",
            "Elapsed seconds: 6.1, Real time factor (RTF): 0.36\n",
            " GOD AS IT IS A DIRECT CONSEQUENCE CONSEQUENCE OF THIS OF THE SIN WHICH WHICH MAN THUS PUT PUNISHED HAD GIVEN HER GIVEN HER A LOVELY LOVELY CHILD WHOSE PLACE PLACE WAS ON ON THAT SAME DAME DISHONORED HONORARDED BOSOM TO TO CONNECT HER PAIR PARENT FOR EVER WITH HER WITH THE RACE ACE AND DESCENTMENT OF MORTAL MORTALS AND AND TO BE FINALLY FINALLY A BLESS LESS SOUL ILL IN HEAVEN\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \" GOD AS IT IS A DIRECT CONSEQUENCE CONSEQUENCE OF THIS OF THE SIN WHICH WHICH MAN THUS PUT PUNISHED HAD GIVEN HER GIVEN HER A LOVELY LOVELY CHILD WHOSE PLACE PLACE WAS ON ON THAT SAME DAME DISHONORED HONORARDED BOSOM TO TO CONNECT HER PAIR PARENT FOR EVER WITH HER WITH THE RACE ACE AND DESCENTMENT OF MORTAL MORTALS AND AND TO BE FINALLY FINALLY A BLESS LESS SOUL ILL IN HEAVEN\", \"timestamps\": [0.36, 0.00, 0.08, 0.20, 0.32, 0.44, 0.04, 0.24, 0.04, 0.12, 0.24, 0.36, 0.48, 0.00, 0.20, 0.40, 0.60, 0.16, 0.36, 0.56, 0.40, 0.56, 0.12, 0.24, 0.36, 0.48, 0.00, 0.20, 0.52, 0.48, 0.08, 0.28, 0.52, 0.00, 0.24, 0.40, 0.56, 0.16, 0.24, 0.36, 0.52, 0.00, 0.04, 0.16, 0.24, 0.28, 0.32, 0.36, 0.48, 0.56, 0.04, 0.28, 0.48, 0.00, 0.16, 0.40, 0.40, 0.52, 0.08, 0.20, 0.28, 0.40, 0.52, 0.16, 0.24, 0.36, 0.48, 0.52, 0.00, 0.20, 0.40, 0.52, 0.16, 0.36, 0.04, 0.24, 0.36, 0.44, 0.00, 0.20, 0.48, 0.60, 0.20, 0.56, 0.20, 0.28, 0.36, 0.48], \"tokens\":[\" GOD\", \" AS\", \" IT\", \" IS\", \" A\", \" DIRECT\", \" CONSEQUENCE\", \" CONSEQUENCE\", \" OF\", \" THIS\", \" OF\", \" THE\", \" SIN\", \" WHICH\", \" WHICH\", \" MAN\", \" THUS\", \" PUT\", \" PUNISH\", \"ED\", \" HAD\", \" GIVEN\", \" HER\", \" GIVEN\", \" HER\", \" A\", \" LOVELY\", \" LOVELY\", \" CHILD\", \" WHOSE\", \" PLACE\", \" PLACE\", \" WAS\", \" ON\", \" ON\", \" THAT\", \" SAME\", \" DAM\", \"E\", \" DISH\", \"ON\", \"OR\", \"ED\", \" HONOR\", \"ARD\", \"ED\", \" BO\", \"S\", \"O\", \"M\", \" TO\", \" TO\", \" CONNECT\", \" HER\", \" PAIR\", \" PARENT\", \" FOR\", \" EVER\", \" WITH\", \" HER\", \" WITH\", \" THE\", \" RACE\", \" A\", \"CE\", \" AND\", \" DE\", \"S\", \"CENT\", \"MENT\", \" OF\", \" MORTAL\", \" MORTAL\", \"S\", \" AND\", \" AND\", \" TO\", \" BE\", \" FINALLY\", \" FINALLY\", \" A\", \" BLESS\", \" LESS\", \" SOUL\", \" I\", \"LL\", \" IN\", \" HEAVEN\"]}\n",
            "\n",
            "./sherpa-onnx-en-wenet-gigaspeech/test_wavs/8k.wav\n",
            "Elapsed seconds: 3.2, Real time factor (RTF): 0.66\n",
            " YET THESE THOUGHTS THOUGHTS AFFECTED AFFECTED HESTER PRIN PRIN LESS WITH WITH HOPE THAN APPREHENREHENSION\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \" YET THESE THOUGHTS THOUGHTS AFFECTED AFFECTED HESTER PRIN PRIN LESS WITH WITH HOPE THAN APPREHENREHENSION\", \"timestamps\": [0.40, 0.00, 0.16, 0.36, 0.04, 0.24, 0.40, 0.56, 0.08, 0.12, 0.32, 0.36, 0.00, 0.16, 0.36, 0.52, 0.36, 0.52, 0.00, 0.08, 0.20, 0.28, 0.40, 0.48], \"tokens\":[\" YET\", \" THESE\", \" THOUGHTS\", \" THOUGHTS\", \" AFFECTED\", \" AFFECTED\", \" HE\", \"STER\", \" PRI\", \"N\", \" PRI\", \"N\", \" LESS\", \" WITH\", \" WITH\", \" HOPE\", \" THAN\", \" APP\", \"RE\", \"HEN\", \"RE\", \"HEN\", \"S\", \"ION\"]}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# int8 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-en-wenet-gigaspeech/model-streaming.int8.onnx \\\n",
        "  --tokens=./sherpa-onnx-en-wenet-gigaspeech/tokens.txt \\\n",
        "  ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXjffuAoOLZ7",
        "outputId": "8fbc3936-17e0-4c3a-9d65-4a3180bdd885"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx --wenet-ctc-model=./sherpa-onnx-en-wenet-gigaspeech/model-streaming.int8.onnx --tokens=./sherpa-onnx-en-wenet-gigaspeech/tokens.txt ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/0.wav ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/1.wav ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/8k.wav \n",
            "\n",
            "OnlineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OnlineModelConfig(transducer=OnlineTransducerModelConfig(encoder=\"\", decoder=\"\", joiner=\"\"), paraformer=OnlineParaformerModelConfig(encoder=\"\", decoder=\"\"), wenet_ctc=OnlineWenetCtcModelConfig(model=\"./sherpa-onnx-en-wenet-gigaspeech/model-streaming.int8.onnx\", chunk_size=16, num_left_chunks=4), tokens=\"./sherpa-onnx-en-wenet-gigaspeech/tokens.txt\", num_threads=1, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OnlineLMConfig(model=\"\", scale=0.5), endpoint_config=EndpointConfig(rule1=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=2.4, min_utterance_length=0), rule2=EndpointRule(must_contain_nonsilence=True, min_trailing_silence=1.2, min_utterance_length=0), rule3=EndpointRule(must_contain_nonsilence=False, min_trailing_silence=0, min_utterance_length=20)), enable_endpoint=True, max_active_paths=4, hotwords_score=1.5, hotwords_file=\"\", decoding_method=\"greedy_search\")\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/features.cc:AcceptWaveformImpl:85 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "./sherpa-onnx-en-wenet-gigaspeech/test_wavs/0.wav\n",
            "Elapsed seconds: 3.2, Real time factor (RTF): 0.48\n",
            " AFTER EARLY EARLY NIGHTFALL FALLLL THE YELLOWLO LAMPS WOULD LIGHT LIGHT UP HERE AND HERE AND THERE THERE THE SQUALILID-LID QUARTER OF THERE OF THE BROTHELSELS\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \" AFTER EARLY EARLY NIGHTFALL FALLLL THE YELLOWLO LAMPS WOULD LIGHT LIGHT UP HERE AND HERE AND THERE THERE THE SQUALILID-LID QUARTER OF THERE OF THE BROTHELSELS\", \"timestamps\": [0.40, 0.04, 0.24, 0.48, 0.04, 0.12, 0.28, 0.32, 0.44, 0.56, 0.16, 0.36, 0.48, 0.60, 0.08, 0.32, 0.48, 0.00, 0.12, 0.24, 0.36, 0.48, 0.12, 0.32, 0.44, 0.52, 0.60, 0.00, 0.04, 0.08, 0.20, 0.28, 0.40, 0.04, 0.12, 0.24, 0.32, 0.44, 0.56, 0.00, 0.08, 0.20, 0.28], \"tokens\":[\" AFTER\", \" EARLY\", \" EARLY\", \" NIGHT\", \"FA\", \"LL\", \" FALL\", \"LL\", \" THE\", \" YELLOW\", \"LO\", \" LAMP\", \"S\", \" WOULD\", \" LIGHT\", \" LIGHT\", \" UP\", \" HERE\", \" AND\", \" HERE\", \" AND\", \" THERE\", \" THERE\", \" THE\", \" S\", \"QUA\", \"LI\", \"LI\", \"D\", \"-\", \"LI\", \"D\", \" QUARTER\", \" OF\", \" THERE\", \" OF\", \" THE\", \" BRO\", \"T\", \"HEL\", \"S\", \"EL\", \"S\"]}\n",
            "\n",
            "./sherpa-onnx-en-wenet-gigaspeech/test_wavs/1.wav\n",
            "Elapsed seconds: 4.8, Real time factor (RTF): 0.29\n",
            " GOD AS IT IS A DIRECT CONSEQUENCE CONSEQUENCE OF THIS OF THE SIN WHICH WHICH MAN THUS PUT PUNISHED HAD GIVEN HER GIVEN HER A LOVELY LOVELY CHILD WHOSE PLACE PLACE WAS ON ON THAT SAME DAME DISHONOREDARDED BOSOM TO TO CONNECT HER PAIR PARENT FOR EVER WITH HER WITH THE RACE ACE AND DESCENTMENT OF MORTAL MORTALS AND AND TO BE FINALLY FINALLY A BLESS LESS SOUL ILL IN HEAVEN\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \" GOD AS IT IS A DIRECT CONSEQUENCE CONSEQUENCE OF THIS OF THE SIN WHICH WHICH MAN THUS PUT PUNISHED HAD GIVEN HER GIVEN HER A LOVELY LOVELY CHILD WHOSE PLACE PLACE WAS ON ON THAT SAME DAME DISHONOREDARDED BOSOM TO TO CONNECT HER PAIR PARENT FOR EVER WITH HER WITH THE RACE ACE AND DESCENTMENT OF MORTAL MORTALS AND AND TO BE FINALLY FINALLY A BLESS LESS SOUL ILL IN HEAVEN\", \"timestamps\": [0.36, 0.00, 0.08, 0.20, 0.32, 0.44, 0.04, 0.24, 0.04, 0.12, 0.24, 0.36, 0.48, 0.00, 0.20, 0.40, 0.60, 0.16, 0.36, 0.56, 0.40, 0.56, 0.12, 0.24, 0.36, 0.48, 0.00, 0.20, 0.52, 0.48, 0.08, 0.28, 0.52, 0.00, 0.24, 0.40, 0.56, 0.16, 0.24, 0.36, 0.52, 0.00, 0.04, 0.24, 0.28, 0.32, 0.36, 0.48, 0.56, 0.04, 0.28, 0.48, 0.00, 0.16, 0.40, 0.40, 0.52, 0.08, 0.20, 0.28, 0.40, 0.52, 0.16, 0.20, 0.36, 0.48, 0.52, 0.00, 0.20, 0.40, 0.52, 0.16, 0.36, 0.04, 0.24, 0.36, 0.44, 0.00, 0.20, 0.48, 0.60, 0.20, 0.56, 0.20, 0.28, 0.36, 0.48], \"tokens\":[\" GOD\", \" AS\", \" IT\", \" IS\", \" A\", \" DIRECT\", \" CONSEQUENCE\", \" CONSEQUENCE\", \" OF\", \" THIS\", \" OF\", \" THE\", \" SIN\", \" WHICH\", \" WHICH\", \" MAN\", \" THUS\", \" PUT\", \" PUNISH\", \"ED\", \" HAD\", \" GIVEN\", \" HER\", \" GIVEN\", \" HER\", \" A\", \" LOVELY\", \" LOVELY\", \" CHILD\", \" WHOSE\", \" PLACE\", \" PLACE\", \" WAS\", \" ON\", \" ON\", \" THAT\", \" SAME\", \" DAM\", \"E\", \" DISH\", \"ON\", \"OR\", \"ED\", \"ARD\", \"ED\", \" BO\", \"S\", \"O\", \"M\", \" TO\", \" TO\", \" CONNECT\", \" HER\", \" PAIR\", \" PARENT\", \" FOR\", \" EVER\", \" WITH\", \" HER\", \" WITH\", \" THE\", \" RACE\", \" A\", \"CE\", \" AND\", \" DE\", \"S\", \"CENT\", \"MENT\", \" OF\", \" MORTAL\", \" MORTAL\", \"S\", \" AND\", \" AND\", \" TO\", \" BE\", \" FINALLY\", \" FINALLY\", \" A\", \" BLESS\", \" LESS\", \" SOUL\", \" I\", \"LL\", \" IN\", \" HEAVEN\"]}\n",
            "\n",
            "./sherpa-onnx-en-wenet-gigaspeech/test_wavs/8k.wav\n",
            "Elapsed seconds: 2.6, Real time factor (RTF): 0.53\n",
            " YET THESE THOUGHTS THOUGHTS AFFECTED AFFECTED HESTER P PRIN PRIN LESS WITH WITH HOPE THAN APPREHENREHENSION\n",
            "{\"is_final\":false, \"segment\":0, \"start_time\":0.00, \"text\": \" YET THESE THOUGHTS THOUGHTS AFFECTED AFFECTED HESTER P PRIN PRIN LESS WITH WITH HOPE THAN APPREHENREHENSION\", \"timestamps\": [0.40, 0.00, 0.16, 0.36, 0.04, 0.24, 0.40, 0.56, 0.04, 0.08, 0.12, 0.32, 0.36, 0.00, 0.16, 0.36, 0.52, 0.36, 0.52, 0.00, 0.08, 0.20, 0.28, 0.40, 0.48], \"tokens\":[\" YET\", \" THESE\", \" THOUGHTS\", \" THOUGHTS\", \" AFFECTED\", \" AFFECTED\", \" HE\", \"STER\", \" P\", \" PRI\", \"N\", \" PRI\", \"N\", \" LESS\", \" WITH\", \" WITH\", \" HOPE\", \" THAN\", \" APP\", \"RE\", \"HEN\", \"RE\", \"HEN\", \"S\", \"ION\"]}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-streaming decoding"
      ],
      "metadata": {
        "id": "PJP03ii1NgAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# float32 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx-offline \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-en-wenet-gigaspeech/model.onnx \\\n",
        "  --tokens=./sherpa-onnx-en-wenet-gigaspeech/tokens.txt \\\n",
        "  ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRKZJTFCNQRx",
        "outputId": "74ae79cd-d2f9-418c-a618-409451c2095c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx-offline --wenet-ctc-model=./sherpa-onnx-en-wenet-gigaspeech/model.onnx --tokens=./sherpa-onnx-en-wenet-gigaspeech/tokens.txt ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/0.wav ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/1.wav ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/8k.wav \n",
            "\n",
            "OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=\"\", decoder_filename=\"\", joiner_filename=\"\"), paraformer=OfflineParaformerModelConfig(model=\"\"), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=\"\"), whisper=OfflineWhisperModelConfig(encoder=\"\", decoder=\"\", language=\"\", task=\"transcribe\"), tdnn=OfflineTdnnModelConfig(model=\"\"), zipformer_ctc=OfflineZipformerCtcModelConfig(model=\"\"), wenet_ctc=OfflineWenetCtcModelConfig(model=\"./sherpa-onnx-en-wenet-gigaspeech/model.onnx\"), tokens=\"./sherpa-onnx-en-wenet-gigaspeech/tokens.txt\", num_threads=2, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OfflineLMConfig(model=\"\", scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=\"\", max_active=3000), decoding_method=\"greedy_search\", max_active_paths=4, hotwords_file=\"\", hotwords_score=1.5)\n",
            "Creating recognizer ...\n",
            "Started\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/offline-stream.cc:AcceptWaveformImpl:113 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "Done!\n",
            "\n",
            "./sherpa-onnx-en-wenet-gigaspeech/test_wavs/0.wav\n",
            "{\"text\": \" AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS\", \"timestamps\": [0.60, 0.96, 1.38, 1.62, 1.74, 1.98, 2.10, 2.40, 2.64, 2.82, 3.00, 3.24, 3.54, 3.72, 3.96, 4.32, 4.50, 4.62, 4.74, 4.86, 5.10, 5.46, 5.58, 5.76, 5.94, 6.12, 6.18], \"tokens\":[\" AFTER\", \" EARLY\", \" NIGHT\", \"FA\", \"LL\", \" THE\", \" YELLOW\", \" LAMP\", \"S\", \" WOULD\", \" LIGHT\", \" UP\", \" HERE\", \" AND\", \" THERE\", \" THE\", \" S\", \"QUA\", \"LI\", \"D\", \" QUARTER\", \" OF\", \" THE\", \" BRO\", \"T\", \"HEL\", \"S\"]}\n",
            "----\n",
            "./sherpa-onnx-en-wenet-gigaspeech/test_wavs/1.wav\n",
            "{\"text\": \" GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONORED BOSOM TO CONNECT HER PARENT FOR EVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN\", \"timestamps\": [0.54, 0.90, 1.02, 1.32, 1.62, 2.28, 2.40, 2.64, 2.88, 3.12, 3.42, 3.72, 4.02, 4.44, 4.68, 4.98, 5.22, 5.40, 5.88, 6.48, 6.84, 7.20, 7.38, 7.62, 7.86, 8.22, 8.46, 8.58, 8.70, 8.82, 8.88, 9.00, 9.12, 9.36, 9.66, 9.90, 10.20, 10.86, 11.04, 11.28, 11.46, 11.70, 12.06, 12.24, 12.30, 12.48, 12.72, 12.96, 13.32, 13.80, 13.98, 14.10, 14.34, 14.82, 15.00, 15.24, 15.54, 15.90, 16.08], \"tokens\":[\" GOD\", \" AS\", \" A\", \" DIRECT\", \" CONSEQUENCE\", \" OF\", \" THE\", \" SIN\", \" WHICH\", \" MAN\", \" THUS\", \" PUNISH\", \"ED\", \" HAD\", \" GIVEN\", \" HER\", \" A\", \" LOVELY\", \" CHILD\", \" WHOSE\", \" PLACE\", \" WAS\", \" ON\", \" THAT\", \" SAME\", \" DISH\", \"ON\", \"OR\", \"ED\", \" BO\", \"S\", \"O\", \"M\", \" TO\", \" CONNECT\", \" HER\", \" PARENT\", \" FOR\", \" EVER\", \" WITH\", \" THE\", \" RACE\", \" AND\", \" DE\", \"S\", \"CENT\", \" OF\", \" MORTAL\", \"S\", \" AND\", \" TO\", \" BE\", \" FINALLY\", \" A\", \" BLESS\", \"ED\", \" SOUL\", \" IN\", \" HEAVEN\"]}\n",
            "----\n",
            "./sherpa-onnx-en-wenet-gigaspeech/test_wavs/8k.wav\n",
            "{\"text\": \" YET THESE THOUGHTS AFFECTED HESTER PRYNE LESS WITH HOPE THAN APPREHENSION\", \"timestamps\": [0.60, 0.84, 1.14, 1.56, 1.86, 2.10, 2.28, 2.34, 2.46, 2.70, 3.06, 3.30, 3.72, 3.96, 4.14, 4.26, 4.44, 4.56], \"tokens\":[\" YET\", \" THESE\", \" THOUGHTS\", \" AFFECTED\", \" HE\", \"STER\", \" P\", \"RY\", \"NE\", \" LESS\", \" WITH\", \" HOPE\", \" THAN\", \" APP\", \"RE\", \"HEN\", \"S\", \"ION\"]}\n",
            "----\n",
            "num threads: 2\n",
            "decoding method: greedy_search\n",
            "Elapsed seconds: 2.838 s\n",
            "Real time factor (RTF): 2.838 / 28.165 = 0.101\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# int8 models\n",
        "./sherpa-onnx/build/bin/sherpa-onnx-offline \\\n",
        "  --wenet-ctc-model=./sherpa-onnx-en-wenet-gigaspeech/model.int8.onnx \\\n",
        "  --tokens=./sherpa-onnx-en-wenet-gigaspeech/tokens.txt \\\n",
        "  ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/0.wav \\\n",
        "  ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/1.wav \\\n",
        "  ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/8k.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqjsHuKEOTaA",
        "outputId": "43570311-c8fe-45be-ff67-64fdeb403547"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:361 ./sherpa-onnx/build/bin/sherpa-onnx-offline --wenet-ctc-model=./sherpa-onnx-en-wenet-gigaspeech/model.int8.onnx --tokens=./sherpa-onnx-en-wenet-gigaspeech/tokens.txt ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/0.wav ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/1.wav ./sherpa-onnx-en-wenet-gigaspeech/test_wavs/8k.wav \n",
            "\n",
            "OfflineRecognizerConfig(feat_config=OfflineFeatureExtractorConfig(sampling_rate=16000, feature_dim=80), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=\"\", decoder_filename=\"\", joiner_filename=\"\"), paraformer=OfflineParaformerModelConfig(model=\"\"), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=\"\"), whisper=OfflineWhisperModelConfig(encoder=\"\", decoder=\"\", language=\"\", task=\"transcribe\"), tdnn=OfflineTdnnModelConfig(model=\"\"), zipformer_ctc=OfflineZipformerCtcModelConfig(model=\"\"), wenet_ctc=OfflineWenetCtcModelConfig(model=\"./sherpa-onnx-en-wenet-gigaspeech/model.int8.onnx\"), tokens=\"./sherpa-onnx-en-wenet-gigaspeech/tokens.txt\", num_threads=2, debug=False, provider=\"cpu\", model_type=\"\"), lm_config=OfflineLMConfig(model=\"\", scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=\"\", max_active=3000), decoding_method=\"greedy_search\", max_active_paths=4, hotwords_file=\"\", hotwords_score=1.5)\n",
            "Creating recognizer ...\n",
            "Started\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/offline-stream.cc:AcceptWaveformImpl:113 Creating a resampler:\n",
            "   in_sample_rate: 8000\n",
            "   output_sample_rate: 16000\n",
            "\n",
            "Done!\n",
            "\n",
            "./sherpa-onnx-en-wenet-gigaspeech/test_wavs/0.wav\n",
            "{\"text\": \" AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD LIGHT UP HERE AND THERE THE SQUALID QUARTER OF THE BROTHELS\", \"timestamps\": [0.60, 0.96, 1.38, 1.62, 1.74, 1.98, 2.10, 2.40, 2.64, 2.82, 3.00, 3.24, 3.54, 3.72, 3.96, 4.32, 4.50, 4.62, 4.74, 4.86, 5.10, 5.46, 5.58, 5.76, 5.94, 6.12, 6.18], \"tokens\":[\" AFTER\", \" EARLY\", \" NIGHT\", \"FA\", \"LL\", \" THE\", \" YELLOW\", \" LAMP\", \"S\", \" WOULD\", \" LIGHT\", \" UP\", \" HERE\", \" AND\", \" THERE\", \" THE\", \" S\", \"QUA\", \"LI\", \"D\", \" QUARTER\", \" OF\", \" THE\", \" BRO\", \"T\", \"HEL\", \"S\"]}\n",
            "----\n",
            "./sherpa-onnx-en-wenet-gigaspeech/test_wavs/1.wav\n",
            "{\"text\": \" GOD AS A DIRECT CONSEQUENCE OF THE SIN WHICH MAN THUS PUNISHED HAD GIVEN HER A LOVELY CHILD WHOSE PLACE WAS ON THAT SAME DISHONORED BOSOM TO CONNECT HER PARENT FOR EVER WITH THE RACE AND DESCENT OF MORTALS AND TO BE FINALLY A BLESSED SOUL IN HEAVEN\", \"timestamps\": [0.54, 0.90, 1.08, 1.32, 1.62, 2.28, 2.40, 2.64, 2.88, 3.12, 3.42, 3.72, 4.02, 4.44, 4.68, 4.98, 5.22, 5.40, 5.88, 6.48, 6.84, 7.20, 7.38, 7.62, 7.92, 8.22, 8.46, 8.58, 8.70, 8.82, 8.88, 9.00, 9.12, 9.36, 9.66, 9.90, 10.20, 10.86, 11.04, 11.28, 11.46, 11.70, 12.06, 12.24, 12.30, 12.48, 12.72, 12.96, 13.32, 13.80, 13.98, 14.10, 14.34, 14.82, 15.00, 15.24, 15.60, 15.90, 16.08], \"tokens\":[\" GOD\", \" AS\", \" A\", \" DIRECT\", \" CONSEQUENCE\", \" OF\", \" THE\", \" SIN\", \" WHICH\", \" MAN\", \" THUS\", \" PUNISH\", \"ED\", \" HAD\", \" GIVEN\", \" HER\", \" A\", \" LOVELY\", \" CHILD\", \" WHOSE\", \" PLACE\", \" WAS\", \" ON\", \" THAT\", \" SAME\", \" DISH\", \"ON\", \"OR\", \"ED\", \" BO\", \"S\", \"O\", \"M\", \" TO\", \" CONNECT\", \" HER\", \" PARENT\", \" FOR\", \" EVER\", \" WITH\", \" THE\", \" RACE\", \" AND\", \" DE\", \"S\", \"CENT\", \" OF\", \" MORTAL\", \"S\", \" AND\", \" TO\", \" BE\", \" FINALLY\", \" A\", \" BLESS\", \"ED\", \" SOUL\", \" IN\", \" HEAVEN\"]}\n",
            "----\n",
            "./sherpa-onnx-en-wenet-gigaspeech/test_wavs/8k.wav\n",
            "{\"text\": \" YET THESE THOUGHTS AFFECTED HESTER PRYNE LESS WITH HOPE THAN APPREHENSION\", \"timestamps\": [0.60, 0.84, 1.14, 1.56, 1.92, 2.10, 2.28, 2.34, 2.46, 2.70, 3.06, 3.30, 3.72, 3.96, 4.14, 4.26, 4.44, 4.56], \"tokens\":[\" YET\", \" THESE\", \" THOUGHTS\", \" AFFECTED\", \" HE\", \"STER\", \" P\", \"RY\", \"NE\", \" LESS\", \" WITH\", \" HOPE\", \" THAN\", \" APP\", \"RE\", \"HEN\", \"S\", \"ION\"]}\n",
            "----\n",
            "num threads: 2\n",
            "decoding method: greedy_search\n",
            "Elapsed seconds: 3.639 s\n",
            "Real time factor (RTF): 3.639 / 28.165 = 0.129\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}
