{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM6PXZHDS199Mb3uOO6eCwN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k2-fsa/colab/blob/master/sherpa-onnx/sherpa_onnx_whisper_large_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "This colab shows how to run Whisper large v3 with sherpa-onnx on CPU as well as on GPU with CUDA."
      ],
      "metadata": {
        "id": "cWBieoYxoEO6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build sherpa-onnx from source with CUDA support"
      ],
      "metadata": {
        "id": "6rRcsXslFYMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "a = torch.rand(1000).cuda()\n",
        "print(a.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoLrkErcoDRM",
        "outputId": "eec3493f-a796-42d6-9d33-fba49e055e5e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdZzzgw4-Zs6",
        "outputId": "b87951c4-9b7a-4da6-edf4-bd44275df4a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sherpa-onnx'...\n",
            "remote: Enumerating objects: 13138, done.\u001b[K\n",
            "remote: Counting objects: 100% (4115/4115), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1285/1285), done.\u001b[K\n",
            "remote: Total 13138 (delta 3344), reused 3066 (delta 2813), pack-reused 9023\u001b[K\n",
            "Receiving objects: 100% (13138/13138), 6.19 MiB | 11.24 MiB/s, done.\n",
            "Resolving deltas: 100% (8647/8647), done.\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- No CMAKE_BUILD_TYPE given, default to Release\n",
            "\u001b[33mCMake Warning at CMakeLists.txt:85 (message):\n",
            "  Compiling for NVIDIA GPU is enabled.  Please make sure cudatoolkit\n",
            "\n",
            "  is installed on your system.  Otherwise, you will get errors at runtime.\n",
            "\n",
            "  Hint: You don't need sudo permission to install CUDA toolkit.  Please refer\n",
            "  to\n",
            "\n",
            "    https://k2-fsa.github.io/k2/installation/cuda-cudnn.html\n",
            "\n",
            "  to install CUDA toolkit if you have not installed it.\n",
            "\n",
            "\u001b[0m\n",
            "-- CMAKE_BUILD_TYPE: Release\n",
            "-- CMAKE_INSTALL_PREFIX: /usr/local\n",
            "-- BUILD_SHARED_LIBS ON\n",
            "-- SHERPA_ONNX_ENABLE_PYTHON OFF\n",
            "-- SHERPA_ONNX_ENABLE_TESTS OFF\n",
            "-- SHERPA_ONNX_ENABLE_CHECK OFF\n",
            "-- SHERPA_ONNX_ENABLE_PORTAUDIO ON\n",
            "-- SHERPA_ONNX_ENABLE_JNI OFF\n",
            "-- SHERPA_ONNX_ENABLE_C_API ON\n",
            "-- SHERPA_ONNX_ENABLE_WEBSOCKET ON\n",
            "-- SHERPA_ONNX_ENABLE_GPU ON\n",
            "-- SHERPA_ONNX_ENABLE_WASM OFF\n",
            "-- SHERPA_ONNX_ENABLE_WASM_TTS OFF\n",
            "-- SHERPA_ONNX_ENABLE_WASM_ASR OFF\n",
            "-- SHERPA_ONNX_ENABLE_WASM_KWS OFF\n",
            "-- SHERPA_ONNX_ENABLE_WASM_NODEJS OFF\n",
            "-- SHERPA_ONNX_ENABLE_BINARY ON\n",
            "-- SHERPA_ONNX_ENABLE_TTS ON\n",
            "-- SHERPA_ONNX_LINK_LIBSTDCPP_STATICALLY ON\n",
            "-- SHERPA_ONNX_USE_PRE_INSTALLED_ONNXRUNTIME_IF_AVAILABLE ON\n",
            "-- SHERPA_ONNX_ENABLE_SANITIZER: OFF\n",
            "-- SHERPA_ONNX_BUILD_C_API_EXAMPLES: ON\n",
            "-- IPO is enabled\n",
            "-- TTS is enabled\n",
            "-- C++ Standard version: 17\n",
            "-- Looking for C++ include alsa/asoundlib.h\n",
            "-- Looking for C++ include alsa/asoundlib.h - found\n",
            "-- With Alsa\n",
            "-- Looking for C++ include cxxabi.h\n",
            "-- Looking for C++ include cxxabi.h - found\n",
            "-- Looking for C++ include execinfo.h\n",
            "-- Looking for C++ include execinfo.h - found\n",
            "-- Downloading kaldi-native-fbank from https://github.com/csukuangfj/kaldi-native-fbank/archive/refs/tags/v1.20.0.tar.gz\n",
            "-- kaldi-native-fbank is downloaded to /content/sherpa-onnx/build/_deps/kaldi_native_fbank-src\n",
            "-- kaldi-native-fbank's binary dir is /content/sherpa-onnx/build/_deps/kaldi_native_fbank-build\n",
            "\u001b[0mCMake Deprecation Warning at build/_deps/kaldi_native_fbank-src/CMakeLists.txt:24 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- CMAKE_BUILD_TYPE: Release\n",
            "-- CMAKE_EXPORT_COMPILE_COMMANDS: \n",
            "-- BUILD_SHARED_LIBS: OFF\n",
            "-- KALDI_NATIVE_FBANK_BUILD_TESTS: OFF\n",
            "-- KALDI_NATIVE_FBANK_BUILD_PYTHON: OFF\n",
            "-- KALDI_NATIVE_FBANK_ENABLE_CHECK: OFF\n",
            "-- KALDI_NATIVE_FBANK_ENABLE_CHECK: OFF\n",
            "-- CMAKE_CXX_FLAGS: \n",
            "-- CMAKE_INSTALL_PREFIX: /usr/local\n",
            "-- Looking for C++ include cxxabi.h\n",
            "-- Looking for C++ include cxxabi.h - found\n",
            "-- Looking for C++ include execinfo.h\n",
            "-- Looking for C++ include execinfo.h - found\n",
            "-- Disable building Python\n",
            "-- Downloading kaldi-decoder from https://github.com/k2-fsa/kaldi-decoder/archive/refs/tags/v0.2.6.tar.gz\n",
            "-- kaldi-decoder is downloaded to /content/sherpa-onnx/build/_deps/kaldi_decoder-src\n",
            "-- kaldi-decoder's binary dir is /content/sherpa-onnx/build/_deps/kaldi_decoder-build\n",
            "-- CMAKE_BUILD_TYPE: Release\n",
            "-- Downloading kaldifst from https://github.com/k2-fsa/kaldifst/archive/refs/tags/v1.7.11.tar.gz\n",
            "-- kaldifst is downloaded to /content/sherpa-onnx/build/_deps/kaldifst-src\n",
            "-- kaldifst's binary dir is /content/sherpa-onnx/build/_deps/kaldifst-build\n",
            "-- CMAKE_BUILD_TYPE: Release\n",
            "-- CMAKE_BUILD_TYPE: Release\n",
            "-- CMAKE_INSTALL_PREFIX: /usr/local\n",
            "-- BUILD_SHARED_LIBS OFF\n",
            "-- C++ Standard version: 17\n",
            "-- CMAKE_CXX_FLAGS: \n",
            "-- Downloading openfst from https://github.com/csukuangfj/openfst/archive/refs/tags/sherpa-onnx-2024-06-19.tar.gz\n",
            "-- openfst is downloaded to /content/sherpa-onnx/build/_deps/openfst-src\n",
            "-- Found the following ICU libraries:\n",
            "--   data (required): /usr/lib/x86_64-linux-gnu/libicudata.so\n",
            "--   i18n (required): /usr/lib/x86_64-linux-gnu/libicui18n.so\n",
            "--   io (required): /usr/lib/x86_64-linux-gnu/libicuio.so\n",
            "--   test (required): /usr/lib/x86_64-linux-gnu/libicutest.so\n",
            "--   tu (required): /usr/lib/x86_64-linux-gnu/libicutu.so\n",
            "--   uc (required): /usr/lib/x86_64-linux-gnu/libicuuc.so\n",
            "-- Found ICU: /usr/include (found version \"70.1\") \n",
            "-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\")  \n",
            "\u001b[0mCMake Deprecation Warning at build/_deps/openfst-src/CMakeLists.txt:15 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- Downloading eigen from https://gitlab.com/libeigen/eigen/-/archive/3.4.0/eigen-3.4.0.tar.gz\n",
            "-- eigen is downloaded to /content/sherpa-onnx/build/_deps/eigen-src\n",
            "-- eigen's binary dir is /content/sherpa-onnx/build/_deps/eigen-build\n",
            "-- Performing Test EIGEN_COMPILER_SUPPORT_CPP11\n",
            "-- Performing Test EIGEN_COMPILER_SUPPORT_CPP11 - Success\n",
            "-- Performing Test COMPILER_SUPPORT_std=cpp03\n",
            "-- Performing Test COMPILER_SUPPORT_std=cpp03 - Success\n",
            "-- Performing Test standard_math_library_linked_to_automatically\n",
            "-- Performing Test standard_math_library_linked_to_automatically - Success\n",
            "-- Standard libraries to link to explicitly: none\n",
            "-- Performing Test COMPILER_SUPPORT_WERROR\n",
            "-- Performing Test COMPILER_SUPPORT_WERROR - Success\n",
            "-- Performing Test COMPILER_SUPPORT_pedantic\n",
            "-- Performing Test COMPILER_SUPPORT_pedantic - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wall\n",
            "-- Performing Test COMPILER_SUPPORT_Wall - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wextra\n",
            "-- Performing Test COMPILER_SUPPORT_Wextra - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wundef\n",
            "-- Performing Test COMPILER_SUPPORT_Wundef - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wcastalign\n",
            "-- Performing Test COMPILER_SUPPORT_Wcastalign - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wcharsubscripts\n",
            "-- Performing Test COMPILER_SUPPORT_Wcharsubscripts - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wnonvirtualdtor\n",
            "-- Performing Test COMPILER_SUPPORT_Wnonvirtualdtor - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wunusedlocaltypedefs\n",
            "-- Performing Test COMPILER_SUPPORT_Wunusedlocaltypedefs - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wpointerarith\n",
            "-- Performing Test COMPILER_SUPPORT_Wpointerarith - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wwritestrings\n",
            "-- Performing Test COMPILER_SUPPORT_Wwritestrings - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wformatsecurity\n",
            "-- Performing Test COMPILER_SUPPORT_Wformatsecurity - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wshorten64to32\n",
            "-- Performing Test COMPILER_SUPPORT_Wshorten64to32 - Failed\n",
            "-- Performing Test COMPILER_SUPPORT_Wlogicalop\n",
            "-- Performing Test COMPILER_SUPPORT_Wlogicalop - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wenumconversion\n",
            "-- Performing Test COMPILER_SUPPORT_Wenumconversion - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wcpp11extensions\n",
            "-- Performing Test COMPILER_SUPPORT_Wcpp11extensions - Failed\n",
            "-- Performing Test COMPILER_SUPPORT_Wdoublepromotion\n",
            "-- Performing Test COMPILER_SUPPORT_Wdoublepromotion - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wshadow\n",
            "-- Performing Test COMPILER_SUPPORT_Wshadow - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wnopsabi\n",
            "-- Performing Test COMPILER_SUPPORT_Wnopsabi - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wnovariadicmacros\n",
            "-- Performing Test COMPILER_SUPPORT_Wnovariadicmacros - Success\n",
            "-- Performing Test COMPILER_SUPPORT_Wnolonglong\n",
            "-- Performing Test COMPILER_SUPPORT_Wnolonglong - Success\n",
            "-- Performing Test COMPILER_SUPPORT_fnochecknew\n",
            "-- Performing Test COMPILER_SUPPORT_fnochecknew - Success\n",
            "-- Performing Test COMPILER_SUPPORT_fnocommon\n",
            "-- Performing Test COMPILER_SUPPORT_fnocommon - Success\n",
            "-- Performing Test COMPILER_SUPPORT_fstrictaliasing\n",
            "-- Performing Test COMPILER_SUPPORT_fstrictaliasing - Success\n",
            "-- Performing Test COMPILER_SUPPORT_wd981\n",
            "-- Performing Test COMPILER_SUPPORT_wd981 - Failed\n",
            "-- Performing Test COMPILER_SUPPORT_wd2304\n",
            "-- Performing Test COMPILER_SUPPORT_wd2304 - Failed\n",
            "-- Performing Test COMPILER_SUPPORT_STRICTANSI\n",
            "-- Performing Test COMPILER_SUPPORT_STRICTANSI - Failed\n",
            "-- Performing Test COMPILER_SUPPORT_Qunusedarguments\n",
            "-- Performing Test COMPILER_SUPPORT_Qunusedarguments - Failed\n",
            "-- Performing Test COMPILER_SUPPORT_ansi\n",
            "-- Performing Test COMPILER_SUPPORT_ansi - Success\n",
            "-- Performing Test COMPILER_SUPPORT_OPENMP\n",
            "-- Performing Test COMPILER_SUPPORT_OPENMP - Success\n",
            "-- Looking for a Fortran compiler\n",
            "-- Looking for a Fortran compiler - /usr/bin/f95\n",
            "-- The Fortran compiler identification is GNU 11.4.0\n",
            "-- Detecting Fortran compiler ABI info\n",
            "-- Detecting Fortran compiler ABI info - done\n",
            "-- Check for working Fortran compiler: /usr/bin/f95 - skipped\n",
            "-- Found unsuitable Qt version \"\" from NOTFOUND\n",
            "-- Qt4 not found, so disabling the mandelbrot and opengl demos\n",
            "-- Could NOT find CHOLMOD (missing: CHOLMOD_INCLUDES CHOLMOD_LIBRARIES) \n",
            "-- Could NOT find UMFPACK (missing: UMFPACK_INCLUDES UMFPACK_LIBRARIES) \n",
            "-- Could NOT find KLU (missing: KLU_INCLUDES KLU_LIBRARIES) \n",
            "-- Performing Test SUPERLU_HAS_GLOBAL_MEM_USAGE_T\n",
            "-- Performing Test SUPERLU_HAS_GLOBAL_MEM_USAGE_T - Success\n",
            "-- Performing Test SUPERLU_HAS_CLEAN_ENUMS\n",
            "-- Performing Test SUPERLU_HAS_CLEAN_ENUMS - Success\n",
            "-- Performing Test SUPERLU_HAS_GLOBALLU_T\n",
            "-- Performing Test SUPERLU_HAS_GLOBALLU_T - Success\n",
            "-- Found SuperLU: /usr/include/superlu (found suitable version \"5.0\", minimum required is \"4.0\") \n",
            "-- Checking for one of the modules 'hwloc'\n",
            "-- Performing Test HAVE_HWLOC_PARENT_MEMBER\n",
            "-- Performing Test HAVE_HWLOC_PARENT_MEMBER - Success\n",
            "-- Performing Test HAVE_HWLOC_CACHE_ATTR\n",
            "-- Performing Test HAVE_HWLOC_CACHE_ATTR - Success\n",
            "-- Performing Test HAVE_HWLOC_OBJ_PU\n",
            "-- Performing Test HAVE_HWLOC_OBJ_PU - Success\n",
            "-- Looking for hwloc_bitmap_free in hwloc\n",
            "-- Looking for hwloc_bitmap_free in hwloc - found\n",
            "-- A version of Pastix has been found but pastix_nompi.h does not exist in the include directory. Because Eigen tests require a version without MPI, we disable the Pastix backend.\n",
            "-- \n",
            "-- Configured Eigen 3.4.0\n",
            "-- \n",
            "-- Available targets (use: make TARGET):\n",
            "-- ---------+--------------------------------------------------------------\n",
            "-- Target   |   Description\n",
            "-- ---------+--------------------------------------------------------------\n",
            "-- install  | Install Eigen. Headers will be installed to:\n",
            "--          |     <CMAKE_INSTALL_PREFIX>/<INCLUDE_INSTALL_DIR>\n",
            "--          |   Using the following values:\n",
            "--          |     CMAKE_INSTALL_PREFIX: /usr/local\n",
            "--          |     INCLUDE_INSTALL_DIR:  include/eigen3\n",
            "--          |   Change the install location of Eigen headers using:\n",
            "--          |     cmake . -DCMAKE_INSTALL_PREFIX=yourprefix\n",
            "--          |   Or:\n",
            "--          |     cmake . -DINCLUDE_INSTALL_DIR=yourdir\n",
            "-- doc      | Generate the API documentation, requires Doxygen & LaTeX\n",
            "-- blas     | Build BLAS library (not the same thing as Eigen)\n",
            "-- uninstall| Remove files installed by the install target\n",
            "-- ---------+--------------------------------------------------------------\n",
            "-- \n",
            "-- CMAKE_SYSTEM_NAME: Linux\n",
            "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "-- location_onnxruntime_header_dir: location_onnxruntime_header_dir-NOTFOUND\n",
            "-- location_onnxruntime_lib: location_onnxruntime_lib-NOTFOUND\n",
            "-- location_onnxruntime_cuda_lib: location_onnxruntime_cuda_lib-NOTFOUND\n",
            "-- Could not find a pre-installed onnxruntime.\n",
            "-- Downloading pre-compiled onnxruntime\n",
            "-- CMAKE_SYSTEM_NAME: Linux\n",
            "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "-- CMAKE_SYSTEM_NAME: Linux\n",
            "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "-- Downloading onnxruntime from https://github.com/microsoft/onnxruntime/releases/download/v1.18.1/onnxruntime-linux-x64-gpu-1.18.1.tgz\n",
            "-- onnxruntime is downloaded to /content/sherpa-onnx/build/_deps/onnxruntime-src\n",
            "-- location_onnxruntime: /content/sherpa-onnx/build/_deps/onnxruntime-src/lib/libonnxruntime.so\n",
            "-- location_onnxruntime_cuda_lib: /content/sherpa-onnx/build/_deps/onnxruntime-src/lib/libonnxruntime_providers_cuda.so\n",
            "-- location_onnxruntime_providers_shared_lib: /content/sherpa-onnx/build/_deps/onnxruntime-src/lib/libonnxruntime_providers_shared.so\n",
            "-- onnxruntime lib files: /content/sherpa-onnx/build/_deps/onnxruntime-src/lib/libonnxruntime.so;/content/sherpa-onnx/build/_deps/onnxruntime-src/lib/libonnxruntime.so.1.18.1;/content/sherpa-onnx/build/_deps/onnxruntime-src/lib/libonnxruntime_providers_cuda.so;/content/sherpa-onnx/build/_deps/onnxruntime-src/lib/libonnxruntime_providers_shared.so;/content/sherpa-onnx/build/_deps/onnxruntime-src/lib/libonnxruntime_providers_tensorrt.so\n",
            "-- Downloading simple-sentencepiece https://github.com/pkufool/simple-sentencepiece/archive/refs/tags/v0.7.tar.gz\n",
            "-- simple-sentencepiece is downloaded to /content/sherpa-onnx/build/_deps/simple-sentencepiece-src\n",
            "-- Performing Test SBPE_COMPILER_SUPPORTS_CXX14\n",
            "-- Performing Test SBPE_COMPILER_SUPPORTS_CXX14 - Success\n",
            "-- C++ Standard version: 17\n",
            "-- ONNXRUNTIME_DIR: /content/sherpa-onnx/build/_deps/onnxruntime-src\n",
            "-- Downloading portaudio from http://files.portaudio.com/archives/pa_stable_v190700_20210406.tgz\n",
            "-- portaudio is downloaded to /content/sherpa-onnx/build/_deps/portaudio-src\n",
            "-- portaudio's binary dir is /content/sherpa-onnx/build/_deps/portaudio-build\n",
            "\u001b[0mCMake Deprecation Warning at build/_deps/portaudio-src/CMakeLists.txt:7 (CMAKE_MINIMUM_REQUIRED):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- Found ALSA: /usr/lib/x86_64-linux-gnu/libasound.so (found version \"1.2.6.1\") \n",
            "-- Downloading websocketpp from https://github.com/zaphoyd/websocketpp/archive/b9aeec6eaf3d5610503439b4fae3581d9aff08e8.zip\n",
            "-- websocketpp is downloaded to /content/sherpa-onnx/build/_deps/websocketpp-src\n",
            "-- Downloading asio https://github.com/chriskohlhoff/asio/archive/refs/tags/asio-1-24-0.tar.gz\n",
            "-- asio is downloaded to /content/sherpa-onnx/build/_deps/asio-src\n",
            "-- Downloading espeak-ng from https://github.com/csukuangfj/espeak-ng/archive/f6fed6c58b5e0998b8e68c6610125e2d07d595a7.zip\n",
            "-- espeak-ng is downloaded to /content/sherpa-onnx/build/_deps/espeak_ng-src\n",
            "-- espeak-ng binary dir is /content/sherpa-onnx/build/_deps/espeak_ng-build\n",
            "-- Looking for mkstemp\n",
            "-- Looking for mkstemp - found\n",
            "-- Configuration:\n",
            "--   shared: OFF\n",
            "--   mbrola: OFF (MBROLA_BIN-NOTFOUND)\n",
            "--   libsonic: OFF (SONIC_LIB-NOTFOUND SONIC_INC-NOTFOUND)\n",
            "--   libpcaudio: OFF (PCAUDIO_LIB-NOTFOUND PCAUDIO_INC-NOTFOUND)\n",
            "--   klatt: OFF\n",
            "--   speech-player: OFF\n",
            "--   async: OFF\n",
            "-- ESPEAK_NG_DIR: /content/sherpa-onnx/build/_deps/espeak_ng-src\n",
            "-- Downloading piper-phonemize from https://github.com/csukuangfj/piper-phonemize/archive/dc6b5f4441bffe521047086930b0fc12686acd56.zip\n",
            "-- piper-phonemize is downloaded to /content/sherpa-onnx/build/_deps/piper_phonemize-src\n",
            "-- piper-phonemize binary dir is /content/sherpa-onnx/build/_deps/piper_phonemize-build\n",
            "-- ESPEAK_NG_DIR: /content/sherpa-onnx/build/_deps/espeak_ng-src\n",
            "-- ONNXRUNTIME_DIR: /content/sherpa-onnx/build/_deps/onnxruntime-src\n",
            "-- Downloading cppjieba https://github.com/csukuangfj/cppjieba/archive/refs/tags/sherpa-onnx-2024-04-19.tar.gz\n",
            "-- cppjieba is downloaded to /content/sherpa-onnx/build/_deps/cppjieba-src\n",
            "\u001b[0mCMake Deprecation Warning at build/_deps/cppjieba-src/CMakeLists.txt:3 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- Downloading cargs https://github.com/likle/cargs/archive/refs/tags/v1.0.3.tar.gz\n",
            "-- cargs is downloaded to /content/sherpa-onnx/build/_deps/cargs-src\n",
            "-- CMAKE_CXX_FLAGS: \n",
            "-- CMAKE_CXX_FLAGS: \n",
            "-- Configuring done (27.3s)\n",
            "-- Generating done (0.2s)\n",
            "-- Build files have been written to: /content/sherpa-onnx/build\n",
            "[  0%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/ucd-tools/CMakeFiles/ucd.dir/src/case.c.o\u001b[0m\n",
            "[  0%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/feature-fbank.cc.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/ucd-tools/CMakeFiles/ucd.dir/src/categories.c.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/ucd-tools/CMakeFiles/ucd.dir/src/ctype.c.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/ucd-tools/CMakeFiles/ucd.dir/src/proplist.c.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/ucd-tools/CMakeFiles/ucd.dir/src/scripts.c.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/ucd-tools/CMakeFiles/ucd.dir/src/tostring.c.o\u001b[0m\n",
            "[  4%] \u001b[32m\u001b[1mLinking C static library ../../../../lib/libucd.a\u001b[0m\n",
            "[  4%] Built target ucd\n",
            "[  7%] \u001b[32mBuilding CXX object _deps/openfst-build/src/lib/CMakeFiles/fst.dir/compat.cc.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object _deps/openfst-build/src/lib/CMakeFiles/fst.dir/flags.cc.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/feature-functions.cc.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/feature-mfcc.cc.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object _deps/openfst-build/src/lib/CMakeFiles/fst.dir/fst.cc.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/feature-window.cc.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/fftsg.cc.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/kaldi-math.cc.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/mel-computations.cc.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/online-feature.cc.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/rfft.cc.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object _deps/kaldi_native_fbank-build/kaldi-native-fbank/csrc/CMakeFiles/kaldi-native-fbank-core.dir/whisper-feature.cc.o\u001b[0m\n",
            "[ 11%] \u001b[32m\u001b[1mLinking CXX static library ../../../../lib/libkaldi-native-fbank-core.a\u001b[0m\n",
            "[ 11%] Built target kaldi-native-fbank-core\n",
            "[ 14%] \u001b[32mBuilding CXX object _deps/simple-sentencepiece-build/ssentencepiece/csrc/CMakeFiles/ssentencepiece_core.dir/ssentencepiece.cc.o\u001b[0m\n",
            "[ 14%] \u001b[32m\u001b[1mLinking CXX static library ../../../../lib/libssentencepiece_core.a\u001b[0m\n",
            "[ 14%] Built target ssentencepiece_core\n",
            "[ 14%] \u001b[32mBuilding CXX object _deps/openfst-build/src/lib/CMakeFiles/fst.dir/properties.cc.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object _deps/openfst-build/src/lib/CMakeFiles/fst.dir/symbol-table.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object _deps/openfst-build/src/lib/CMakeFiles/fst.dir/util.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object _deps/openfst-build/src/lib/CMakeFiles/fst.dir/symbol-table-ops.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object _deps/openfst-build/src/lib/CMakeFiles/fst.dir/mapped-file.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object _deps/openfst-build/src/lib/CMakeFiles/fst.dir/weight.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/common.c.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/mnemonics.c.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/error.c.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/ieee80.c.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/compiledata.c.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/compiledict.c.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/dictionary.c.o\u001b[0m\n",
            "[ 19%] \u001b[32m\u001b[1mLinking CXX static library ../../../../lib/libsherpa-onnx-fst.a\u001b[0m\n",
            "[ 19%] Built target fst\n",
            "[ 21%] \u001b[32mBuilding CXX object _deps/openfst-build/src/extensions/far/CMakeFiles/fstfar.dir/sttable.cc.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/encoding.c.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/intonation.c.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/langopts.c.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/numbers.c.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object _deps/openfst-build/src/extensions/far/CMakeFiles/fstfar.dir/stlist.cc.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/phoneme.c.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/phonemelist.c.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/readclause.c.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/setlengths.c.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/soundicon.c.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/spect.c.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/ssml.c.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/synthdata.c.o\u001b[0m\n",
            "[ 28%] \u001b[32m\u001b[1mLinking CXX static library ../../../../../lib/libsherpa-onnx-fstfar.a\u001b[0m\n",
            "[ 28%] Built target fstfar\n",
            "[ 28%] \u001b[32mBuilding CXX object _deps/kaldifst-build/kaldifst/csrc/CMakeFiles/kaldifst_core.dir/context-fst.cc.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/synthesize.c.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/tr_languages.c.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/translate.c.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/translateword.c.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/voices.c.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/wavegen.c.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/speech.c.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding C object _deps/espeak_ng-build/src/libespeak-ng/CMakeFiles/espeak-ng.dir/espeak_api.c.o\u001b[0m\n",
            "[ 30%] \u001b[32m\u001b[1mLinking C static library ../../../../lib/libespeak-ng.a\u001b[0m\n",
            "[ 30%] Built target espeak-ng\n",
            "[ 33%] \u001b[32mBuilding CXX object _deps/piper_phonemize-build/CMakeFiles/piper_phonemize.dir/src/phonemize.cpp.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object _deps/kaldifst-build/kaldifst/csrc/CMakeFiles/kaldifst_core.dir/kaldi-fst-io.cc.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object _deps/piper_phonemize-build/CMakeFiles/piper_phonemize.dir/src/phoneme_ids.cpp.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object _deps/piper_phonemize-build/CMakeFiles/piper_phonemize.dir/src/tashkeel.cpp.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object _deps/kaldifst-build/kaldifst/csrc/CMakeFiles/kaldifst_core.dir/kaldi-holder.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object _deps/kaldifst-build/kaldifst/csrc/CMakeFiles/kaldifst_core.dir/kaldi-io.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object _deps/piper_phonemize-build/CMakeFiles/piper_phonemize.dir/src/shared.cpp.o\u001b[0m\n",
            "[ 35%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libpiper_phonemize.a\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object _deps/kaldifst-build/kaldifst/csrc/CMakeFiles/kaldifst_core.dir/kaldi-math.cc.o\u001b[0m\n",
            "[ 35%] Built target piper_phonemize\n",
            "[ 35%] \u001b[32mBuilding CXX object _deps/kaldifst-build/kaldifst/csrc/CMakeFiles/kaldifst_core.dir/kaldi-semaphore.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object _deps/kaldifst-build/kaldifst/csrc/CMakeFiles/kaldifst_core.dir/kaldi-table.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object _deps/kaldifst-build/kaldifst/csrc/CMakeFiles/kaldifst_core.dir/parse-options.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object _deps/kaldifst-build/kaldifst/csrc/CMakeFiles/kaldifst_core.dir/text-normalizer.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object _deps/kaldifst-build/kaldifst/csrc/CMakeFiles/kaldifst_core.dir/text-utils.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32m\u001b[1mLinking CXX static library ../../../../lib/libsherpa-onnx-kaldifst-core.a\u001b[0m\n",
            "[ 38%] Built target kaldifst_core\n",
            "[ 38%] \u001b[32mBuilding CXX object _deps/kaldi_decoder-build/kaldi-decoder/csrc/CMakeFiles/kaldi-decoder-core.dir/decodable-ctc.cc.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object _deps/kaldi_decoder-build/kaldi-decoder/csrc/CMakeFiles/kaldi-decoder-core.dir/eigen.cc.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object _deps/kaldi_decoder-build/kaldi-decoder/csrc/CMakeFiles/kaldi-decoder-core.dir/faster-decoder.cc.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object _deps/kaldi_decoder-build/kaldi-decoder/csrc/CMakeFiles/kaldi-decoder-core.dir/lattice-faster-decoder.cc.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object _deps/kaldi_decoder-build/kaldi-decoder/csrc/CMakeFiles/kaldi-decoder-core.dir/lattice-simple-decoder.cc.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object _deps/kaldi_decoder-build/kaldi-decoder/csrc/CMakeFiles/kaldi-decoder-core.dir/simple-decoder.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32m\u001b[1mLinking CXX static library ../../../../lib/libkaldi-decoder-core.a\u001b[0m\n",
            "[ 42%] Built target kaldi-decoder-core\n",
            "[ 42%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/base64-decode.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/cat.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/circular-buffer.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/context-graph.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/endpoint.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/features.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/file-utils.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/hypothesis.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/keyword-spotter-impl.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/keyword-spotter.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-ctc-fst-decoder-config.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-ctc-fst-decoder.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-ctc-greedy-search-decoder.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-ctc-model.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-lm-config.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-lm.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-model-config.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-nemo-enc-dec-ctc-model-config.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-nemo-enc-dec-ctc-model.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-paraformer-greedy-search-decoder.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-paraformer-model-config.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-paraformer-model.cc.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-recognizer-impl.cc.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-recognizer.cc.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-rnn-lm.cc.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-stream.cc.o\u001b[0m\n",
            "[ 54%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-tdnn-ctc-model.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-tdnn-model-config.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-telespeech-ctc-model.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-transducer-greedy-search-decoder.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-transducer-greedy-search-nemo-decoder.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-transducer-model-config.cc.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-transducer-model.cc.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-transducer-modified-beam-search-decoder.cc.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-transducer-nemo-model.cc.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-wenet-ctc-model-config.cc.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-wenet-ctc-model.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-whisper-greedy-search-decoder.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-whisper-model-config.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-whisper-model.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-zipformer-ctc-model-config.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-zipformer-ctc-model.cc.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-conformer-transducer-model.cc.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-ctc-fst-decoder-config.cc.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-ctc-fst-decoder.cc.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-ctc-greedy-search-decoder.cc.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-ctc-model.cc.o\u001b[0m\n",
            "[ 64%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-lm-config.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-lm.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-lstm-transducer-model.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-model-config.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-nemo-ctc-model-config.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-nemo-ctc-model.cc.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-paraformer-model-config.cc.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-paraformer-model.cc.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-recognizer-impl.cc.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-recognizer.cc.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-rnn-lm.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-stream.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-transducer-decoder.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-transducer-greedy-search-decoder.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-transducer-model-config.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-transducer-model.cc.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-transducer-modified-beam-search-decoder.cc.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-transducer-nemo-model.cc.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-transducer-greedy-search-nemo-decoder.cc.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-wenet-ctc-model-config.cc.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-wenet-ctc-model.cc.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-zipformer-transducer-model.cc.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-zipformer2-ctc-model-config.cc.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-zipformer2-ctc-model.cc.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/online-zipformer2-transducer-model.cc.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/onnx-utils.cc.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/packed-sequence.cc.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/pad-sequence.cc.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/parse-options.cc.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/provider-config.cc.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/provider.cc.o\u001b[0m\n",
            "In file included from \u001b[01m\u001b[K/content/sherpa-onnx/sherpa-onnx/csrc/provider-config.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/sherpa-onnx/sherpa-onnx/csrc/provider-config.cc:5\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/sherpa-onnx/sherpa-onnx/csrc/provider-config.cc:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kbool sherpa_onnx::TensorrtConfig::Validate() const\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/sherpa-onnx/sherpa-onnx/csrc/provider-config.cc:63:22:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%lld\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Klong long int\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Klong int\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wformat=\u0007-Wformat=\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   63 |     SHERPA_ONNX_LOGE(\u001b[01;35m\u001b[K\"trt_max_workspace_size: %lld is not valid.\"\u001b[m\u001b[K,\n",
            "      |                      \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "   64 |         \u001b[32m\u001b[Ktrt_max_workspace_size\u001b[m\u001b[K);\n",
            "      |         \u001b[32m\u001b[K~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "      |         \u001b[32m\u001b[K|\u001b[m\u001b[K\n",
            "      |         \u001b[32m\u001b[Klong int\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/sherpa-onnx/sherpa-onnx/csrc/macros.h:32:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KSHERPA_ONNX_LOGE\u001b[m\u001b[K’\n",
            "   32 |     fprintf(stderr, ##\u001b[01;36m\u001b[K__VA_ARGS__\u001b[m\u001b[K);                  \\\n",
            "      |                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/sherpa-onnx/sherpa-onnx/csrc/provider-config.cc:63:50:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kformat string is defined here\n",
            "   63 |     SHERPA_ONNX_LOGE(\"trt_max_workspace_size: \u001b[01;36m\u001b[K%lld\u001b[m\u001b[K is not valid.\",\n",
            "      |                                               \u001b[01;36m\u001b[K~~~^\u001b[m\u001b[K\n",
            "      |                                                  \u001b[01;36m\u001b[K|\u001b[m\u001b[K\n",
            "      |                                                  \u001b[01;36m\u001b[Klong long int\u001b[m\u001b[K\n",
            "      |                                               \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/sherpa-onnx/sherpa-onnx/csrc/provider-config.cc:\u001b[m\u001b[K At top level:\n",
            "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kunrecognized command-line option ‘\u001b[01m\u001b[K-Wno-missing-template-keyword\u001b[m\u001b[K’ may have been intended to silence earlier diagnostics\n",
            "[ 80%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/resample.cc.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/session.cc.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/silero-vad-model-config.cc.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/silero-vad-model.cc.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/slice.cc.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/spoken-language-identification-impl.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/spoken-language-identification.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/stack.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/symbol-table.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/text-utils.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/transducer-keyword-decoder.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/transpose.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/unbind.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/utils.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/vad-model-config.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/vad-model.cc.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/voice-activity-detector.cc.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/wave-reader.cc.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/wave-writer.cc.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/speaker-embedding-extractor-impl.cc.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/speaker-embedding-extractor-model.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/speaker-embedding-extractor-nemo-model.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/speaker-embedding-extractor.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/speaker-embedding-manager.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/audio-tagging-impl.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/audio-tagging-label-file.cc.o\u001b[0m\n",
            "[ 92%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/audio-tagging-model-config.cc.o\u001b[0m\n",
            "[ 92%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/audio-tagging.cc.o\u001b[0m\n",
            "[ 92%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-ced-model.cc.o\u001b[0m\n",
            "[ 92%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-zipformer-audio-tagging-model-config.cc.o\u001b[0m\n",
            "[ 92%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-zipformer-audio-tagging-model.cc.o\u001b[0m\n",
            "[ 95%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-ct-transformer-model.cc.o\u001b[0m\n",
            "[ 95%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-punctuation-impl.cc.o\u001b[0m\n",
            "[ 95%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-punctuation-model-config.cc.o\u001b[0m\n",
            "[ 95%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-punctuation.cc.o\u001b[0m\n",
            "[ 95%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/jieba-lexicon.cc.o\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/lexicon.cc.o\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-tts-character-frontend.cc.o\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-tts-impl.cc.o\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-tts-model-config.cc.o\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-tts-vits-model-config.cc.o\u001b[0m\n",
            "[100%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-tts-vits-model.cc.o\u001b[0m\n",
            "[100%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/offline-tts.cc.o\u001b[0m\n",
            "[100%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-core.dir/piper-phonemize-lexicon.cc.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libsherpa-onnx-core.a\u001b[0m\n",
            "[100%] Built target sherpa-onnx-core\n",
            "[100%] \u001b[32mBuilding CXX object sherpa-onnx/csrc/CMakeFiles/sherpa-onnx-offline.dir/sherpa-onnx-offline.cc.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/sherpa-onnx-offline\u001b[0m\n",
            "[100%] Built target sherpa-onnx-offline\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "%%shell\n",
        "\n",
        "git clone https://github.com/k2-fsa/sherpa-onnx\n",
        "cd sherpa-onnx\n",
        "\n",
        "mkdir -p build\n",
        "cd build\n",
        "cmake \\\n",
        "  -DBUILD_SHARED_LIBS=ON \\\n",
        "  -DSHERPA_ONNX_ENABLE_GPU=ON \\\n",
        "  ..\n",
        "\n",
        "make -j2 sherpa-onnx-offline"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GX5PO_IaigYO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "git lfs install\n",
        "git clone https://huggingface.co/csukuangfj/sherpa-onnx-whisper-large-v3\n",
        "\n",
        "ls -lh sherpa-onnx-whisper-large-v3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uwpcVhm-hyA",
        "outputId": "74049a0f-70a3-48ee-f19f-f7b66c85fe22"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'sherpa-onnx-whisper-large-v3'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 21 (delta 1), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (21/21), 1.00 MiB | 1.44 MiB/s, done.\n",
            "Filtering content: 100% (4/4), 5.75 GiB | 54.10 MiB/s, done.\n",
            "total 5.8G\n",
            "-rw-r--r-- 1 root root 2.8M Jul 12 16:10 large-v3-decoder.onnx\n",
            "-rw-r--r-- 1 root root 3.0G Jul 12 16:12 large-v3-decoder.weights\n",
            "-rw-r--r-- 1 root root 745K Jul 12 16:10 large-v3-encoder.onnx\n",
            "-rw-r--r-- 1 root root 2.8G Jul 12 16:11 large-v3-encoder.weights\n",
            "-rw-r--r-- 1 root root 798K Jul 12 16:10 large-v3-tokens.txt\n",
            "drwxr-xr-x 2 root root 4.0K Jul 12 16:10 test_wavs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run with CPU"
      ],
      "metadata": {
        "id": "nWy3bMPb_Twg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "ls -lh sherpa-onnx/build/bin/sherpa-onnx-offline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGk2EvRn-kPP",
        "outputId": "a59be7c2-ddc4-4222-a628-c9222777b32d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rwxr-xr-x 1 root root 2.6M Jul 12 16:10 sherpa-onnx/build/bin/sherpa-onnx-offline\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "exe=$PWD/sherpa-onnx/build/bin/sherpa-onnx-offline\n",
        "\n",
        "echo $exe\n",
        "cd sherpa-onnx-whisper-large-v3\n",
        "\n",
        "time $exe \\\n",
        "  --whisper-encoder=./large-v3-encoder.onnx \\\n",
        "  --whisper-decoder=./large-v3-decoder.onnx \\\n",
        "  --tokens=./large-v3-tokens.txt \\\n",
        "  --num-threads=2 \\\n",
        "  ./test_wavs/0.wav\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIOiH5u__Yjj",
        "outputId": "2ba56d7f-e992-4a76-f53f-1c0b22ba2c35"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/build/bin/sherpa-onnx-offline\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:375 /content/sherpa-onnx/build/bin/sherpa-onnx-offline --whisper-encoder=./large-v3-encoder.onnx --whisper-decoder=./large-v3-decoder.onnx --tokens=./large-v3-tokens.txt --num-threads=2 ./test_wavs/0.wav \n",
            "\n",
            "OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=\"\", decoder_filename=\"\", joiner_filename=\"\"), paraformer=OfflineParaformerModelConfig(model=\"\"), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=\"\"), whisper=OfflineWhisperModelConfig(encoder=\"./large-v3-encoder.onnx\", decoder=\"./large-v3-decoder.onnx\", language=\"\", task=\"transcribe\", tail_paddings=-1), tdnn=OfflineTdnnModelConfig(model=\"\"), zipformer_ctc=OfflineZipformerCtcModelConfig(model=\"\"), wenet_ctc=OfflineWenetCtcModelConfig(model=\"\"), telespeech_ctc=\"\", tokens=\"./large-v3-tokens.txt\", num_threads=2, debug=False, provider=\"cpu\", model_type=\"\", modeling_unit=\"cjkchar\", bpe_vocab=\"\"), lm_config=OfflineLMConfig(model=\"\", scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=\"\", max_active=3000), decoding_method=\"greedy_search\", max_active_paths=4, hotwords_file=\"\", hotwords_score=1.5, blank_penalty=0, rule_fsts=\"\", rule_fars=\"\")\n",
            "Creating recognizer ...\n",
            "Started\n",
            "Done!\n",
            "\n",
            "./test_wavs/0.wav\n",
            "{\"text\": \" after early nightfall the yellow lamps would light up here and there the squalid quarter of the brothels\", \"timestamps\": [], \"tokens\":[\" after\", \" early\", \" night\", \"fall\", \" the\", \" yellow\", \" lamps\", \" would\", \" light\", \" up\", \" here\", \" and\", \" there\", \" the\", \" squ\", \"alid\", \" quarter\", \" of\", \" the\", \" broth\", \"els\"], \"words\": []}\n",
            "----\n",
            "num threads: 2\n",
            "decoding method: greedy_search\n",
            "Elapsed seconds: 54.070 s\n",
            "Real time factor (RTF): 54.070 / 6.625 = 8.162\n",
            "\n",
            "real\t1m32.107s\n",
            "user\t1m39.877s\n",
            "sys\t0m10.405s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install CUDA 11.8\n",
        "\n",
        "We are using onnxruntime 1.18.1 in sherpa-onnx.\n",
        "\n",
        "According to\n",
        "https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html\n",
        "we need to install cuda 11.8\n",
        "\n",
        "please follow\n",
        "https://k2-fsa.github.io/k2/installation/cuda-cudnn.html#cuda-11-8\n",
        "to install it."
      ],
      "metadata": {
        "id": "vuZ1hHfrm7MH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p /star-fj/fangjun/software/cuda-11.8.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdMZzS7JJfF_",
        "outputId": "bc370327-4cd8-40be-f0ac-64e6d91cd2f2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run\n",
        "\n",
        "chmod +x cuda_11.8.0_520.61.05_linux.run\n",
        "\n",
        "./cuda_11.8.0_520.61.05_linux.run \\\n",
        "  --silent \\\n",
        "  --toolkit \\\n",
        "  --installpath=/star-fj/fangjun/software/cuda-11.8.0 \\\n",
        "  --no-opengl-libs \\\n",
        "  --no-drm \\\n",
        "  --no-man-page"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTS_ZHUehQYj",
        "outputId": "26172b8a-9a42-4440-daf6-35fd8d773c42"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-12 16:13:55--  https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4336730777 (4.0G) [application/octet-stream]\n",
            "Saving to: ‘cuda_11.8.0_520.61.05_linux.run’\n",
            "\n",
            "cuda_11.8.0_520.61. 100%[===================>]   4.04G  65.4MB/s    in 87s     \n",
            "\n",
            "2024-07-12 16:15:23 (47.3 MB/s) - ‘cuda_11.8.0_520.61.05_linux.run’ saved [4336730777/4336730777]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "wget https://huggingface.co/csukuangfj/cudnn/resolve/main/cudnn-linux-x86_64-8.9.1.23_cuda11-archive.tar.xz\n",
        "\n",
        "tar xvf cudnn-linux-x86_64-8.9.1.23_cuda11-archive.tar.xz --strip-components=1 -C /star-fj/fangjun/software/cuda-11.8.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqqPcm8XmIEu",
        "outputId": "9e1fe3d8-39b1-4fde-bbd7-2c741f56be5b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-12 16:19:03--  https://huggingface.co/csukuangfj/cudnn/resolve/main/cudnn-linux-x86_64-8.9.1.23_cuda11-archive.tar.xz\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.23, 18.164.174.17, 18.164.174.118, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/csukuangfj/cudnn/a6d9887267e28590c9db95ce65cbe96a668df0352338b7d337e0532ded33485c?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27cudnn-linux-x86_64-8.9.1.23_cuda11-archive.tar.xz%3B+filename%3D%22cudnn-linux-x86_64-8.9.1.23_cuda11-archive.tar.xz%22%3B&response-content-type=application%2Fx-xz&Expires=1721060343&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMTA2MDM0M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9jc3VrdWFuZ2ZqL2N1ZG5uL2E2ZDk4ODcyNjdlMjg1OTBjOWRiOTVjZTY1Y2JlOTZhNjY4ZGYwMzUyMzM4YjdkMzM3ZTA1MzJkZWQzMzQ4NWM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=lmgoRw6RnLeofbNMxXJYixzbug-AaJpkRISXLY6T%7EHq77MgHBsoS%7Ez3L31Zh1gII5mefjvbcenXy9ruW6A6O%7EqJHXM4i3ntti8NtkGDSpecvYMwy9mjhFCudO%7Ew-760fnmjNETOLCPVx22Wv-DzJJWw6r1YX-%7Euy4xGlxyRcC00PSHAdicO3xeYJ2KWo6eDICVqQ0IKQPCcq7QS6d1vonM7GBsOqQU%7EN%7EQW-UpNHSjaLSRKO5cAAThsneaka-bM8Sou0HDmdW-Fcys9aoJq5qCbsKvreNiTJGMjnaeuwVpo8nrqMKMBSV-BLOZsooUN8KulBv3chFMYHv15XNzHM-Q__&Key-Pair-Id=K3ESJI6DHPFC7 [following]\n",
            "--2024-07-12 16:19:03--  https://cdn-lfs.huggingface.co/csukuangfj/cudnn/a6d9887267e28590c9db95ce65cbe96a668df0352338b7d337e0532ded33485c?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27cudnn-linux-x86_64-8.9.1.23_cuda11-archive.tar.xz%3B+filename%3D%22cudnn-linux-x86_64-8.9.1.23_cuda11-archive.tar.xz%22%3B&response-content-type=application%2Fx-xz&Expires=1721060343&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMTA2MDM0M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9jc3VrdWFuZ2ZqL2N1ZG5uL2E2ZDk4ODcyNjdlMjg1OTBjOWRiOTVjZTY1Y2JlOTZhNjY4ZGYwMzUyMzM4YjdkMzM3ZTA1MzJkZWQzMzQ4NWM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=lmgoRw6RnLeofbNMxXJYixzbug-AaJpkRISXLY6T%7EHq77MgHBsoS%7Ez3L31Zh1gII5mefjvbcenXy9ruW6A6O%7EqJHXM4i3ntti8NtkGDSpecvYMwy9mjhFCudO%7Ew-760fnmjNETOLCPVx22Wv-DzJJWw6r1YX-%7Euy4xGlxyRcC00PSHAdicO3xeYJ2KWo6eDICVqQ0IKQPCcq7QS6d1vonM7GBsOqQU%7EN%7EQW-UpNHSjaLSRKO5cAAThsneaka-bM8Sou0HDmdW-Fcys9aoJq5qCbsKvreNiTJGMjnaeuwVpo8nrqMKMBSV-BLOZsooUN8KulBv3chFMYHv15XNzHM-Q__&Key-Pair-Id=K3ESJI6DHPFC7\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.65.25.122, 18.65.25.124, 18.65.25.40, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.65.25.122|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 903887852 (862M) [application/x-xz]\n",
            "Saving to: ‘cudnn-linux-x86_64-8.9.1.23_cuda11-archive.tar.xz’\n",
            "\n",
            "cudnn-linux-x86_64- 100%[===================>] 862.01M  27.3MB/s    in 32s     \n",
            "\n",
            "2024-07-12 16:19:35 (26.9 MB/s) - ‘cudnn-linux-x86_64-8.9.1.23_cuda11-archive.tar.xz’ saved [903887852/903887852]\n",
            "\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_adv_infer_static.a\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_adv_infer_static_v8.a\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_adv_train_static.a\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_adv_train_static_v8.a\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_cnn_infer_static.a\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_cnn_infer_static_v8.a\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_cnn_train_static.a\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_cnn_train_static_v8.a\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_ops_infer_static.a\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_ops_infer_static_v8.a\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_ops_train_static.a\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_ops_train_static_v8.a\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn.so.8\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn.so.8.9.1\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn.so\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_adv_infer.so.8.9.1\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_adv_infer.so\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_adv_infer.so.8\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_adv_train.so\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_adv_train.so.8\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_adv_train.so.8.9.1\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_cnn_infer.so.8\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_cnn_infer.so\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_cnn_infer.so.8.9.1\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_cnn_train.so.8.9.1\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_cnn_train.so\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_cnn_train.so.8\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_ops_infer.so\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_ops_infer.so.8\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_ops_infer.so.8.9.1\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_ops_train.so\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_ops_train.so.8.9.1\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/lib/libcudnn_ops_train.so.8\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/include/\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/include/cudnn_v8.h\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/include/cudnn_adv_infer_v8.h\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/include/cudnn_adv_train_v8.h\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/include/cudnn_backend_v8.h\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/include/cudnn_cnn_infer_v8.h\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/include/cudnn_cnn_train_v8.h\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/include/cudnn_ops_infer_v8.h\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/include/cudnn_ops_train_v8.h\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/include/cudnn_version_v8.h\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/include/cudnn.h\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/include/cudnn_adv_infer.h\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/include/cudnn_adv_train.h\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/include/cudnn_backend.h\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/include/cudnn_cnn_infer.h\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/include/cudnn_cnn_train.h\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/include/cudnn_ops_infer.h\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/include/cudnn_ops_train.h\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/include/cudnn_version.h\n",
            "cudnn-linux-x86_64-8.9.1.23_cuda11-archive/LICENSE\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "exe=$PWD/sherpa-onnx/build/bin/sherpa-onnx-offline\n",
        "\n",
        "echo $exe\n",
        "cd sherpa-onnx-whisper-large-v3\n",
        "\n",
        "\n",
        "time $exe \\\n",
        "  --whisper-encoder=./large-v3-encoder.onnx \\\n",
        "  --whisper-decoder=./large-v3-decoder.onnx \\\n",
        "  --tokens=./large-v3-tokens.txt \\\n",
        "  --provider=cuda \\\n",
        "  --num-threads=2 \\\n",
        "  ./test_wavs/0.wav || true\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-2mDB8ikPkl",
        "outputId": "48a28357-63b5-42fd-ce5c-9e37de520ea8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/build/bin/sherpa-onnx-offline\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:375 /content/sherpa-onnx/build/bin/sherpa-onnx-offline --whisper-encoder=./large-v3-encoder.onnx --whisper-decoder=./large-v3-decoder.onnx --tokens=./large-v3-tokens.txt --provider=cuda --num-threads=2 ./test_wavs/0.wav \n",
            "\n",
            "OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=\"\", decoder_filename=\"\", joiner_filename=\"\"), paraformer=OfflineParaformerModelConfig(model=\"\"), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=\"\"), whisper=OfflineWhisperModelConfig(encoder=\"./large-v3-encoder.onnx\", decoder=\"./large-v3-decoder.onnx\", language=\"\", task=\"transcribe\", tail_paddings=-1), tdnn=OfflineTdnnModelConfig(model=\"\"), zipformer_ctc=OfflineZipformerCtcModelConfig(model=\"\"), wenet_ctc=OfflineWenetCtcModelConfig(model=\"\"), telespeech_ctc=\"\", tokens=\"./large-v3-tokens.txt\", num_threads=2, debug=False, provider=\"cuda\", model_type=\"\", modeling_unit=\"cjkchar\", bpe_vocab=\"\"), lm_config=OfflineLMConfig(model=\"\", scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=\"\", max_active=3000), decoding_method=\"greedy_search\", max_active_paths=4, hotwords_file=\"\", hotwords_score=1.5, blank_penalty=0, rule_fsts=\"\", rule_fars=\"\")\n",
            "Creating recognizer ...\n",
            "terminate called after throwing an instance of 'Ort::Exception'\n",
            "  what():  /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1426 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "\n",
            "/bin/bash: line 14:  8499 Aborted                 (core dumped) $exe --whisper-encoder=./large-v3-encoder.onnx --whisper-decoder=./large-v3-decoder.onnx --tokens=./large-v3-tokens.txt --provider=cuda --num-threads=2 ./test_wavs/0.wav\n",
            "\n",
            "real\t0m4.100s\n",
            "user\t0m1.707s\n",
            "sys\t0m2.047s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "ldd ./sherpa-onnx/build/_deps/onnxruntime-src/lib/libonnxruntime_providers_cuda.so"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWNwPyh3lR9i",
        "outputId": "4e856693-571a-46d0-8145-0904c23926bb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tlinux-vdso.so.1 (0x00007ffc8fbd3000)\n",
            "\tlibcublasLt.so.11 => not found\n",
            "\tlibcublas.so.11 => not found\n",
            "\tlibcudnn.so.8 => /lib/x86_64-linux-gnu/libcudnn.so.8 (0x00007fe2ec000000)\n",
            "\tlibcurand.so.10 => /usr/local/cuda/targets/x86_64-linux/lib/libcurand.so.10 (0x00007fe2e5600000)\n",
            "\tlibcufft.so.10 => not found\n",
            "\tlibcudart.so.11.0 => not found\n",
            "\tlibdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007fe2ec285000)\n",
            "\tlibrt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007fe2ec280000)\n",
            "\tlibpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007fe2ec27b000)\n",
            "\tlibstdc++.so.6 => /lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007fe2e53d4000)\n",
            "\tlibm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007fe2ebf19000)\n",
            "\tlibgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007fe2ec259000)\n",
            "\tlibc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007fe2e51ab000)\n",
            "\t/lib64/ld-linux-x86-64.so.2 (0x00007fe30b553000)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd /star-fj/fangjun/software/cuda-11.8.0\n",
        "find . -name libcublasLt.so.11\n",
        "\n",
        "find . -name libcublas.so.11\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWlBNIHXldNq",
        "outputId": "7570b9f8-270d-4137-8cd7-312891bfe20e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./targets/x86_64-linux/lib/libcublasLt.so.11\n",
            "./targets/x86_64-linux/lib/libcublas.so.11\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "export CUDA_HOME=/star-fj/fangjun/software/cuda-11.8.0\n",
        "export PATH=$CUDA_HOME/bin:$PATH\n",
        "export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH\n",
        "export LD_LIBRARY_PATH=$CUDA_HOME/lib:$LD_LIBRARY_PATH\n",
        "\n",
        "export CUDA_TOOLKIT_ROOT_DIR=$CUDA_HOME\n",
        "export CUDA_TOOLKIT_ROOT=$CUDA_HOME\n",
        "export CUDA_BIN_PATH=$CUDA_HOME\n",
        "export CUDA_PATH=$CUDA_HOME\n",
        "export CUDA_INC_PATH=$CUDA_HOME/targets/x86_64-linux\n",
        "export CFLAGS=-I$CUDA_HOME/targets/x86_64-linux/include:$CFLAGS\n",
        "\n",
        "exe=$PWD/sherpa-onnx/build/bin/sherpa-onnx-offline\n",
        "\n",
        "echo $exe\n",
        "cd sherpa-onnx-whisper-large-v3\n",
        "\n",
        "time $exe \\\n",
        "  --whisper-encoder=./large-v3-encoder.onnx \\\n",
        "  --whisper-decoder=./large-v3-decoder.onnx \\\n",
        "  --tokens=./large-v3-tokens.txt \\\n",
        "  --provider=cuda \\\n",
        "  --num-threads=2 \\\n",
        "  ./test_wavs/0.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ00ZH0IlqMA",
        "outputId": "89a74c92-9af1-49bb-e25f-72dd17ede477"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sherpa-onnx/build/bin/sherpa-onnx-offline\n",
            "/content/sherpa-onnx/sherpa-onnx/csrc/parse-options.cc:Read:375 /content/sherpa-onnx/build/bin/sherpa-onnx-offline --whisper-encoder=./large-v3-encoder.onnx --whisper-decoder=./large-v3-decoder.onnx --tokens=./large-v3-tokens.txt --provider=cuda --num-threads=2 ./test_wavs/0.wav \n",
            "\n",
            "OfflineRecognizerConfig(feat_config=FeatureExtractorConfig(sampling_rate=16000, feature_dim=80, low_freq=20, high_freq=-400, dither=0), model_config=OfflineModelConfig(transducer=OfflineTransducerModelConfig(encoder_filename=\"\", decoder_filename=\"\", joiner_filename=\"\"), paraformer=OfflineParaformerModelConfig(model=\"\"), nemo_ctc=OfflineNemoEncDecCtcModelConfig(model=\"\"), whisper=OfflineWhisperModelConfig(encoder=\"./large-v3-encoder.onnx\", decoder=\"./large-v3-decoder.onnx\", language=\"\", task=\"transcribe\", tail_paddings=-1), tdnn=OfflineTdnnModelConfig(model=\"\"), zipformer_ctc=OfflineZipformerCtcModelConfig(model=\"\"), wenet_ctc=OfflineWenetCtcModelConfig(model=\"\"), telespeech_ctc=\"\", tokens=\"./large-v3-tokens.txt\", num_threads=2, debug=False, provider=\"cuda\", model_type=\"\", modeling_unit=\"cjkchar\", bpe_vocab=\"\"), lm_config=OfflineLMConfig(model=\"\", scale=0.5), ctc_fst_decoder_config=OfflineCtcFstDecoderConfig(graph=\"\", max_active=3000), decoding_method=\"greedy_search\", max_active_paths=4, hotwords_file=\"\", hotwords_score=1.5, blank_penalty=0, rule_fsts=\"\", rule_fars=\"\")\n",
            "Creating recognizer ...\n",
            "Started\n",
            "Done!\n",
            "\n",
            "./test_wavs/0.wav\n",
            "{\"text\": \" after early nightfall the yellow lamps would light up here and there the squalid quarter of the brothels\", \"timestamps\": [], \"tokens\":[\" after\", \" early\", \" night\", \"fall\", \" the\", \" yellow\", \" lamps\", \" would\", \" light\", \" up\", \" here\", \" and\", \" there\", \" the\", \" squ\", \"alid\", \" quarter\", \" of\", \" the\", \" broth\", \"els\"], \"words\": []}\n",
            "----\n",
            "num threads: 2\n",
            "decoding method: greedy_search\n",
            "Elapsed seconds: 5.910 s\n",
            "Real time factor (RTF): 5.910 / 6.625 = 0.892\n",
            "\n",
            "real\t0m26.996s\n",
            "user\t0m12.854s\n",
            "sys\t0m4.486s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPdgg6Ill4q3",
        "outputId": "035d9862-a3e8-4cae-e546-8af1c173dd87"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jul 12 16:23:02 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   78C    P0              42W /  70W |    105MiB / 15360MiB |      1%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NqDtZp0Ina6U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
